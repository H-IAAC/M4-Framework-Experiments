trial_id,config,error_type,error_message,error_traceback
2e1a339a,"{'temperature_head': 0.9, 'latent_dim': 127, 'batch_size': 182, 'transform_funcs': (3, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.07 GiB memory in use. Process 110650 has 844.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 882.00 MiB memory in use. Process 113906 has 792.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 902.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 928.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 886.00 MiB memory in use. Process 114710 has 926.00 MiB memory in use. Process 114711 has 768.00 MiB memory in use. Process 114717 has 1.06 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 948.00 MiB memory in use. Process 115097 has 960.00 MiB memory in use. Process 115103 has 586.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 714.00 MiB memory in use. Of the allocated memory 210.84 MiB is allocated by PyTorch, and 37.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
071a96ab,"{'temperature_head': 0.2, 'latent_dim': 21, 'batch_size': 289, 'transform_funcs': (1, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1014.00 MiB memory in use. Process 110622 has 648.00 MiB memory in use. Process 110650 has 996.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 730.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 744.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 1.01 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 954.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 45.53 MiB is allocated by PyTorch, and 34.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
67e502dc,"{'temperature_head': 0.6000000000000001, 'latent_dim': 55, 'batch_size': 262, 'transform_funcs': (1, 2, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 996.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 732.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 992.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 744.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 562.00 MiB memory in use. Process 114717 has 452.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 954.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 166.79 MiB is allocated by PyTorch, and 57.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aeb9b9c5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 103, 'batch_size': 253, 'transform_funcs': (1, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 732.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 992.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 792.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 510.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 956.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.65 MiB is allocated by PyTorch, and 37.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ce9abd12,"{'temperature_head': 0.5, 'latent_dim': 87, 'batch_size': 169, 'transform_funcs': (1, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 696.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 992.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 792.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 510.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1014.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.52 MiB is allocated by PyTorch, and 37.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
150817d3,"{'temperature_head': 0.4, 'latent_dim': 40, 'batch_size': 281, 'transform_funcs': (1, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 452.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 992.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 700.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 508.00 MiB memory in use. Process 114717 has 748.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1014.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.16 MiB is allocated by PyTorch, and 35.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ecbab2c7,"{'temperature_head': 0.2, 'latent_dim': 136, 'batch_size': 157, 'transform_funcs': (0, 1, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 696.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 592.00 MiB memory in use. Process 114717 has 748.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 215.31 MiB is allocated by PyTorch, and 38.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3dc58b82,"{'temperature_head': 0.5, 'latent_dim': 94, 'batch_size': 328, 'transform_funcs': (1, 2, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 856.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 872.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 508.00 MiB memory in use. Process 114717 has 504.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.58 MiB is allocated by PyTorch, and 35.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d5687096,"{'temperature_head': 0.4, 'latent_dim': 48, 'batch_size': 237, 'transform_funcs': (1, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 856.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 818.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 508.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.22 MiB is allocated by PyTorch, and 35.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
213db51a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 70, 'batch_size': 344, 'transform_funcs': (0, 1, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 856.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 772.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 566.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 175.77 MiB is allocated by PyTorch, and 52.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b273470f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 122, 'batch_size': 292, 'transform_funcs': (1, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 858.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 816.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 508.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.80 MiB is allocated by PyTorch, and 35.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
afc97aea,"{'temperature_head': 0.30000000000000004, 'latent_dim': 81, 'batch_size': 199, 'transform_funcs': (5, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 558.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 896.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 806.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 566.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 182.36 MiB is allocated by PyTorch, and 45.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b2a84b79,"{'temperature_head': 0.1, 'latent_dim': 58, 'batch_size': 207, 'transform_funcs': (1, 2, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 976.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 452.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 420.00 MiB memory in use. Process 114717 has 726.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.82 MiB is allocated by PyTorch, and 36.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1c794a9a,"{'temperature_head': 0.5, 'latent_dim': 115, 'batch_size': 336, 'transform_funcs': (1, 2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 502.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 504.00 MiB memory in use. Process 114717 has 728.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.74 MiB is allocated by PyTorch, and 31.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
da865dd3,"{'temperature_head': 0.7000000000000001, 'latent_dim': 102, 'batch_size': 296, 'transform_funcs': (4, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 502.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 728.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.64 MiB is allocated by PyTorch, and 35.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
18295119,"{'temperature_head': 0.30000000000000004, 'latent_dim': 108, 'batch_size': 354, 'transform_funcs': (0, 2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 782.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 508.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 574.00 MiB memory in use. Process 114717 has 624.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 198.69 MiB is allocated by PyTorch, and 37.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
93dda031,"{'temperature_head': 0.30000000000000004, 'latent_dim': 87, 'batch_size': 242, 'transform_funcs': (0, 1, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 506.00 MiB memory in use. Process 114717 has 562.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.52 MiB is allocated by PyTorch, and 33.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3571105b,"{'temperature_head': 0.5, 'latent_dim': 113, 'batch_size': 280, 'transform_funcs': (1, 2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 510.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.73 MiB is allocated by PyTorch, and 37.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
63ef0cc9,"{'temperature_head': 0.4, 'latent_dim': 18, 'batch_size': 471, 'transform_funcs': (4, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.51 MiB is allocated by PyTorch, and 32.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c5861782,"{'temperature_head': 0.5, 'latent_dim': 104, 'batch_size': 257, 'transform_funcs': (4, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 454.00 MiB memory in use. Process 114717 has 504.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.66 MiB is allocated by PyTorch, and 37.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b6977de3,"{'temperature_head': 0.2, 'latent_dim': 34, 'batch_size': 193, 'transform_funcs': (3, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 822.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.11 MiB is allocated by PyTorch, and 33.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
56dde865,"{'temperature_head': 0.9, 'latent_dim': 54, 'batch_size': 234, 'transform_funcs': (2, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 470.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.79 MiB is allocated by PyTorch, and 32.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
56ad5370,"{'temperature_head': 0.5, 'latent_dim': 42, 'batch_size': 213, 'transform_funcs': (1, 3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 420.00 MiB memory in use. Process 114717 has 478.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.69 MiB is allocated by PyTorch, and 36.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ca2d1e75,"{'temperature_head': 0.5, 'latent_dim': 26, 'batch_size': 199, 'transform_funcs': (2, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 608.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 496.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 414.00 MiB memory in use. Process 114717 has 486.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.57 MiB is allocated by PyTorch, and 30.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e8ae615,"{'temperature_head': 0.4, 'latent_dim': 65, 'batch_size': 296, 'transform_funcs': (0, 1, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 608.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 496.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 424.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 57.15 MiB is allocated by PyTorch, and 28.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
0ecc4cfc,"{'temperature_head': 0.1, 'latent_dim': 81, 'batch_size': 227, 'transform_funcs': (2, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 608.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 496.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 424.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 57.60 MiB is allocated by PyTorch, and 28.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
d8179b1c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 87, 'batch_size': 178, 'transform_funcs': (0, 3, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 608.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 496.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 424.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 57.63 MiB is allocated by PyTorch, and 28.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
09c9fe5f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 96, 'batch_size': 335, 'transform_funcs': (2, 3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 820.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 550.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 496.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 510.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.59 MiB is allocated by PyTorch, and 37.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
071ea1ed,"{'temperature_head': 0.8, 'latent_dim': 138, 'batch_size': 377, 'transform_funcs': (0, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 502.00 MiB memory in use. Process 114325 has 778.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 592.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 216.92 MiB is allocated by PyTorch, and 37.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5b9eb446,"{'temperature_head': 0.4, 'latent_dim': 3, 'batch_size': 421, 'transform_funcs': (0, 3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 950.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 780.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 680.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 61.71 MiB is allocated by PyTorch, and 30.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
c841507e,"{'temperature_head': 0.2, 'latent_dim': 151, 'batch_size': 204, 'transform_funcs': (1, 2, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 952.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 950.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 670.00 MiB memory in use. Process 114717 has 732.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 79.02 MiB is allocated by PyTorch, and 34.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6dff8498,"{'temperature_head': 0.5, 'latent_dim': 62, 'batch_size': 324, 'transform_funcs': (2, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 952.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 950.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 450.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 670.00 MiB memory in use. Process 114717 has 732.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.33 MiB is allocated by PyTorch, and 33.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b26bbb60,"{'temperature_head': 0.30000000000000004, 'latent_dim': 58, 'batch_size': 133, 'transform_funcs': (0, 2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 952.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 504.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 656.00 MiB memory in use. Process 114717 has 732.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.30 MiB is allocated by PyTorch, and 31.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
68c7ab35,"{'temperature_head': 0.30000000000000004, 'latent_dim': 132, 'batch_size': 341, 'transform_funcs': (2, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 462.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 442.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 422.00 MiB memory in use. Process 114717 has 770.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.40 MiB is allocated by PyTorch, and 37.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
37d4c4e6,"{'temperature_head': 0.9, 'latent_dim': 110, 'batch_size': 385, 'transform_funcs': (0, 2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 464.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 442.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 420.00 MiB memory in use. Process 114717 has 770.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.23 MiB is allocated by PyTorch, and 35.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4069d5e5,"{'temperature_head': 0.4, 'latent_dim': 42, 'batch_size': 328, 'transform_funcs': (0, 1, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 592.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 470.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 448.00 MiB memory in use. Process 114717 has 710.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.17 MiB is allocated by PyTorch, and 31.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
52675958,"{'temperature_head': 0.6000000000000001, 'latent_dim': 84, 'batch_size': 173, 'transform_funcs': (0, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.53 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 592.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 468.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 710.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.02 MiB is allocated by PyTorch, and 31.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
38026b08,"{'temperature_head': 0.30000000000000004, 'latent_dim': 70, 'batch_size': 163, 'transform_funcs': (1, 3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.53 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 714.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.91 MiB is allocated by PyTorch, and 34.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4782f096,"{'temperature_head': 0.5, 'latent_dim': 77, 'batch_size': 214, 'transform_funcs': (1, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 666.00 MiB memory in use. Process 114325 has 454.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 714.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.44 MiB is allocated by PyTorch, and 37.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d57c2327,"{'temperature_head': 0.30000000000000004, 'latent_dim': 66, 'batch_size': 197, 'transform_funcs': (0, 1, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 678.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 448.00 MiB memory in use. Process 114717 has 714.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.36 MiB is allocated by PyTorch, and 31.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5f49de24,"{'temperature_head': 0.5, 'latent_dim': 81, 'batch_size': 206, 'transform_funcs': (3, 4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 672.00 MiB memory in use. Process 114324 has 746.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 506.00 MiB memory in use. Process 114717 has 472.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.48 MiB is allocated by PyTorch, and 33.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
adda1551,"{'temperature_head': 0.30000000000000004, 'latent_dim': 57, 'batch_size': 236, 'transform_funcs': (5, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 672.00 MiB memory in use. Process 114324 has 746.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 400.00 MiB memory in use. Process 114717 has 472.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 35.70 MiB is allocated by PyTorch, and 26.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
1114f40c,"{'temperature_head': 0.4, 'latent_dim': 38, 'batch_size': 295, 'transform_funcs': (0, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 644.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 672.00 MiB memory in use. Process 114324 has 692.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.66 MiB is allocated by PyTorch, and 32.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
834ada5b,"{'temperature_head': 0.5, 'latent_dim': 47, 'batch_size': 306, 'transform_funcs': (1, 2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 538.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 700.00 MiB memory in use. Process 114324 has 690.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 488.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.73 MiB is allocated by PyTorch, and 32.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
690ccf2d,"{'temperature_head': 0.2, 'latent_dim': 83, 'batch_size': 252, 'transform_funcs': (2, 3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 618.00 MiB memory in use. Process 114325 has 662.00 MiB memory in use. Process 114324 has 690.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 502.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.49 MiB is allocated by PyTorch, and 33.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
868e7bdd,"{'temperature_head': 0.7000000000000001, 'latent_dim': 66, 'batch_size': 301, 'transform_funcs': (3, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 510.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 618.00 MiB memory in use. Process 114325 has 662.00 MiB memory in use. Process 114324 has 690.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 52.23 MiB is allocated by PyTorch, and 27.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
ac464662,"{'temperature_head': 0.4, 'latent_dim': 58, 'batch_size': 241, 'transform_funcs': (0, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 506.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 618.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 448.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.30 MiB is allocated by PyTorch, and 31.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8b4c59c7,"{'temperature_head': 0.1, 'latent_dim': 35, 'batch_size': 169, 'transform_funcs': (0, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 454.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 448.00 MiB memory in use. Process 114325 has 418.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 618.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.64 MiB is allocated by PyTorch, and 34.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cac5208d,"{'temperature_head': 0.4, 'latent_dim': 51, 'batch_size': 334, 'transform_funcs': (2, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 808.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 466.00 MiB memory in use. Process 114325 has 464.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.77 MiB is allocated by PyTorch, and 32.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4396ab30,"{'temperature_head': 0.2, 'latent_dim': 70, 'batch_size': 255, 'transform_funcs': (0, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 808.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 448.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.39 MiB is allocated by PyTorch, and 31.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
02871037,"{'temperature_head': 0.8, 'latent_dim': 81, 'batch_size': 480, 'transform_funcs': (3, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 808.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 438.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.00 MiB is allocated by PyTorch, and 34.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1ad2e6b8,"{'temperature_head': 0.4, 'latent_dim': 103, 'batch_size': 158, 'transform_funcs': (3, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 454.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 510.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 720.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.65 MiB is allocated by PyTorch, and 37.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
78a9462a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 55, 'batch_size': 283, 'transform_funcs': (0, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 500.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 416.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 720.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.80 MiB is allocated by PyTorch, and 32.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d2bd3975,"{'temperature_head': 0.5, 'latent_dim': 75, 'batch_size': 310, 'transform_funcs': (0, 2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 500.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 494.00 MiB memory in use. Process 114325 has 420.00 MiB memory in use. Process 114324 has 502.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 746.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 36.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
09576cd8,"{'temperature_head': 0.30000000000000004, 'latent_dim': 42, 'batch_size': 262, 'transform_funcs': (2, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 498.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 494.00 MiB memory in use. Process 114325 has 418.00 MiB memory in use. Process 114324 has 504.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 764.00 MiB memory in use. Process 114717 has 562.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.69 MiB is allocated by PyTorch, and 34.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8730c1ad,"{'temperature_head': 0.6000000000000001, 'latent_dim': 123, 'batch_size': 248, 'transform_funcs': (0, 4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 722.00 MiB memory in use. Process 110650 has 866.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 510.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.80 MiB is allocated by PyTorch, and 37.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4e7eabc2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 24, 'batch_size': 303, 'transform_funcs': (2, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 666.00 MiB memory in use. Process 110650 has 916.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 450.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 562.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.03 MiB is allocated by PyTorch, and 33.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
adaa2319,"{'temperature_head': 0.4, 'latent_dim': 90, 'batch_size': 276, 'transform_funcs': (2, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 434.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 508.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.55 MiB is allocated by PyTorch, and 35.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
610ebdfd,"{'temperature_head': 0.1, 'latent_dim': 62, 'batch_size': 268, 'transform_funcs': (0, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 560.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 506.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 766.00 MiB memory in use. Process 114717 has 450.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.33 MiB is allocated by PyTorch, and 33.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26182d14,"{'temperature_head': 0.2, 'latent_dim': 16, 'batch_size': 232, 'transform_funcs': (3, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 556.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 454.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 77.97 MiB is allocated by PyTorch, and 34.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f3c2c587,"{'temperature_head': 0.30000000000000004, 'latent_dim': 147, 'batch_size': 214, 'transform_funcs': (0, 1, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 556.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 512.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
de5e172c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 82, 'batch_size': 257, 'transform_funcs': (0, 1, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 554.00 MiB memory in use. Process 114324 has 730.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.01 MiB is allocated by PyTorch, and 33.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ce198d14,"{'temperature_head': 0.4, 'latent_dim': 71, 'batch_size': 375, 'transform_funcs': (1, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 556.00 MiB memory in use. Process 114324 has 730.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 448.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.40 MiB is allocated by PyTorch, and 31.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b8f5211,"{'temperature_head': 0.4, 'latent_dim': 31, 'batch_size': 225, 'transform_funcs': (1, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 594.00 MiB memory in use. Process 114324 has 734.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.61 MiB is allocated by PyTorch, and 34.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3148d9f5,"{'temperature_head': 0.4, 'latent_dim': 87, 'batch_size': 300, 'transform_funcs': (1, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 688.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.05 MiB is allocated by PyTorch, and 33.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e4b0b035,"{'temperature_head': 0.6000000000000001, 'latent_dim': 98, 'batch_size': 317, 'transform_funcs': (0, 1, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 688.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 504.00 MiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 454.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.61 MiB is allocated by PyTorch, and 37.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d4d957ea,"{'temperature_head': 0.4, 'latent_dim': 108, 'batch_size': 281, 'transform_funcs': (1, 2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 786.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 702.00 MiB memory in use. Process 114324 has 456.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 420.00 MiB memory in use. Process 114717 has 556.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.21 MiB is allocated by PyTorch, and 35.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6e2a0d92,"{'temperature_head': 0.4, 'latent_dim': 80, 'batch_size': 322, 'transform_funcs': (0, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 866.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 966.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 900.00 MiB memory in use. Process 114325 has 456.00 MiB memory in use. Process 114324 has 864.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.47 MiB is allocated by PyTorch, and 39.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
54ca9ce2,"{'temperature_head': 0.4, 'latent_dim': 97, 'batch_size': 178, 'transform_funcs': (0, 1, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 456.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 866.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 966.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 900.00 MiB memory in use. Process 114325 has 454.00 MiB memory in use. Process 114324 has 864.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.60 MiB is allocated by PyTorch, and 37.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f7d015d6,"{'temperature_head': 0.2, 'latent_dim': 153, 'batch_size': 296, 'transform_funcs': (2, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 432.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 902.00 MiB memory in use. Process 114325 has 508.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 688.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.04 MiB is allocated by PyTorch, and 34.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e8842e4d,"{'temperature_head': 0.5, 'latent_dim': 119, 'batch_size': 340, 'transform_funcs': (2, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 496.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 846.00 MiB memory in use. Process 114325 has 454.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 690.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.77 MiB is allocated by PyTorch, and 37.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e25e1cac,"{'temperature_head': 0.4, 'latent_dim': 75, 'batch_size': 298, 'transform_funcs': (0, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 496.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 848.00 MiB memory in use. Process 114325 has 510.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 634.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.43 MiB is allocated by PyTorch, and 37.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0ae6b5e5,"{'temperature_head': 0.2, 'latent_dim': 161, 'batch_size': 264, 'transform_funcs': (4, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 470.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 496.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 830.00 MiB memory in use. Process 114325 has 508.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 634.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.10 MiB is allocated by PyTorch, and 34.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e6f6c37b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 95, 'batch_size': 279, 'transform_funcs': (0, 1, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 470.00 MiB memory in use. Process 110650 has 1004.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 510.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 846.00 MiB memory in use. Process 114325 has 568.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 634.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 190.75 MiB is allocated by PyTorch, and 39.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f2ea2b87,"{'temperature_head': 0.2, 'latent_dim': 5, 'batch_size': 268, 'transform_funcs': (0, 3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 472.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 832.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.00 GiB memory in use. Process 114325 has 614.00 MiB memory in use. Process 114324 has 1.07 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 504.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 133.88 MiB is allocated by PyTorch, and 32.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3fd7fbb4,"{'temperature_head': 0.1, 'latent_dim': 13, 'batch_size': 239, 'transform_funcs': (0, 1, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 832.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 448.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 77.94 MiB is allocated by PyTorch, and 32.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cdaffd16,"{'temperature_head': 0.2, 'latent_dim': 18, 'batch_size': 260, 'transform_funcs': (0, 1, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 828.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1012.00 MiB memory in use. Process 114325 has 664.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.51 MiB is allocated by PyTorch, and 32.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1e832e3e,"{'temperature_head': 0.4, 'latent_dim': 132, 'batch_size': 306, 'transform_funcs': (4, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 944.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 828.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1012.00 MiB memory in use. Process 114325 has 664.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 454.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.88 MiB is allocated by PyTorch, and 37.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f7861771,"{'temperature_head': 0.30000000000000004, 'latent_dim': 102, 'batch_size': 321, 'transform_funcs': (0, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 770.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 752.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.64 MiB is allocated by PyTorch, and 35.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1089a0f7,"{'temperature_head': 0.5, 'latent_dim': 128, 'batch_size': 391, 'transform_funcs': (0, 3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 836.00 MiB memory in use. Process 114324 has 770.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 728.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.84 MiB is allocated by PyTorch, and 35.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c8dc2060,"{'temperature_head': 0.30000000000000004, 'latent_dim': 105, 'batch_size': 415, 'transform_funcs': (0, 2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 836.00 MiB memory in use. Process 114324 has 770.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 572.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 728.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 196.74 MiB is allocated by PyTorch, and 37.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7b025ab3,"{'temperature_head': 0.4, 'latent_dim': 84, 'batch_size': 304, 'transform_funcs': (4, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 476.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 880.00 MiB memory in use. Process 114324 has 770.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 562.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 772.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 184.16 MiB is allocated by PyTorch, and 39.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0827fd81,"{'temperature_head': 0.30000000000000004, 'latent_dim': 114, 'batch_size': 295, 'transform_funcs': (2, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.05 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 770.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 420.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 774.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.26 MiB is allocated by PyTorch, and 35.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4a0830dd,"{'temperature_head': 0.2, 'latent_dim': 86, 'batch_size': 402, 'transform_funcs': (0, 2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 472.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.04 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 770.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 786.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.52 MiB is allocated by PyTorch, and 33.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bc071271,"{'temperature_head': 0.7000000000000001, 'latent_dim': 102, 'batch_size': 250, 'transform_funcs': (0, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 754.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 664.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 658.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.64 MiB is allocated by PyTorch, and 35.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f7f374b8,"{'temperature_head': 0.4, 'latent_dim': 109, 'batch_size': 236, 'transform_funcs': (2, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 754.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 664.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 454.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 658.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.69 MiB is allocated by PyTorch, and 37.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
df65f5c5,"{'temperature_head': 0.30000000000000004, 'latent_dim': 114, 'batch_size': 267, 'transform_funcs': (1, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 754.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 712.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 1.47 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 532.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.73 MiB is allocated by PyTorch, and 35.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1660b792,"{'temperature_head': 0.2, 'latent_dim': 100, 'batch_size': 321, 'transform_funcs': (4, 5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 754.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 834.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 738.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 508.00 MiB memory in use. Process 114717 has 1.47 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 532.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.62 MiB is allocated by PyTorch, and 35.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
75ca12be,"{'temperature_head': 0.7000000000000001, 'latent_dim': 69, 'batch_size': 417, 'transform_funcs': (0, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 934.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 420.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 438.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.91 MiB is allocated by PyTorch, and 36.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ef46c9f1,"{'temperature_head': 0.5, 'latent_dim': 84, 'batch_size': 261, 'transform_funcs': (3, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 508.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 452.00 MiB memory in use. Process 115104 has 642.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.50 MiB is allocated by PyTorch, and 35.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f588b83f,"{'temperature_head': 0.4, 'latent_dim': 56, 'batch_size': 320, 'transform_funcs': (0, 1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 830.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 448.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 622.00 MiB memory in use. Process 115104 has 642.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.28 MiB is allocated by PyTorch, and 31.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7471b45a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 113, 'batch_size': 233, 'transform_funcs': (1, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 510.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 682.00 MiB memory in use. Process 115104 has 918.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.73 MiB is allocated by PyTorch, and 37.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
75de4afc,"{'temperature_head': 0.5, 'latent_dim': 94, 'batch_size': 375, 'transform_funcs': (4, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 424.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 744.00 MiB memory in use. Process 115104 has 916.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 896.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.10 MiB is allocated by PyTorch, and 39.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0cf73efb,"{'temperature_head': 0.30000000000000004, 'latent_dim': 14, 'batch_size': 314, 'transform_funcs': (0, 1, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 530.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 450.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 744.00 MiB memory in use. Process 115104 has 916.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 896.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 77.95 MiB is allocated by PyTorch, and 34.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0ba1c3fc,"{'temperature_head': 0.5, 'latent_dim': 80, 'batch_size': 333, 'transform_funcs': (0, 1, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 838.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 510.00 MiB memory in use. Process 114324 has 660.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.47 MiB is allocated by PyTorch, and 37.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0825125e,"{'temperature_head': 0.5, 'latent_dim': 72, 'batch_size': 267, 'transform_funcs': (0, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 810.00 MiB memory in use. Process 113903 has 780.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 420.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 676.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.93 MiB is allocated by PyTorch, and 36.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ce48046c,"{'temperature_head': 0.1, 'latent_dim': 77, 'batch_size': 340, 'transform_funcs': (2, 3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 494.00 MiB memory in use. Process 114325 has 422.00 MiB memory in use. Process 114324 has 848.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.97 MiB is allocated by PyTorch, and 38.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5f91b1df,"{'temperature_head': 0.4, 'latent_dim': 86, 'batch_size': 354, 'transform_funcs': (2, 3, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 420.00 MiB memory in use. Process 114324 has 792.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.04 MiB is allocated by PyTorch, and 35.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9dfe4a8f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 120, 'batch_size': 407, 'transform_funcs': (1, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 510.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 512.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.78 MiB is allocated by PyTorch, and 37.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e14af7ac,"{'temperature_head': 0.4, 'latent_dim': 108, 'batch_size': 236, 'transform_funcs': (0, 2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 510.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.69 MiB is allocated by PyTorch, and 37.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
564cf69e,"{'temperature_head': 0.4, 'latent_dim': 57, 'batch_size': 295, 'transform_funcs': (0, 2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 504.00 MiB memory in use. Process 114324 has 792.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.46 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 506.00 MiB memory in use. Process 115097 has 514.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.29 MiB is allocated by PyTorch, and 31.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c2052b95,"{'temperature_head': 0.4, 'latent_dim': 62, 'batch_size': 301, 'transform_funcs': (4, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 560.00 MiB memory in use. Process 114324 has 792.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.46 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 484.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 170.98 MiB is allocated by PyTorch, and 51.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
65dd821b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 49, 'batch_size': 273, 'transform_funcs': (0, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 450.00 MiB memory in use. Process 114324 has 792.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.46 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 456.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.23 MiB is allocated by PyTorch, and 33.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
