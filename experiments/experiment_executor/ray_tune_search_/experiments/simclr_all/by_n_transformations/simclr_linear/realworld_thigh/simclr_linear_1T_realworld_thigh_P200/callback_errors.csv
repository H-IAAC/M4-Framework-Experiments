trial_id,config,error_type,error_message,error_traceback
d31fcfe0,"{'temperature_head': 0.2, 'latent_dim': 708, 'batch_size': 342, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 271.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 876.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 690.00 MiB memory in use. Process 21287 has 992.00 MiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 808.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 886.00 MiB memory in use. Process 21689 has 682.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.20 GiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 876.00 MiB memory in use. Process 22080 has 946.00 MiB memory in use. Process 22462 has 824.00 MiB memory in use. Process 22468 has 1.13 GiB memory in use. Process 22465 has 1022.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 860.00 MiB memory in use. Of the allocated memory 458.00 MiB is allocated by PyTorch, and 360.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7998b533,"{'temperature_head': 0.4, 'latent_dim': 639, 'batch_size': 362, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 237.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 878.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 992.00 MiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 886.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.05 GiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 876.00 MiB memory in use. Process 22080 has 700.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.13 GiB memory in use. Process 22465 has 992.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 425.64 MiB is allocated by PyTorch, and 228.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3187ec2a,"{'temperature_head': 0.4, 'latent_dim': 548, 'batch_size': 185, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 239.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 878.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 992.00 MiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 886.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.05 GiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 876.00 MiB memory in use. Process 22080 has 700.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.13 GiB memory in use. Process 22465 has 990.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 380.68 MiB is allocated by PyTorch, and 271.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a46d279c,"{'temperature_head': 1.0, 'latent_dim': 409, 'batch_size': 366, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 173.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 878.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 992.00 MiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 886.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.08 GiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 876.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.13 GiB memory in use. Process 22465 has 994.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 311.91 MiB is allocated by PyTorch, and 344.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2fbcfedf,"{'temperature_head': 0.7000000000000001, 'latent_dim': 622, 'batch_size': 315, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 221.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 878.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 992.00 MiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 886.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.00 GiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 876.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.13 GiB memory in use. Process 22465 has 1.00 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 415.44 MiB is allocated by PyTorch, and 274.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ab8fb6f5,"{'temperature_head': 0.9, 'latent_dim': 458, 'batch_size': 418, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 221.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 878.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 992.00 MiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 886.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 876.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.13 GiB memory in use. Process 22465 has 994.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 335.85 MiB is allocated by PyTorch, and 320.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
033605fd,"{'temperature_head': 0.30000000000000004, 'latent_dim': 568, 'batch_size': 199, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 878.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 992.00 MiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 886.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 876.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 990.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 390.37 MiB is allocated by PyTorch, and 261.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6697d4c2,"{'temperature_head': 0.6000000000000001, 'latent_dim': 475, 'batch_size': 270, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 878.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 994.00 MiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 784.00 MiB memory in use. Process 22084 has 878.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 988.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 344.15 MiB is allocated by PyTorch, and 305.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9f0539ab,"{'temperature_head': 0.9, 'latent_dim': 370, 'batch_size': 345, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.09 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 784.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 492.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 115.43 MiB is allocated by PyTorch, and 38.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7bc6ac5d,"{'temperature_head': 0.5, 'latent_dim': 660, 'batch_size': 232, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 139.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.03 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 784.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 446.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 436.35 MiB is allocated by PyTorch, and 281.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a930caf2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 589, 'batch_size': 436, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.03 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 784.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 498.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 117.16 MiB is allocated by PyTorch, and 42.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
04b62f7b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 512, 'batch_size': 376, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.03 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 784.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 534.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 363.08 MiB is allocated by PyTorch, and 350.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bd5befc0,"{'temperature_head': 0.1, 'latent_dim': 424, 'batch_size': 289, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 167.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 462.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 708.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 319.80 MiB is allocated by PyTorch, and 50.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
52e42a54,"{'temperature_head': 0.4, 'latent_dim': 685, 'batch_size': 267, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 462.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 824.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 744.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 446.98 MiB is allocated by PyTorch, and 373.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cef9ddca,"{'temperature_head': 0.5, 'latent_dim': 381, 'batch_size': 321, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 135.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 442.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 824.00 MiB memory in use. Process 22462 has 856.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 666.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 114.58 MiB is allocated by PyTorch, and 213.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
76121016,"{'temperature_head': 0.2, 'latent_dim': 521, 'batch_size': 128, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 722.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 508.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 824.00 MiB memory in use. Process 22462 has 888.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 696.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 366.44 MiB is allocated by PyTorch, and 449.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6c346e34,"{'temperature_head': 0.9, 'latent_dim': 439, 'batch_size': 482, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 740.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.03 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.30 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 750.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 476.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 888.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 696.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 327.42 MiB is allocated by PyTorch, and 390.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1f39a162,"{'temperature_head': 0.7000000000000001, 'latent_dim': 314, 'batch_size': 273, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 149.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 740.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.20 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 442.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 888.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 618.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 114.05 MiB is allocated by PyTorch, and 165.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
945a1d35,"{'temperature_head': 0.2, 'latent_dim': 481, 'batch_size': 299, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 149.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 740.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.03 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.20 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 442.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 888.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 652.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 347.93 MiB is allocated by PyTorch, and 370.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a5b6426d,"{'temperature_head': 1.0, 'latent_dim': 597, 'batch_size': 452, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 117.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.20 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 1.01 GiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 442.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 888.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 618.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 116.95 MiB is allocated by PyTorch, and 163.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dd7c4f21,"{'temperature_head': 0.5, 'latent_dim': 538, 'batch_size': 413, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 107.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.20 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 794.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 694.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 890.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 616.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 115.81 MiB is allocated by PyTorch, and 162.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d2903db3,"{'temperature_head': 0.4, 'latent_dim': 677, 'batch_size': 372, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.20 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 794.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 694.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 930.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 620.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 116.91 MiB is allocated by PyTorch, and 165.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
be8ba123,"{'temperature_head': 0.9, 'latent_dim': 399, 'batch_size': 228, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.20 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 794.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 694.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 930.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 618.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 114.72 MiB is allocated by PyTorch, and 165.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
66b12294,"{'temperature_head': 0.8, 'latent_dim': 638, 'batch_size': 344, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.20 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 794.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 422.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 930.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 924.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 423.77 MiB is allocated by PyTorch, and 162.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5a9d13b3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 572, 'batch_size': 257, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.03 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 828.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.04 GiB memory in use. Process 22081 has 594.00 MiB memory in use. Process 22084 has 960.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 930.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 704.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 936.00 MiB memory in use. Of the allocated memory 392.39 MiB is allocated by PyTorch, and 319.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1494cd4d,"{'temperature_head': 0.5, 'latent_dim': 452, 'batch_size': 128, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 197.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1024.00 MiB memory in use. Process 22081 has 692.00 MiB memory in use. Process 22084 has 422.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 952.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 820.00 MiB memory in use. Of the allocated memory 332.79 MiB is allocated by PyTorch, and 353.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a0d1140,"{'temperature_head': 0.30000000000000004, 'latent_dim': 565, 'batch_size': 142, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 189.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 986.00 MiB memory in use. Process 22081 has 712.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 812.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 388.88 MiB is allocated by PyTorch, and 85.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2b59360a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 615, 'batch_size': 405, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 225.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 986.00 MiB memory in use. Process 22081 has 712.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 826.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 812.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 412.36 MiB is allocated by PyTorch, and 405.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
508dca95,"{'temperature_head': 0.4, 'latent_dim': 658, 'batch_size': 366, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.06 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1002.00 MiB memory in use. Process 22081 has 746.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 748.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 996.00 MiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 434.11 MiB is allocated by PyTorch, and 229.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
10fdfff2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 716, 'batch_size': 318, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 444.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 604.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 462.54 MiB is allocated by PyTorch, and 231.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
72f15947,"{'temperature_head': 0.5, 'latent_dim': 700, 'batch_size': 491, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 225.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 500.00 MiB memory in use. Process 22081 has 756.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 604.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.31 MiB is allocated by PyTorch, and 43.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7393ccc3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 548, 'batch_size': 444, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 225.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 534.00 MiB memory in use. Process 22081 has 756.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 604.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 381.11 MiB is allocated by PyTorch, and 436.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
99d6ef48,"{'temperature_head': 1.0, 'latent_dim': 638, 'batch_size': 349, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 279.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 940.00 MiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 480.00 MiB memory in use. Process 22081 has 756.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 604.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.82 MiB is allocated by PyTorch, and 24.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
60fed86e,"{'temperature_head': 0.9, 'latent_dim': 439, 'batch_size': 464, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 85.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 482.00 MiB memory in use. Process 22081 has 756.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 634.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.25 MiB is allocated by PyTorch, and 27.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
94756c0f,"{'temperature_head': 0.4, 'latent_dim': 575, 'batch_size': 337, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 774.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 478.00 MiB memory in use. Process 22081 has 756.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 634.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.37 MiB is allocated by PyTorch, and 22.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
343a9b3d,"{'temperature_head': 0.8, 'latent_dim': 511, 'batch_size': 295, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 83.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 776.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 482.00 MiB memory in use. Process 22081 has 756.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 634.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.82 MiB is allocated by PyTorch, and 27.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d41385c2,"{'temperature_head': 0.1, 'latent_dim': 393, 'batch_size': 274, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 776.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 482.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 494.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.13 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.89 MiB is allocated by PyTorch, and 28.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a505c7a8,"{'temperature_head': 0.2, 'latent_dim': 526, 'batch_size': 252, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 776.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 442.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.21 MiB is allocated by PyTorch, and 20.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
328bfcf8,"{'temperature_head': 0.9, 'latent_dim': 306, 'batch_size': 371, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 776.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 472.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 444.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.27 MiB is allocated by PyTorch, and 18.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2b1069e1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 628, 'batch_size': 304, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 482.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 444.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 418.71 MiB is allocated by PyTorch, and 399.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a0e374ba,"{'temperature_head': 0.8, 'latent_dim': 267, 'batch_size': 330, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.34 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.02 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 444.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.96 MiB is allocated by PyTorch, and 23.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
67db835d,"{'temperature_head': 0.4, 'latent_dim': 405, 'batch_size': 190, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 886.00 MiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 584.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.05 MiB is allocated by PyTorch, and 21.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
87f9648f,"{'temperature_head': 0.1, 'latent_dim': 337, 'batch_size': 471, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 886.00 MiB memory in use. Process 22071 has 472.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 584.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.51 MiB is allocated by PyTorch, and 18.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a6a949c2,"{'temperature_head': 0.5, 'latent_dim': 379, 'batch_size': 221, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 117.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 886.00 MiB memory in use. Process 22071 has 472.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 584.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.84 MiB is allocated by PyTorch, and 18.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
de51e4c5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 435, 'batch_size': 230, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 81.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 886.00 MiB memory in use. Process 22071 has 472.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 620.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.22 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.28 MiB is allocated by PyTorch, and 17.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ce98bf61,"{'temperature_head': 0.2, 'latent_dim': 327, 'batch_size': 235, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 886.00 MiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 552.00 MiB memory in use. Process 22080 has 622.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.43 MiB is allocated by PyTorch, and 22.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9c02d3c4,"{'temperature_head': 0.6000000000000001, 'latent_dim': 355, 'batch_size': 177, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 932.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 886.00 MiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 554.00 MiB memory in use. Process 22080 has 622.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.65 MiB is allocated by PyTorch, and 20.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8336ca30,"{'temperature_head': 0.30000000000000004, 'latent_dim': 198, 'batch_size': 288, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 816.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 572.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 554.00 MiB memory in use. Process 22080 has 622.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 210.42 MiB is allocated by PyTorch, and 23.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d2984792,"{'temperature_head': 0.4, 'latent_dim': 295, 'batch_size': 135, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 592.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.37 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 816.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 522.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 584.00 MiB memory in use. Process 22080 has 656.00 MiB memory in use. Process 22462 has 962.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.30 MiB is allocated by PyTorch, and 69.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
21c21b51,"{'temperature_head': 0.8, 'latent_dim': 388, 'batch_size': 152, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 103.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 682.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 884.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 876.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 662.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 302.92 MiB is allocated by PyTorch, and 41.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
71663d2e,"{'temperature_head': 0.9, 'latent_dim': 541, 'batch_size': 492, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 151.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 634.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 884.00 MiB memory in use. Process 21295 has 896.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 876.00 MiB memory in use. Process 22081 has 904.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 662.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.75 MiB is allocated by PyTorch, and 179.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0239661a,"{'temperature_head': 1.0, 'latent_dim': 558, 'batch_size': 273, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 908.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 884.00 MiB memory in use. Process 21295 has 610.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 910.00 MiB memory in use. Process 22081 has 884.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 734.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 385.09 MiB is allocated by PyTorch, and 184.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3aaa797f,"{'temperature_head': 1.0, 'latent_dim': 582, 'batch_size': 217, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 914.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 884.00 MiB memory in use. Process 21295 has 610.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 942.00 MiB memory in use. Process 22081 has 884.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 734.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 397.07 MiB is allocated by PyTorch, and 178.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5f04eb62,"{'temperature_head': 0.4, 'latent_dim': 508, 'batch_size': 437, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 213.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 740.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 884.00 MiB memory in use. Process 21295 has 610.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 942.00 MiB memory in use. Process 22081 has 884.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 734.00 MiB memory in use. Process 22462 has 932.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 361.54 MiB is allocated by PyTorch, and 40.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6f2d78d0,"{'temperature_head': 0.5, 'latent_dim': 493, 'batch_size': 473, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 796.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 694.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 886.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 922.00 MiB memory in use. Process 22071 has 942.00 MiB memory in use. Process 22081 has 884.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 820.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.37 MiB is allocated by PyTorch, and 239.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b9677084,"{'temperature_head': 0.9, 'latent_dim': 277, 'batch_size': 318, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 898.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 694.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.03 GiB memory in use. Process 22071 has 978.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 660.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 247.81 MiB is allocated by PyTorch, and 108.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
95314a09,"{'temperature_head': 0.8, 'latent_dim': 554, 'batch_size': 430, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 898.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 696.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.03 GiB memory in use. Process 22071 has 978.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 706.00 MiB memory in use. Process 22080 has 660.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.18 MiB is allocated by PyTorch, and 240.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
87e1ced3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 533, 'batch_size': 347, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 139.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 898.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 694.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.03 GiB memory in use. Process 22071 has 978.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 610.00 MiB memory in use. Process 22080 has 660.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 642.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.68 MiB is allocated by PyTorch, and 239.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6d47307f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 515, 'batch_size': 281, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 79.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 692.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.03 GiB memory in use. Process 22071 has 978.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 610.00 MiB memory in use. Process 22080 has 718.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.51 MiB is allocated by PyTorch, and 236.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3a5d50c1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 648, 'batch_size': 312, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 151.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 728.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.03 GiB memory in use. Process 22071 has 834.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 718.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 429.08 MiB is allocated by PyTorch, and 66.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
631cc2f9,"{'temperature_head': 0.9, 'latent_dim': 681, 'batch_size': 301, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 151.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 728.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.03 GiB memory in use. Process 22071 has 834.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 718.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.94 MiB is allocated by PyTorch, and 379.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
43b127f8,"{'temperature_head': 0.5, 'latent_dim': 367, 'batch_size': 331, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 874.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.03 GiB memory in use. Process 22071 has 834.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 718.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 291.78 MiB is allocated by PyTorch, and 244.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1cc661d8,"{'temperature_head': 0.8, 'latent_dim': 628, 'batch_size': 388, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 293.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 906.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 484.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 718.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.44 MiB is allocated by PyTorch, and 27.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bf12c39b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 699, 'batch_size': 361, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 201.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 964.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 518.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 718.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 453.99 MiB is allocated by PyTorch, and 172.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1c10c27b,"{'temperature_head': 0.8, 'latent_dim': 663, 'batch_size': 479, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 173.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 996.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 482.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.67 MiB is allocated by PyTorch, and 23.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9eb99e18,"{'temperature_head': 0.4, 'latent_dim': 427, 'batch_size': 269, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 169.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 962.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 520.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 321.09 MiB is allocated by PyTorch, and 302.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ce8cbc6c,"{'temperature_head': 0.5, 'latent_dim': 500, 'batch_size': 291, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 169.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 994.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 488.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 646.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.73 MiB is allocated by PyTorch, and 31.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
de0d1247,"{'temperature_head': 0.7000000000000001, 'latent_dim': 392, 'batch_size': 488, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 85.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 900.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 994.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 806.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 764.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 482.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.89 MiB is allocated by PyTorch, and 26.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b3843997,"{'temperature_head': 0.5, 'latent_dim': 300, 'batch_size': 465, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 131.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 694.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 994.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 892.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 692.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 628.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 259.36 MiB is allocated by PyTorch, and 28.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d83b1fc5,"{'temperature_head': 1.0, 'latent_dim': 325, 'batch_size': 421, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 694.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 998.00 MiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 892.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 692.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 744.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 270.69 MiB is allocated by PyTorch, and 133.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
13ba1701,"{'temperature_head': 0.4, 'latent_dim': 375, 'batch_size': 497, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 694.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 892.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 692.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 478.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.81 MiB is allocated by PyTorch, and 22.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a111e291,"{'temperature_head': 0.9, 'latent_dim': 354, 'batch_size': 509, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 694.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 892.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 692.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.65 MiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f3e88926,"{'temperature_head': 0.7000000000000001, 'latent_dim': 476, 'batch_size': 456, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 694.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 892.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 692.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.61 MiB is allocated by PyTorch, and 17.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
efea4653,"{'temperature_head': 0.8, 'latent_dim': 451, 'batch_size': 475, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 612.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 892.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 692.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.41 MiB is allocated by PyTorch, and 19.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
766c6b53,"{'temperature_head': 0.8, 'latent_dim': 567, 'batch_size': 286, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 123.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 612.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 646.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.32 MiB is allocated by PyTorch, and 16.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b7e6454a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 529, 'batch_size': 246, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 123.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 612.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 646.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.27 MiB is allocated by PyTorch, and 16.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1c73f784,"{'temperature_head': 0.5, 'latent_dim': 433, 'batch_size': 433, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 646.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 646.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.27 MiB is allocated by PyTorch, and 17.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
96d08c2a,"{'temperature_head': 0.9, 'latent_dim': 406, 'batch_size': 264, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 646.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 478.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.06 MiB is allocated by PyTorch, and 21.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
86ef9bf8,"{'temperature_head': 0.8, 'latent_dim': 287, 'batch_size': 443, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 646.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.12 MiB is allocated by PyTorch, and 18.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4754e017,"{'temperature_head': 0.30000000000000004, 'latent_dim': 485, 'batch_size': 250, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 686.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 678.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.68 MiB is allocated by PyTorch, and 19.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3989c600,"{'temperature_head': 0.6000000000000001, 'latent_dim': 608, 'batch_size': 320, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 656.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 678.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 478.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.65 MiB is allocated by PyTorch, and 20.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2d8dc30c,"{'temperature_head': 1.0, 'latent_dim': 544, 'batch_size': 374, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 81.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 656.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 678.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 478.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 378.12 MiB is allocated by PyTorch, and 437.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8cf60b12,"{'temperature_head': 0.7000000000000001, 'latent_dim': 513, 'batch_size': 204, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 656.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 928.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 678.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 516.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 750.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.59 MiB is allocated by PyTorch, and 59.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
83657fa5,"{'temperature_head': 0.30000000000000004, 'latent_dim': 387, 'batch_size': 326, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.19 MiB is free. Process 20917 has 1.01 GiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 656.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 678.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 726.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.91 MiB is allocated by PyTorch, and 20.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
824f10c5,"{'temperature_head': 0.9, 'latent_dim': 399, 'batch_size': 258, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 139.19 MiB is free. Process 20917 has 896.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 696.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 702.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 474.00 MiB memory in use. Process 22081 has 914.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.00 MiB is allocated by PyTorch, and 18.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
71bb60ff,"{'temperature_head': 0.4, 'latent_dim': 346, 'batch_size': 425, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.19 MiB is free. Process 20917 has 896.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 696.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 472.00 MiB memory in use. Process 22081 has 836.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.58 MiB is allocated by PyTorch, and 16.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bba4fa2e,"{'temperature_head': 1.0, 'latent_dim': 231, 'batch_size': 486, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 20917 has 896.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 648.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.22 GiB memory in use. Process 21299 has 1.04 GiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 586.00 MiB memory in use. Process 22081 has 836.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 730.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.30 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 226.68 MiB is allocated by PyTorch, and 19.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0d7f1cb8,"{'temperature_head': 0.6000000000000001, 'latent_dim': 324, 'batch_size': 334, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 133.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.53 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.23 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 744.00 MiB memory in use. Process 22081 has 870.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 774.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 806.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 270.26 MiB is allocated by PyTorch, and 133.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1403f8cc,"{'temperature_head': 0.8, 'latent_dim': 556, 'batch_size': 286, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.53 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.15 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 772.00 MiB memory in use. Process 22081 has 870.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 806.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 383.54 MiB is allocated by PyTorch, and 458.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
902844bb,"{'temperature_head': 0.9, 'latent_dim': 209, 'batch_size': 207, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.53 GiB memory in use. Process 21299 has 724.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.18 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 742.00 MiB memory in use. Process 22081 has 988.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 704.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 214.08 MiB is allocated by PyTorch, and 187.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
430a99ec,"{'temperature_head': 0.8, 'latent_dim': 586, 'batch_size': 219, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 282.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 119.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 756.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.15 GiB memory in use. Process 21681 has 1.24 GiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 970.00 MiB memory in use. Process 22081 has 1018.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 610.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 398.19 MiB is allocated by PyTorch, and 441.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
836b05b3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 413, 'batch_size': 157, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 201.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 756.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 676.00 MiB memory in use. Process 22081 has 1018.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 708.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 314.62 MiB is allocated by PyTorch, and 21.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
880473a1,"{'temperature_head': 0.4, 'latent_dim': 311, 'batch_size': 246, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 756.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 630.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 854.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 263.91 MiB is allocated by PyTorch, and 26.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8458f2fe,"{'temperature_head': 0.8, 'latent_dim': 290, 'batch_size': 379, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 125.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 630.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 854.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.26 MiB is allocated by PyTorch, and 175.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3bc66640,"{'temperature_head': 0.5, 'latent_dim': 641, 'batch_size': 300, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 123.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 632.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 854.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.80 MiB is allocated by PyTorch, and 174.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f7b8cc25,"{'temperature_head': 0.6000000000000001, 'latent_dim': 552, 'batch_size': 283, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 161.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 632.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 854.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 381.64 MiB is allocated by PyTorch, and 434.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a7b5745,"{'temperature_head': 0.7000000000000001, 'latent_dim': 662, 'batch_size': 355, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 125.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 666.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 854.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 435.32 MiB is allocated by PyTorch, and 382.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b5090f28,"{'temperature_head': 0.4, 'latent_dim': 370, 'batch_size': 207, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 163.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 628.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 854.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.89 MiB is allocated by PyTorch, and 173.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b5169c76,"{'temperature_head': 0.8, 'latent_dim': 431, 'batch_size': 229, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 127.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 730.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 630.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 854.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.37 MiB is allocated by PyTorch, and 174.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9d92621e,"{'temperature_head': 0.1, 'latent_dim': 595, 'batch_size': 315, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 181.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 662.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 774.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 402.64 MiB is allocated by PyTorch, and 413.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f0d1b7a3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 571, 'batch_size': 332, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 175.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 964.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 806.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 954.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.06 GiB memory in use. Process 22071 has 632.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 774.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.55 MiB is allocated by PyTorch, and 175.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0d09df80,"{'temperature_head': 0.6000000000000001, 'latent_dim': 323, 'batch_size': 296, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 722.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 270.52 MiB is allocated by PyTorch, and 111.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5655db77,"{'temperature_head': 0.6000000000000001, 'latent_dim': 435, 'batch_size': 266, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 780.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 325.40 MiB is allocated by PyTorch, and 114.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
66d67019,"{'temperature_head': 0.5, 'latent_dim': 338, 'batch_size': 309, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 149.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 642.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 277.98 MiB is allocated by PyTorch, and 24.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1170e73a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 364, 'batch_size': 407, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 774.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 289.80 MiB is allocated by PyTorch, and 144.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eb0cb350,"{'temperature_head': 0.8, 'latent_dim': 455, 'batch_size': 286, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 754.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 334.26 MiB is allocated by PyTorch, and 79.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
40cec14f,"{'temperature_head': 0.4, 'latent_dim': 399, 'batch_size': 506, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 117.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 672.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 308.00 MiB is allocated by PyTorch, and 24.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cf4358dd,"{'temperature_head': 0.5, 'latent_dim': 355, 'batch_size': 240, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 165.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 624.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.77 MiB is allocated by PyTorch, and 169.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a8a1df79,"{'temperature_head': 0.7000000000000001, 'latent_dim': 546, 'batch_size': 257, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 167.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 622.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.36 MiB is allocated by PyTorch, and 165.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a855b0f0,"{'temperature_head': 0.9, 'latent_dim': 467, 'batch_size': 467, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 167.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 930.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 622.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.65 MiB is allocated by PyTorch, and 166.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
425c0fcb,"{'temperature_head': 0.7000000000000001, 'latent_dim': 226, 'batch_size': 426, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 898.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 734.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 222.38 MiB is allocated by PyTorch, and 171.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cf5f9088,"{'temperature_head': 0.4, 'latent_dim': 274, 'batch_size': 431, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 898.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 734.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 245.83 MiB is allocated by PyTorch, and 148.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d9643109,"{'temperature_head': 0.8, 'latent_dim': 249, 'batch_size': 399, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 898.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 732.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 233.62 MiB is allocated by PyTorch, and 158.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d47180aa,"{'temperature_head': 0.6000000000000001, 'latent_dim': 285, 'batch_size': 372, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 898.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 732.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 251.21 MiB is allocated by PyTorch, and 140.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
20d0acf7,"{'temperature_head': 0.5, 'latent_dim': 234, 'batch_size': 276, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 91.19 MiB is free. Process 20917 has 928.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 898.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 730.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 804.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 226.29 MiB is allocated by PyTorch, and 163.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4a9e0916,"{'temperature_head': 0.7000000000000001, 'latent_dim': 582, 'batch_size': 211, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 71.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 720.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 940.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 872.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 396.39 MiB is allocated by PyTorch, and 423.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cd515efb,"{'temperature_head': 0.30000000000000004, 'latent_dim': 694, 'batch_size': 437, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 334.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 740.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 840.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 940.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 848.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 451.58 MiB is allocated by PyTorch, and 368.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
35b78672,"{'temperature_head': 0.9, 'latent_dim': 604, 'batch_size': 320, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 740.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 940.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 848.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 407.52 MiB is allocated by PyTorch, and 410.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1d748557,"{'temperature_head': 0.1, 'latent_dim': 540, 'batch_size': 480, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 211.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 740.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 798.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 848.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 376.49 MiB is allocated by PyTorch, and 81.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
17eb5dc0,"{'temperature_head': 0.8, 'latent_dim': 526, 'batch_size': 350, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 143.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 774.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 800.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 880.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 369.37 MiB is allocated by PyTorch, and 90.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7b7cc42b,"{'temperature_head': 0.9, 'latent_dim': 670, 'batch_size': 494, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 107.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 748.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 862.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 880.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 439.42 MiB is allocated by PyTorch, and 82.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c6c50e77,"{'temperature_head': 1.0, 'latent_dim': 575, 'batch_size': 401, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 748.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 858.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 880.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 392.92 MiB is allocated by PyTorch, and 125.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
338186d6,"{'temperature_head': 0.8, 'latent_dim': 651, 'batch_size': 384, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 103.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 748.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 866.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 880.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 430.01 MiB is allocated by PyTorch, and 95.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ad568322,"{'temperature_head': 0.8, 'latent_dim': 491, 'batch_size': 420, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 103.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 748.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 866.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 880.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 351.84 MiB is allocated by PyTorch, and 174.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c620410a,"{'temperature_head': 0.8, 'latent_dim': 688, 'batch_size': 511, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 97.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 748.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 872.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 880.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 448.08 MiB is allocated by PyTorch, and 83.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
142b0ac1,"{'temperature_head': 0.30000000000000004, 'latent_dim': 600, 'batch_size': 447, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 780.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 874.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 880.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 406.11 MiB is allocated by PyTorch, and 127.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c983bc82,"{'temperature_head': 0.4, 'latent_dim': 559, 'batch_size': 457, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 766.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 872.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 386.32 MiB is allocated by PyTorch, and 145.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
86d4df73,"{'temperature_head': 0.9, 'latent_dim': 618, 'batch_size': 309, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.27 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 766.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 874.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 414.21 MiB is allocated by PyTorch, and 119.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b92b0170,"{'temperature_head': 0.2, 'latent_dim': 435, 'batch_size': 463, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 766.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 876.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 324.49 MiB is allocated by PyTorch, and 211.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9e637807,"{'temperature_head': 0.30000000000000004, 'latent_dim': 536, 'batch_size': 303, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 766.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 906.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 374.38 MiB is allocated by PyTorch, and 443.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
af2ec2ea,"{'temperature_head': 0.8, 'latent_dim': 586, 'batch_size': 365, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 282.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 79.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 766.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 872.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 398.27 MiB is allocated by PyTorch, and 133.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
142279e4,"{'temperature_head': 0.4, 'latent_dim': 444, 'batch_size': 372, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 946.00 MiB memory in use. Process 20914 has 1.16 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 766.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 874.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 328.88 MiB is allocated by PyTorch, and 205.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
583ec207,"{'temperature_head': 0.8, 'latent_dim': 528, 'batch_size': 405, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 123.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.13 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 760.00 MiB memory in use. Process 21292 has 446.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.21 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 370.02 MiB is allocated by PyTorch, and 445.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
82a65af5,"{'temperature_head': 0.2, 'latent_dim': 589, 'batch_size': 261, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 810.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1012.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 400.66 MiB is allocated by PyTorch, and 281.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0004efa9,"{'temperature_head': 0.9, 'latent_dim': 394, 'batch_size': 421, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1024.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 810.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.02 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 304.46 MiB is allocated by PyTorch, and 379.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eaad064f,"{'temperature_head': 1.0, 'latent_dim': 674, 'batch_size': 472, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 810.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 441.87 MiB is allocated by PyTorch, and 216.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
744c31ac,"{'temperature_head': 0.8, 'latent_dim': 481, 'batch_size': 376, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 810.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 346.96 MiB is allocated by PyTorch, and 335.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2de5920f,"{'temperature_head': 0.8, 'latent_dim': 616, 'batch_size': 246, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.30 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 413.83 MiB is allocated by PyTorch, and 244.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c6beb4b7,"{'temperature_head': 0.9, 'latent_dim': 440, 'batch_size': 358, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 109.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1020.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 326.93 MiB is allocated by PyTorch, and 353.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8a1c4d17,"{'temperature_head': 1.0, 'latent_dim': 410, 'batch_size': 333, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 109.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1020.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 312.27 MiB is allocated by PyTorch, and 367.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
61e1ab36,"{'temperature_head': 0.2, 'latent_dim': 512, 'batch_size': 459, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 145.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1020.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 362.10 MiB is allocated by PyTorch, and 295.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e28437e9,"{'temperature_head': 0.9, 'latent_dim': 496, 'batch_size': 501, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1000.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 354.28 MiB is allocated by PyTorch, and 305.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
84eecb5e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 379, 'batch_size': 436, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 141.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1000.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 297.13 MiB is allocated by PyTorch, and 384.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
13b5e52a,"{'temperature_head': 0.8, 'latent_dim': 551, 'batch_size': 283, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 109.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 996.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 381.21 MiB is allocated by PyTorch, and 274.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9e7bf062,"{'temperature_head': 0.4, 'latent_dim': 368, 'batch_size': 268, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 109.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 792.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 996.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 291.75 MiB is allocated by PyTorch, and 364.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d735be8b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 597, 'batch_size': 252, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 996.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 403.62 MiB is allocated by PyTorch, and 252.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e5baba9c,"{'temperature_head': 0.8, 'latent_dim': 533, 'batch_size': 235, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 371.96 MiB is allocated by PyTorch, and 286.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8a6ae95d,"{'temperature_head': 1.0, 'latent_dim': 653, 'batch_size': 450, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 996.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 430.58 MiB is allocated by PyTorch, and 225.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
34635bef,"{'temperature_head': 0.4, 'latent_dim': 567, 'batch_size': 345, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 996.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 388.63 MiB is allocated by PyTorch, and 267.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
671b4a06,"{'temperature_head': 0.7000000000000001, 'latent_dim': 607, 'batch_size': 367, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 408.11 MiB is allocated by PyTorch, and 249.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
61545ba5,"{'temperature_head': 0.9, 'latent_dim': 406, 'batch_size': 289, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 310.32 MiB is allocated by PyTorch, and 371.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f274741d,"{'temperature_head': 0.4, 'latent_dim': 430, 'batch_size': 171, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 322.04 MiB is allocated by PyTorch, and 335.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4bcbb819,"{'temperature_head': 0.8, 'latent_dim': 487, 'batch_size': 511, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1000.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 349.89 MiB is allocated by PyTorch, and 310.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
df47cfb0,"{'temperature_head': 0.2, 'latent_dim': 514, 'batch_size': 326, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 20917 has 882.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 362.75 MiB is allocated by PyTorch, and 319.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4f7ba9d2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 458, 'batch_size': 257, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 850.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 335.72 MiB is allocated by PyTorch, and 322.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
07190ca8,"{'temperature_head': 0.7000000000000001, 'latent_dim': 545, 'batch_size': 491, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 850.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 378.12 MiB is allocated by PyTorch, and 303.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
de88f445,"{'temperature_head': 0.5, 'latent_dim': 632, 'batch_size': 478, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1000.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 850.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 421.56 MiB is allocated by PyTorch, and 238.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2deb7dc2,"{'temperature_head': 0.4, 'latent_dim': 503, 'batch_size': 226, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 107.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 850.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 357.70 MiB is allocated by PyTorch, and 324.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
132d2d6e,"{'temperature_head': 1.0, 'latent_dim': 584, 'batch_size': 398, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 282.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.03 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 850.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 397.96 MiB is allocated by PyTorch, and 260.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92c584de,"{'temperature_head': 0.9, 'latent_dim': 662, 'batch_size': 302, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 826.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.01 GiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 850.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 435.38 MiB is allocated by PyTorch, and 246.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3d1f3395,"{'temperature_head': 0.5, 'latent_dim': 368, 'batch_size': 464, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 920.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 998.00 MiB memory in use. Process 22081 has 1020.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 850.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 291.75 MiB is allocated by PyTorch, and 366.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0802c72a,"{'temperature_head': 0.9, 'latent_dim': 568, 'batch_size': 316, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1022.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.31 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 922.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 926.00 MiB memory in use. Process 22081 has 990.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 389.72 MiB is allocated by PyTorch, and 292.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
be44fc88,"{'temperature_head': 0.2, 'latent_dim': 683, 'batch_size': 149, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.01 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.33 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 922.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 960.00 MiB memory in use. Process 22081 has 990.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 445.64 MiB is allocated by PyTorch, and 248.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4cbcf88c,"{'temperature_head': 0.7000000000000001, 'latent_dim': 448, 'batch_size': 129, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.04 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.33 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 880.00 MiB memory in use. Process 22081 has 1024.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 330.83 MiB is allocated by PyTorch, and 209.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26b557ac,"{'temperature_head': 0.4, 'latent_dim': 719, 'batch_size': 433, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.02 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.33 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 880.00 MiB memory in use. Process 22081 has 1024.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 463.64 MiB is allocated by PyTorch, and 244.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
61aefb7b,"{'temperature_head': 0.8, 'latent_dim': 406, 'batch_size': 390, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.02 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.33 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 880.00 MiB memory in use. Process 22081 has 1024.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 310.32 MiB is allocated by PyTorch, and 229.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
94174f09,"{'temperature_head': 0.9, 'latent_dim': 366, 'batch_size': 447, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 155.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.06 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 670.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1024.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 292.25 MiB is allocated by PyTorch, and 39.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
60d18c6b,"{'temperature_head': 0.1, 'latent_dim': 519, 'batch_size': 334, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 155.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.02 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 704.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1024.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 365.70 MiB is allocated by PyTorch, and 342.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
19f4593c,"{'temperature_head': 0.4, 'latent_dim': 607, 'batch_size': 309, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 199.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.06 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 624.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1024.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.16 MiB is allocated by PyTorch, and 167.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d198786d,"{'temperature_head': 0.5, 'latent_dim': 473, 'batch_size': 485, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 199.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.02 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 660.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1024.00 MiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 343.05 MiB is allocated by PyTorch, and 364.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d9ab1639,"{'temperature_head': 0.7000000000000001, 'latent_dim': 492, 'batch_size': 359, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 231.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.02 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 626.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.36 MiB is allocated by PyTorch, and 171.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b392ffe4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 262, 'batch_size': 472, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.55 MiB is allocated by PyTorch, and 169.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1135f378,"{'temperature_head': 0.6000000000000001, 'latent_dim': 288, 'batch_size': 452, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 626.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.76 MiB is allocated by PyTorch, and 173.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ae48d080,"{'temperature_head': 0.7000000000000001, 'latent_dim': 317, 'batch_size': 441, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.98 MiB is allocated by PyTorch, and 169.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0d265d0e,"{'temperature_head': 0.6000000000000001, 'latent_dim': 333, 'batch_size': 461, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 626.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.11 MiB is allocated by PyTorch, and 172.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9cd685c2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 250, 'batch_size': 418, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 624.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 882.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.46 MiB is allocated by PyTorch, and 171.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0863e8fb,"{'temperature_head': 0.5, 'latent_dim': 301, 'batch_size': 429, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 884.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.86 MiB is allocated by PyTorch, and 169.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
699ee8b7,"{'temperature_head': 0.6000000000000001, 'latent_dim': 219, 'batch_size': 402, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 626.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 888.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 884.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.21 MiB is allocated by PyTorch, and 173.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6b343781,"{'temperature_head': 0.8, 'latent_dim': 534, 'batch_size': 448, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 221.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 828.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 852.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 884.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 374.19 MiB is allocated by PyTorch, and 139.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d5e69394,"{'temperature_head': 0.6000000000000001, 'latent_dim': 401, 'batch_size': 442, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 191.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 670.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.01 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 886.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 308.76 MiB is allocated by PyTorch, and 21.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b10069b4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 593, 'batch_size': 393, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 201.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 624.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 886.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.71 MiB is allocated by PyTorch, and 167.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b3ca6f87,"{'temperature_head': 0.8, 'latent_dim': 433, 'batch_size': 456, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 203.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 622.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 954.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 886.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.39 MiB is allocated by PyTorch, and 166.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
deaeaca8,"{'temperature_head': 0.5, 'latent_dim': 561, 'batch_size': 289, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 235.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 622.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 922.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 886.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.39 MiB is allocated by PyTorch, and 165.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bc61563a,"{'temperature_head': 0.4, 'latent_dim': 326, 'batch_size': 510, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 782.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 922.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 886.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 271.24 MiB is allocated by PyTorch, and 170.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9c3cab56,"{'temperature_head': 0.9, 'latent_dim': 415, 'batch_size': 383, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 788.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 922.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 856.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 315.24 MiB is allocated by PyTorch, and 132.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
66c77e72,"{'temperature_head': 0.5, 'latent_dim': 362, 'batch_size': 404, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 792.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 922.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 856.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 288.82 MiB is allocated by PyTorch, and 163.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
217ce5f5,"{'temperature_head': 0.4, 'latent_dim': 273, 'batch_size': 425, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 97.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 788.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 922.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 856.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 245.34 MiB is allocated by PyTorch, and 202.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
05813039,"{'temperature_head': 0.8, 'latent_dim': 547, 'batch_size': 278, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 261.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 590.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 856.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.33 MiB is allocated by PyTorch, and 133.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
489c6226,"{'temperature_head': 0.5, 'latent_dim': 641, 'batch_size': 246, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 229.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 590.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 888.00 MiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.96 MiB is allocated by PyTorch, and 132.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
445b57b4,"{'temperature_head': 0.9, 'latent_dim': 306, 'batch_size': 253, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 590.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.39 MiB is allocated by PyTorch, and 135.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a6432c81,"{'temperature_head': 0.6000000000000001, 'latent_dim': 244, 'batch_size': 272, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 588.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 113.90 MiB is allocated by PyTorch, and 134.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7b56f260,"{'temperature_head': 0.30000000000000004, 'latent_dim': 341, 'batch_size': 331, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 588.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.66 MiB is allocated by PyTorch, and 133.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
268053ef,"{'temperature_head': 0.7000000000000001, 'latent_dim': 507, 'batch_size': 449, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 592.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.97 MiB is allocated by PyTorch, and 136.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7b499ecd,"{'temperature_head': 0.4, 'latent_dim': 423, 'batch_size': 511, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 590.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.31 MiB is allocated by PyTorch, and 134.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1a075a29,"{'temperature_head': 0.8, 'latent_dim': 388, 'batch_size': 317, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 586.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.03 MiB is allocated by PyTorch, and 130.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c8c5bec2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 228, 'batch_size': 411, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.19 MiB is free. Process 20917 has 850.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 588.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 113.77 MiB is allocated by PyTorch, and 134.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cf17dd6b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 596, 'batch_size': 438, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 592.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.87 MiB is allocated by PyTorch, and 134.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3c9c1181,"{'temperature_head': 1.0, 'latent_dim': 439, 'batch_size': 366, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 590.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.43 MiB is allocated by PyTorch, and 134.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fbe32687,"{'temperature_head': 0.6000000000000001, 'latent_dim': 401, 'batch_size': 350, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 588.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.13 MiB is allocated by PyTorch, and 132.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d6f196d9,"{'temperature_head': 0.7000000000000001, 'latent_dim': 314, 'batch_size': 232, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 586.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.45 MiB is allocated by PyTorch, and 131.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
74099b70,"{'temperature_head': 0.5, 'latent_dim': 295, 'batch_size': 457, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 590.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.30 MiB is allocated by PyTorch, and 135.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
574b63fa,"{'temperature_head': 0.8, 'latent_dim': 581, 'batch_size': 485, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.19 MiB is free. Process 20917 has 884.00 MiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 588.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.05 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.35 MiB is allocated by PyTorch, and 130.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
92203749,"{'temperature_head': 0.4, 'latent_dim': 623, 'batch_size': 325, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 127.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 488.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.74 MiB is allocated by PyTorch, and 29.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e4fbd902,"{'temperature_head': 0.7000000000000001, 'latent_dim': 355, 'batch_size': 280, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 129.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 486.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.63 MiB is allocated by PyTorch, and 29.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a78d3f4e,"{'temperature_head': 0.9, 'latent_dim': 377, 'batch_size': 501, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 125.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 490.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 734.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.80 MiB is allocated by PyTorch, and 33.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ce60060a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 331, 'batch_size': 339, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 488.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.44 MiB is allocated by PyTorch, and 31.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
21bdb74d,"{'temperature_head': 0.4, 'latent_dim': 555, 'batch_size': 389, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 488.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.46 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.21 MiB is allocated by PyTorch, and 29.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b1263dc5,"{'temperature_head': 0.30000000000000004, 'latent_dim': 481, 'batch_size': 462, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 730.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 349.16 MiB is allocated by PyTorch, and 40.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ff1f68fc,"{'temperature_head': 0.7000000000000001, 'latent_dim': 464, 'batch_size': 302, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 722.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 341.02 MiB is allocated by PyTorch, and 40.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9d7ddf30,"{'temperature_head': 0.5, 'latent_dim': 354, 'batch_size': 267, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 668.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 286.31 MiB is allocated by PyTorch, and 41.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ac9a2d06,"{'temperature_head': 1.0, 'latent_dim': 658, 'batch_size': 415, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 109.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 624.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.67 MiB is allocated by PyTorch, and 166.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c6863308,"{'temperature_head': 0.7000000000000001, 'latent_dim': 566, 'batch_size': 246, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.50 MiB is allocated by PyTorch, and 164.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
238cad5e,"{'temperature_head': 0.6000000000000001, 'latent_dim': 441, 'batch_size': 474, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.96 MiB is allocated by PyTorch, and 166.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ac51602a,"{'temperature_head': 0.8, 'latent_dim': 337, 'batch_size': 422, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 620.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 966.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.14 MiB is allocated by PyTorch, and 164.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3dbfd7f7,"{'temperature_head': 0.6000000000000001, 'latent_dim': 395, 'batch_size': 450, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 109.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.60 MiB is allocated by PyTorch, and 166.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3835f1ab,"{'temperature_head': 0.30000000000000004, 'latent_dim': 365, 'batch_size': 274, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 620.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.26 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.36 MiB is allocated by PyTorch, and 164.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f243079f,"{'temperature_head': 0.5, 'latent_dim': 531, 'batch_size': 441, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 71.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 626.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.67 MiB is allocated by PyTorch, and 169.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0d8c2bd9,"{'temperature_head': 0.9, 'latent_dim': 320, 'batch_size': 511, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 620.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.01 MiB is allocated by PyTorch, and 164.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f902eabc,"{'temperature_head': 0.4, 'latent_dim': 637, 'batch_size': 240, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 79.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 618.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.50 MiB is allocated by PyTorch, and 160.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e9030416,"{'temperature_head': 0.5, 'latent_dim': 675, 'batch_size': 311, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 944.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 624.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.80 MiB is allocated by PyTorch, and 166.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fcb86346,"{'temperature_head': 0.8, 'latent_dim': 581, 'batch_size': 355, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 920.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.45 MiB is allocated by PyTorch, and 164.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
caf9eea7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 382, 'batch_size': 486, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 920.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.50 MiB is allocated by PyTorch, and 166.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
875eda81,"{'temperature_head': 0.5, 'latent_dim': 470, 'batch_size': 195, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 920.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 620.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.19 MiB is allocated by PyTorch, and 163.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9b8e033a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 485, 'batch_size': 375, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 920.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.31 MiB is allocated by PyTorch, and 165.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e0c90711,"{'temperature_head': 0.8, 'latent_dim': 696, 'batch_size': 434, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 920.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.75 MiB is allocated by PyTorch, and 163.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2fea3415,"{'temperature_head': 0.4, 'latent_dim': 410, 'batch_size': 504, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 954.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.72 MiB is allocated by PyTorch, and 166.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fc3b0c02,"{'temperature_head': 0.8, 'latent_dim': 597, 'batch_size': 478, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 954.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 620.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.19 MiB is allocated by PyTorch, and 162.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3f5e0659,"{'temperature_head': 0.9, 'latent_dim': 568, 'batch_size': 447, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 954.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 620.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.96 MiB is allocated by PyTorch, and 163.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
05ddd76a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 369, 'batch_size': 494, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 954.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.39 MiB is allocated by PyTorch, and 166.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
342cbf63,"{'temperature_head': 0.2, 'latent_dim': 350, 'batch_size': 421, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 954.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 624.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.24 MiB is allocated by PyTorch, and 168.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
189656d0,"{'temperature_head': 0.7000000000000001, 'latent_dim': 518, 'batch_size': 305, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 956.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 622.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.93 MiB is allocated by PyTorch, and 165.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9e440839,"{'temperature_head': 0.4, 'latent_dim': 496, 'batch_size': 337, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 177.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 808.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 656.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 354.28 MiB is allocated by PyTorch, and 113.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f0f84460,"{'temperature_head': 1.0, 'latent_dim': 336, 'batch_size': 283, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 842.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 786.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 277.13 MiB is allocated by PyTorch, and 168.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9d9c640,"{'temperature_head': 0.6000000000000001, 'latent_dim': 617, 'batch_size': 252, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 285.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 866.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 490.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 413.40 MiB is allocated by PyTorch, and 112.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4b010ede,"{'temperature_head': 0.5, 'latent_dim': 450, 'batch_size': 270, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 900.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 714.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 333.21 MiB is allocated by PyTorch, and 40.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a94f8bc1,"{'temperature_head': 0.1, 'latent_dim': 470, 'batch_size': 429, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 900.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 722.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 343.07 MiB is allocated by PyTorch, and 38.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
84ee9dba,"{'temperature_head': 0.5, 'latent_dim': 260, 'batch_size': 369, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 123.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 900.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 618.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 240.39 MiB is allocated by PyTorch, and 37.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1eaa0f16,"{'temperature_head': 1.0, 'latent_dim': 282, 'batch_size': 453, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 902.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 706.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 250.71 MiB is allocated by PyTorch, and 115.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9c2ddacf,"{'temperature_head': 0.30000000000000004, 'latent_dim': 529, 'batch_size': 180, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.07 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 506.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.54 MiB is allocated by PyTorch, and 48.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
480ca673,"{'temperature_head': 0.7000000000000001, 'latent_dim': 648, 'batch_size': 483, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.07 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 504.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.67 MiB is allocated by PyTorch, and 45.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2dd3d7bd,"{'temperature_head': 0.7000000000000001, 'latent_dim': 118, 'batch_size': 294, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.07 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 508.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.24 MiB is allocated by PyTorch, and 53.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f257c124,"{'temperature_head': 0.8, 'latent_dim': 194, 'batch_size': 440, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.07 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 496.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.90 MiB is allocated by PyTorch, and 41.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2c3405d9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 149, 'batch_size': 311, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.07 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 496.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.55 MiB is allocated by PyTorch, and 41.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
17c69b06,"{'temperature_head': 0.2, 'latent_dim': 510, 'batch_size': 278, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.07 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 496.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.39 MiB is allocated by PyTorch, and 38.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
71de7e8d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 561, 'batch_size': 317, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.08 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 496.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 118.79 MiB is allocated by PyTorch, and 37.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4a863799,"{'temperature_head': 0.8, 'latent_dim': 300, 'batch_size': 288, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.08 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 494.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.73 MiB is allocated by PyTorch, and 38.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
37c5d970,"{'temperature_head': 0.4, 'latent_dim': 329, 'batch_size': 270, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.08 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 498.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.96 MiB is allocated by PyTorch, and 42.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7875f620,"{'temperature_head': 0.5, 'latent_dim': 226, 'batch_size': 362, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.08 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 498.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.15 MiB is allocated by PyTorch, and 42.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
87acf427,"{'temperature_head': 0.7000000000000001, 'latent_dim': 459, 'batch_size': 226, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.08 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 500.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.98 MiB is allocated by PyTorch, and 43.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ad6853c4,"{'temperature_head': 1.0, 'latent_dim': 271, 'batch_size': 473, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.08 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 498.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.51 MiB is allocated by PyTorch, and 42.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
accac4dc,"{'temperature_head': 0.9, 'latent_dim': 575, 'batch_size': 435, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.08 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 494.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.90 MiB is allocated by PyTorch, and 36.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7dc27309,"{'temperature_head': 0.5, 'latent_dim': 396, 'batch_size': 249, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 668.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 906.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 306.32 MiB is allocated by PyTorch, and 21.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0cc23046,"{'temperature_head': 0.9, 'latent_dim': 544, 'batch_size': 459, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 622.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 906.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.44 MiB is allocated by PyTorch, and 165.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c58d4c60,"{'temperature_head': 0.4, 'latent_dim': 374, 'batch_size': 238, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 624.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 906.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.92 MiB is allocated by PyTorch, and 169.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5c8c62b0,"{'temperature_head': 0.7000000000000001, 'latent_dim': 628, 'batch_size': 305, 'transform_funcs': (8,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 622.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 906.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.92 MiB is allocated by PyTorch, and 165.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8dd1f1af,"{'temperature_head': 0.5, 'latent_dim': 415, 'batch_size': 419, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 115.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 620.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 906.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.24 MiB is allocated by PyTorch, and 164.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b27a80a3,"{'temperature_head': 0.7000000000000001, 'latent_dim': 285, 'batch_size': 482, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 115.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 620.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 906.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.22 MiB is allocated by PyTorch, and 165.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a13c08d4,"{'temperature_head': 0.8, 'latent_dim': 607, 'batch_size': 445, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 199.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 656.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 786.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.29 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 410.15 MiB is allocated by PyTorch, and 35.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d474eb40,"{'temperature_head': 0.30000000000000004, 'latent_dim': 535, 'batch_size': 218, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 622.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 958.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.71 MiB is allocated by PyTorch, and 165.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
88796f51,"{'temperature_head': 0.4, 'latent_dim': 443, 'batch_size': 266, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 622.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 958.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.46 MiB is allocated by PyTorch, and 166.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3f02fbef,"{'temperature_head': 0.8, 'latent_dim': 477, 'batch_size': 380, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 620.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 958.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.73 MiB is allocated by PyTorch, and 164.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2f20c549,"{'temperature_head': 0.5, 'latent_dim': 313, 'batch_size': 464, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 620.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 958.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.44 MiB is allocated by PyTorch, and 165.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
837c5716,"{'temperature_head': 0.9, 'latent_dim': 555, 'batch_size': 278, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 624.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 958.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.36 MiB is allocated by PyTorch, and 167.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
39dbbd36,"{'temperature_head': 0.9, 'latent_dim': 389, 'batch_size': 494, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 624.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 958.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.04 MiB is allocated by PyTorch, and 168.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
879baeb4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 208, 'batch_size': 323, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 622.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 958.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 213.59 MiB is allocated by PyTorch, and 68.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6ec5a8bd,"{'temperature_head': 0.8, 'latent_dim': 296, 'batch_size': 428, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.12 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 430.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.31 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 43.24 MiB is allocated by PyTorch, and 46.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0c7eb437,"{'temperature_head': 0.5, 'latent_dim': 363, 'batch_size': 286, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 147.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.12 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.16 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.72 MiB is allocated by PyTorch, and 20.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4c6748a2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 432, 'batch_size': 511, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 147.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.12 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.16 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.26 MiB is allocated by PyTorch, and 19.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
26b57004,"{'temperature_head': 0.8, 'latent_dim': 344, 'batch_size': 476, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 145.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.12 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.16 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 478.00 MiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.57 MiB is allocated by PyTorch, and 22.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ae4b494e,"{'temperature_head': 0.4, 'latent_dim': 269, 'batch_size': 369, 'transform_funcs': (0,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.12 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.16 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 608.00 MiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 244.98 MiB is allocated by PyTorch, and 23.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7fa2a88a,"{'temperature_head': 0.2, 'latent_dim': 451, 'batch_size': 313, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 147.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.12 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.16 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 116.41 MiB is allocated by PyTorch, and 19.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d12e79ae,"{'temperature_head': 0.6000000000000001, 'latent_dim': 527, 'batch_size': 456, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.16 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 476.00 MiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 117.43 MiB is allocated by PyTorch, and 18.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
edd6fa72,"{'temperature_head': 0.5, 'latent_dim': 328, 'batch_size': 232, 'transform_funcs': (11,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 492.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.95 MiB is allocated by PyTorch, and 36.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0737ba8a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 307, 'batch_size': 206, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 490.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.79 MiB is allocated by PyTorch, and 34.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e21fef76,"{'temperature_head': 0.6000000000000001, 'latent_dim': 3, 'batch_size': 236, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 492.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 113.40 MiB is allocated by PyTorch, and 38.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a228c78d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 282, 'batch_size': 228, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 494.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.59 MiB is allocated by PyTorch, and 38.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f54139fc,"{'temperature_head': 0.6000000000000001, 'latent_dim': 222, 'batch_size': 249, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 496.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.12 MiB is allocated by PyTorch, and 40.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
88f4d1f2,"{'temperature_head': 0.5, 'latent_dim': 182, 'batch_size': 180, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 496.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.81 MiB is allocated by PyTorch, and 41.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b871f0e3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 291, 'batch_size': 257, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.21 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 492.00 MiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.66 MiB is allocated by PyTorch, and 36.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9d9315f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 266, 'batch_size': 186, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 476.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.95 MiB is allocated by PyTorch, and 21.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
34ca2d1f,"{'temperature_head': 0.5, 'latent_dim': 307, 'batch_size': 266, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 472.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.28 MiB is allocated by PyTorch, and 16.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
eb02de93,"{'temperature_head': 0.7000000000000001, 'latent_dim': 351, 'batch_size': 250, 'transform_funcs': (1,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 478.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.62 MiB is allocated by PyTorch, and 22.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2d7885e9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 379, 'batch_size': 287, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 478.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.84 MiB is allocated by PyTorch, and 22.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7f2a1e31,"{'temperature_head': 0.5, 'latent_dim': 264, 'batch_size': 146, 'transform_funcs': (5,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 476.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.94 MiB is allocated by PyTorch, and 21.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
50a890b2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 163, 'batch_size': 226, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 554.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 192.49 MiB is allocated by PyTorch, and 21.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e38ef8a5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 225, 'batch_size': 256, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 476.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.63 MiB is allocated by PyTorch, and 21.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d987d753,"{'temperature_head': 0.7000000000000001, 'latent_dim': 236, 'batch_size': 168, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 476.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 114.72 MiB is allocated by PyTorch, and 21.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
60d64cd0,"{'temperature_head': 0.8, 'latent_dim': 320, 'batch_size': 154, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 91.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 474.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.38 MiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f43f8ff9,"{'temperature_head': 0.7000000000000001, 'latent_dim': 280, 'batch_size': 195, 'transform_funcs': (10,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 91.19 MiB is free. Process 20917 has 1.02 GiB memory in use. Process 20915 has 642.00 MiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 474.00 MiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 1.17 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21295 has 642.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 21693 has 842.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 1.17 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22084 has 824.00 MiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 968.00 MiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.25 GiB memory in use. Process 22471 has 644.00 MiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 115.06 MiB is allocated by PyTorch, and 18.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5f12ba81,"{'temperature_head': 0.7000000000000001, 'latent_dim': 631, 'batch_size': 503, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 127.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.10 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 420.23 MiB is allocated by PyTorch, and 361.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3146614f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 670, 'batch_size': 426, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 129.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.09 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 440.06 MiB is allocated by PyTorch, and 339.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d0e5f87f,"{'temperature_head': 0.8, 'latent_dim': 691, 'batch_size': 154, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 334.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 127.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.10 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 450.20 MiB is allocated by PyTorch, and 331.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
14d8d768,"{'temperature_head': 0.6000000000000001, 'latent_dim': 524, 'batch_size': 400, 'transform_funcs': (3,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 127.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.10 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 368.21 MiB is allocated by PyTorch, and 413.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3b1d9836,"{'temperature_head': 0.4, 'latent_dim': 542, 'batch_size': 386, 'transform_funcs': (7,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 129.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.09 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 376.36 MiB is allocated by PyTorch, and 403.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
db013738,"{'temperature_head': 0.8, 'latent_dim': 570, 'batch_size': 200, 'transform_funcs': (9,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 131.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.09 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 390.68 MiB is allocated by PyTorch, and 387.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
352f3cd4,"{'temperature_head': 0.9, 'latent_dim': 621, 'batch_size': 186, 'transform_funcs': (2,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 129.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.09 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 415.35 MiB is allocated by PyTorch, and 364.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a62083ac,"{'temperature_head': 0.9, 'latent_dim': 555, 'batch_size': 193, 'transform_funcs': (4,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 131.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.09 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 383.47 MiB is allocated by PyTorch, and 394.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bc4b1961,"{'temperature_head': 0.7000000000000001, 'latent_dim': 573, 'batch_size': 327, 'transform_funcs': (6,)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 133.88 MiB is free. Process 20917 has 1.03 GiB memory in use. Process 20913 has 858.00 MiB memory in use. Process 20914 has 1.09 GiB memory in use. Process 20912 has 894.00 MiB memory in use. Process 21287 has 1.36 GiB memory in use. Process 21296 has 2.37 GiB memory in use. Process 21299 has 762.00 MiB memory in use. Process 21292 has 890.00 MiB memory in use. Process 21684 has 1.57 GiB memory in use. Process 21681 has 956.00 MiB memory in use. Process 21690 has 956.00 MiB memory in use. Process 21689 has 834.00 MiB memory in use. Process 22075 has 1.28 GiB memory in use. Process 22071 has 2.24 GiB memory in use. Process 22081 has 1.00 GiB memory in use. Process 22080 has 906.00 MiB memory in use. Process 22462 has 1.16 GiB memory in use. Process 22468 has 1.03 GiB memory in use. Process 22465 has 1.62 GiB memory in use. Process 22507 has 856.00 MiB memory in use. Of the allocated memory 392.12 MiB is allocated by PyTorch, and 383.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
