trial_id,config,error_type,error_message,error_traceback
2c04af36,"{'temperature_head': 0.2, 'latent_dim': 627, 'batch_size': 436, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 246.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.04 GiB memory in use. Process 25580 has 762.00 MiB memory in use. Process 25542 has 1.43 GiB memory in use. Process 25586 has 672.00 MiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.10 GiB memory in use. Process 28798 has 770.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 1008.00 MiB memory in use. Process 28792 has 836.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 976.00 MiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 782.00 MiB memory in use. Process 29188 has 878.00 MiB memory in use. Process 29577 has 878.00 MiB memory in use. Process 29574 has 864.00 MiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 714.00 MiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.06 GiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 510.40 MiB is allocated by PyTorch, and 29.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4937069e,"{'temperature_head': 0.8, 'latent_dim': 435, 'batch_size': 344, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 210.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.04 GiB memory in use. Process 25580 has 762.00 MiB memory in use. Process 25542 has 1.43 GiB memory in use. Process 25586 has 720.00 MiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.10 GiB memory in use. Process 28798 has 812.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 1008.00 MiB memory in use. Process 28792 has 836.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 976.00 MiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 782.00 MiB memory in use. Process 29188 has 824.00 MiB memory in use. Process 29577 has 878.00 MiB memory in use. Process 29574 has 864.00 MiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 714.00 MiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.06 GiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 393.91 MiB is allocated by PyTorch, and 92.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9d54085,"{'temperature_head': 0.7000000000000001, 'latent_dim': 684, 'batch_size': 194, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 930.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 1.30 GiB memory in use. Process 25586 has 862.00 MiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.39 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 904.00 MiB memory in use. Process 28792 has 920.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 962.00 MiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 824.00 MiB memory in use. Process 29577 has 422.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 784.00 MiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.01 GiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 139.37 MiB is allocated by PyTorch, and 346.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4d8763bb,"{'temperature_head': 0.30000000000000004, 'latent_dim': 213, 'batch_size': 277, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 1.30 GiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.39 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 904.00 MiB memory in use. Process 28792 has 920.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 962.00 MiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 468.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 786.00 MiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.01 GiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 135.51 MiB is allocated by PyTorch, and 36.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d1ca21b6,"{'temperature_head': 0.30000000000000004, 'latent_dim': 516, 'batch_size': 451, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 154.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 1.30 GiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.39 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 468.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 716.00 MiB memory in use. Process 29195 has 962.00 MiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 628.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.05 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 137.88 MiB is allocated by PyTorch, and 34.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6056309c,"{'temperature_head': 0.9, 'latent_dim': 456, 'batch_size': 154, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 164.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 1.30 GiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.39 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 504.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 716.00 MiB memory in use. Process 29195 has 962.00 MiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 628.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.05 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 984.00 MiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 406.90 MiB is allocated by PyTorch, and 239.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
74a67184,"{'temperature_head': 0.4, 'latent_dim': 327, 'batch_size': 258, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 1.30 GiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.39 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 552.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 716.00 MiB memory in use. Process 29195 has 966.00 MiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 628.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.05 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.00 GiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 136.40 MiB is allocated by PyTorch, and 33.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c952946b,"{'temperature_head': 1.0, 'latent_dim': 385, 'batch_size': 211, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.39 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 716.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 800.00 MiB memory in use. Process 29577 has 628.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.05 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.00 GiB memory in use. Process 29972 has 1014.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 136.86 MiB is allocated by PyTorch, and 37.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cb53013d,"{'temperature_head': 1.0, 'latent_dim': 382, 'batch_size': 389, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 646.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.43 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 648.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 800.00 MiB memory in use. Process 29577 has 562.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 982.00 MiB memory in use. Process 29972 has 922.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 362.16 MiB is allocated by PyTorch, and 281.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9fc38a53,"{'temperature_head': 0.9, 'latent_dim': 581, 'batch_size': 418, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 646.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 648.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 854.00 MiB memory in use. Process 29577 has 608.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 430.00 MiB memory in use. Process 29972 has 922.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 482.39 MiB is allocated by PyTorch, and 33.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
adcb9261,"{'temperature_head': 0.8, 'latent_dim': 50, 'batch_size': 132, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 692.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 450.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 900.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 420.00 MiB memory in use. Process 29972 has 922.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 45.76 MiB is allocated by PyTorch, and 36.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
776b3935,"{'temperature_head': 0.7000000000000001, 'latent_dim': 248, 'batch_size': 176, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 692.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 450.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 900.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 922.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 66.21 MiB is allocated by PyTorch, and 19.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dfcf7a02,"{'temperature_head': 0.5, 'latent_dim': 172, 'batch_size': 242, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 622.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 450.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 900.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 922.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 236.68 MiB is allocated by PyTorch, and 47.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
957d6eb2,"{'temperature_head': 0.9, 'latent_dim': 346, 'batch_size': 380, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 784.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 900.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 922.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 136.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
67e30a4b,"{'temperature_head': 0.5, 'latent_dim': 570, 'batch_size': 292, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 674.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 900.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 1.60 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 922.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 138.30 MiB is allocated by PyTorch, and 33.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
467a8456,"{'temperature_head': 1.0, 'latent_dim': 268, 'batch_size': 215, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 674.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 900.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 135.94 MiB is allocated by PyTorch, and 36.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f8b0f71e,"{'temperature_head': 0.9, 'latent_dim': 54, 'batch_size': 230, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 674.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 900.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 470.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 134.27 MiB is allocated by PyTorch, and 37.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
34625fea,"{'temperature_head': 0.8, 'latent_dim': 159, 'batch_size': 147, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 674.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 616.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 902.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 510.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 135.09 MiB is allocated by PyTorch, and 34.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26522009,"{'temperature_head': 0.7000000000000001, 'latent_dim': 225, 'batch_size': 176, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 674.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 616.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 902.00 MiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 554.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 47.13 MiB is allocated by PyTorch, and 38.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1970b120,"{'temperature_head': 0.9, 'latent_dim': 75, 'batch_size': 198, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 672.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 422.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 658.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 78.43 MiB is allocated by PyTorch, and 35.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4f6e38dd,"{'temperature_head': 1.0, 'latent_dim': 203, 'batch_size': 165, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 776.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 672.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 422.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 658.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 79.43 MiB is allocated by PyTorch, and 36.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
831e1427,"{'temperature_head': 0.6000000000000001, 'latent_dim': 419, 'batch_size': 315, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 976.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 672.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 470.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 660.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 137.12 MiB is allocated by PyTorch, and 36.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ade6ce31,"{'temperature_head': 0.7000000000000001, 'latent_dim': 137, 'batch_size': 129, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 470.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 672.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 506.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 660.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 78.92 MiB is allocated by PyTorch, and 33.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e3ec4c30,"{'temperature_head': 0.9, 'latent_dim': 309, 'batch_size': 186, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.03 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 470.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 826.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 80.26 MiB is allocated by PyTorch, and 33.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ff8b13d0,"{'temperature_head': 1.0, 'latent_dim': 244, 'batch_size': 268, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 962.00 MiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.10 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 826.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 135.75 MiB is allocated by PyTorch, and 32.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8d111bda,"{'temperature_head': 0.4, 'latent_dim': 29, 'batch_size': 325, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 962.00 MiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 966.00 MiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.07 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 566.00 MiB memory in use. Process 29972 has 826.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 78.07 MiB is allocated by PyTorch, and 31.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7d01f2d8,"{'temperature_head': 1.0, 'latent_dim': 516, 'batch_size': 296, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 470.00 MiB memory in use. Process 25586 has 962.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 878.00 MiB memory in use. Process 28792 has 968.00 MiB memory in use. Process 29194 has 622.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.07 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 814.00 MiB memory in use. Process 29972 has 452.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 444.28 MiB is allocated by PyTorch, and 31.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
39cf85b0,"{'temperature_head': 0.6000000000000001, 'latent_dim': 354, 'batch_size': 211, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 962.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 878.00 MiB memory in use. Process 28792 has 968.00 MiB memory in use. Process 29194 has 622.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.07 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 864.00 MiB memory in use. Process 29972 has 452.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 136.61 MiB is allocated by PyTorch, and 33.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8df0cb3b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 392, 'batch_size': 370, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 172.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 884.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 962.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 878.00 MiB memory in use. Process 28792 has 782.00 MiB memory in use. Process 29194 has 622.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.07 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 764.00 MiB memory in use. Process 29972 has 612.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 368.16 MiB is allocated by PyTorch, and 57.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
45b1cf3a,"{'temperature_head': 0.8, 'latent_dim': 282, 'batch_size': 156, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 820.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 996.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 878.00 MiB memory in use. Process 28792 has 828.00 MiB memory in use. Process 29194 has 622.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.07 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 808.00 MiB memory in use. Process 29972 has 656.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 136.05 MiB is allocated by PyTorch, and 33.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c0869448,"{'temperature_head': 0.6000000000000001, 'latent_dim': 201, 'batch_size': 504, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 978.00 MiB memory in use. Process 25580 has 820.00 MiB memory in use. Process 25542 has 632.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 974.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 878.00 MiB memory in use. Process 28792 has 470.00 MiB memory in use. Process 29194 has 466.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 556.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.07 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 952.00 MiB memory in use. Process 29972 has 718.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 254.25 MiB is allocated by PyTorch, and 37.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a79cd506,"{'temperature_head': 0.4, 'latent_dim': 44, 'batch_size': 347, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 422.00 MiB memory in use. Process 25542 has 418.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 760.00 MiB memory in use. Process 28792 has 904.00 MiB memory in use. Process 29194 has 678.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 712.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1000.00 MiB memory in use. Process 29972 has 556.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 45.71 MiB is allocated by PyTorch, and 32.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c4100788,"{'temperature_head': 0.9, 'latent_dim': 655, 'batch_size': 369, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 434.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 760.00 MiB memory in use. Process 28792 has 904.00 MiB memory in use. Process 29194 has 678.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 712.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1000.00 MiB memory in use. Process 29972 has 556.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 71.35 MiB is allocated by PyTorch, and 10.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 22, in forward
    hidden_features_transform_1 = model(samples_transform_1)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 20, in forward
    projection_1 = self.projection_1(base_model_output)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
"
af5debf3,"{'temperature_head': 0.5, 'latent_dim': 457, 'batch_size': 306, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 432.00 MiB memory in use. Process 25542 has 410.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 760.00 MiB memory in use. Process 28792 has 904.00 MiB memory in use. Process 29194 has 678.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 932.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 712.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 946.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1000.00 MiB memory in use. Process 29972 has 556.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 65.83 MiB is allocated by PyTorch, and 4.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e1a4e9d0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 486, 'batch_size': 137, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 506.00 MiB memory in use. Process 25542 has 524.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 760.00 MiB memory in use. Process 28792 has 452.00 MiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.11 GiB memory in use. Process 29577 has 652.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 952.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 424.46 MiB is allocated by PyTorch, and 189.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8490810f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 618, 'batch_size': 256, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 556.00 MiB memory in use. Process 25542 has 524.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 670.00 MiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 652.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 139.31 MiB is allocated by PyTorch, and 44.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a3ea3cb,"{'temperature_head': 0.8, 'latent_dim': 67, 'batch_size': 269, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 556.00 MiB memory in use. Process 25542 has 572.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 670.00 MiB memory in use. Process 29194 has 712.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 606.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 418.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 45.89 MiB is allocated by PyTorch, and 34.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aab10db5,"{'temperature_head': 0.5, 'latent_dim': 339, 'batch_size': 340, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 556.00 MiB memory in use. Process 25542 has 572.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 670.00 MiB memory in use. Process 29194 has 712.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 606.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 428.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 66.12 MiB is allocated by PyTorch, and 23.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bc334859,"{'temperature_head': 1.0, 'latent_dim': 373, 'batch_size': 304, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 556.00 MiB memory in use. Process 25542 has 572.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 670.00 MiB memory in use. Process 29194 has 712.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 606.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 79.73 MiB is allocated by PyTorch, and 14.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
d468ede8,"{'temperature_head': 0.4, 'latent_dim': 718, 'batch_size': 436, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 556.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 670.00 MiB memory in use. Process 29194 has 712.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 606.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 139.72 MiB is allocated by PyTorch, and 32.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d94513e9,"{'temperature_head': 0.7000000000000001, 'latent_dim': 249, 'batch_size': 397, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.03 GiB memory in use. Process 25580 has 652.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 670.00 MiB memory in use. Process 29194 has 670.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 606.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 135.79 MiB is allocated by PyTorch, and 32.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1b618d8b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 28, 'batch_size': 162, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 556.00 MiB memory in use. Process 25580 has 888.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 670.00 MiB memory in use. Process 29194 has 670.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 698.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 654.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 682.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 930.00 MiB memory in use. Of the allocated memory 134.06 MiB is allocated by PyTorch, and 33.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6054593e,"{'temperature_head': 0.8, 'latent_dim': 111, 'batch_size': 224, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 556.00 MiB memory in use. Process 25580 has 888.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 452.00 MiB memory in use. Process 29194 has 718.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 698.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 820.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 682.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 932.00 MiB memory in use. Of the allocated memory 134.71 MiB is allocated by PyTorch, and 31.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3527e997,"{'temperature_head': 0.9, 'latent_dim': 684, 'batch_size': 178, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 406.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 176.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 888.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 466.00 MiB memory in use. Process 29194 has 690.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 744.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 820.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 524.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 932.00 MiB memory in use. Of the allocated memory 139.35 MiB is allocated by PyTorch, and 28.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c1ff41c3,"{'temperature_head': 0.30000000000000004, 'latent_dim': 610, 'batch_size': 252, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 888.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 678.00 MiB memory in use. Process 29194 has 718.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 744.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.41 GiB memory in use. Process 29577 has 820.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 822.00 MiB memory in use. Of the allocated memory 138.61 MiB is allocated by PyTorch, and 33.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e64c73b9,"{'temperature_head': 0.5, 'latent_dim': 311, 'batch_size': 283, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 790.00 MiB memory in use. Process 25542 has 692.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 694.00 MiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 820.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 864.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 822.00 MiB memory in use. Of the allocated memory 320.28 MiB is allocated by PyTorch, and 31.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d02036f7,"{'temperature_head': 1.0, 'latent_dim': 263, 'batch_size': 316, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 790.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 938.00 MiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 820.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 866.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 822.00 MiB memory in use. Of the allocated memory 135.90 MiB is allocated by PyTorch, and 36.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0d1bf8e4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 293, 'batch_size': 188, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 790.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 938.00 MiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 820.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 866.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 822.00 MiB memory in use. Of the allocated memory 136.14 MiB is allocated by PyTorch, and 29.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
17d99a08,"{'temperature_head': 0.8, 'latent_dim': 87, 'batch_size': 220, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 790.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 938.00 MiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 820.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 866.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 778.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 822.00 MiB memory in use. Of the allocated memory 78.52 MiB is allocated by PyTorch, and 37.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8f539eca,"{'temperature_head': 0.9, 'latent_dim': 176, 'batch_size': 171, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 790.00 MiB memory in use. Process 25542 has 562.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 938.00 MiB memory in use. Process 29194 has 676.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 820.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 866.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 656.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 822.00 MiB memory in use. Of the allocated memory 79.22 MiB is allocated by PyTorch, and 34.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7ad78153,"{'temperature_head': 0.8, 'latent_dim': 461, 'batch_size': 425, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 790.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1008.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 938.00 MiB memory in use. Process 29194 has 676.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 820.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 866.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 656.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 788.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 409.99 MiB is allocated by PyTorch, and 38.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2c6566da,"{'temperature_head': 0.4, 'latent_dim': 647, 'batch_size': 298, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1010.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 938.00 MiB memory in use. Process 29194 has 676.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 820.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 866.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 656.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 521.41 MiB is allocated by PyTorch, and 34.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1c6b77c2,"{'temperature_head': 0.6000000000000001, 'latent_dim': 210, 'batch_size': 288, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 944.00 MiB memory in use. Process 25586 has 1010.00 MiB memory in use. Process 25582 has 714.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 938.00 MiB memory in use. Process 29194 has 726.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.42 GiB memory in use. Process 29577 has 866.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 704.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 650.00 MiB memory in use. Of the allocated memory 79.49 MiB is allocated by PyTorch, and 36.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dc679831,"{'temperature_head': 0.8, 'latent_dim': 70, 'batch_size': 277, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 968.00 MiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 852.00 MiB memory in use. Process 29194 has 710.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 704.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 650.00 MiB memory in use. Of the allocated memory 134.39 MiB is allocated by PyTorch, and 35.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ba9e9f0b,"{'temperature_head': 0.9, 'latent_dim': 414, 'batch_size': 249, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 968.00 MiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 852.00 MiB memory in use. Process 29194 has 710.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 704.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 650.00 MiB memory in use. Of the allocated memory 81.08 MiB is allocated by PyTorch, and 32.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a4a026a7,"{'temperature_head': 0.7000000000000001, 'latent_dim': 228, 'batch_size': 145, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 506.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 968.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 852.00 MiB memory in use. Process 29194 has 710.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 576.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 704.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 696.00 MiB memory in use. Of the allocated memory 135.63 MiB is allocated by PyTorch, and 36.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0ec3feb5,"{'temperature_head': 0.8, 'latent_dim': 149, 'batch_size': 368, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 554.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 968.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 852.00 MiB memory in use. Process 29194 has 710.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 826.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 704.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 602.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 664.00 MiB memory in use. Of the allocated memory 223.10 MiB is allocated by PyTorch, and 38.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92b80dca,"{'temperature_head': 0.5, 'latent_dim': 404, 'batch_size': 157, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 1014.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 900.00 MiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 774.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 454.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 702.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 546.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 664.00 MiB memory in use. Of the allocated memory 136.50 MiB is allocated by PyTorch, and 69.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e42270fa,"{'temperature_head': 0.6000000000000001, 'latent_dim': 681, 'batch_size': 459, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 970.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 808.00 MiB memory in use. Process 28792 has 836.00 MiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 774.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 1.00 GiB memory in use. Process 29582 has 450.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 962.00 MiB memory in use. Process 29971 has 426.00 MiB memory in use. Of the allocated memory 139.17 MiB is allocated by PyTorch, and 30.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
320d318d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 279, 'batch_size': 483, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 970.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 612.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 794.00 MiB memory in use. Process 28792 has 452.00 MiB memory in use. Process 29194 has 814.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 772.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 452.00 MiB memory in use. Process 29574 has 984.00 MiB memory in use. Process 29582 has 564.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 680.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 556.00 MiB memory in use. Of the allocated memory 300.97 MiB is allocated by PyTorch, and 39.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4573a3b1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 320, 'batch_size': 326, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 970.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 612.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 430.00 MiB memory in use. Process 28792 has 470.00 MiB memory in use. Process 29194 has 814.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 772.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 690.00 MiB memory in use. Process 29574 has 984.00 MiB memory in use. Process 29582 has 450.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 700.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 758.00 MiB memory in use. Of the allocated memory 326.35 MiB is allocated by PyTorch, and 33.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fbeb65e8,"{'temperature_head': 0.8, 'latent_dim': 716, 'batch_size': 177, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 424.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1012.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 612.00 MiB memory in use. Process 28795 has 1.81 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 764.00 MiB memory in use. Process 28792 has 554.00 MiB memory in use. Process 29194 has 814.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 432.00 MiB memory in use. Process 29971 has 758.00 MiB memory in use. Of the allocated memory 139.44 MiB is allocated by PyTorch, and 32.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2675d28c,"{'temperature_head': 0.5, 'latent_dim': 474, 'batch_size': 221, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 282.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1012.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.45 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 764.00 MiB memory in use. Process 28792 has 454.00 MiB memory in use. Process 29194 has 862.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 676.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 516.00 MiB memory in use. Process 29972 has 498.00 MiB memory in use. Process 29971 has 758.00 MiB memory in use. Of the allocated memory 137.55 MiB is allocated by PyTorch, and 38.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6fa2b4d0,"{'temperature_head': 0.8, 'latent_dim': 234, 'batch_size': 212, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1012.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.45 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 766.00 MiB memory in use. Process 28792 has 470.00 MiB memory in use. Process 29194 has 862.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 676.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 554.00 MiB memory in use. Process 29971 has 806.00 MiB memory in use. Of the allocated memory 135.67 MiB is allocated by PyTorch, and 38.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26ef25cd,"{'temperature_head': 0.7000000000000001, 'latent_dim': 501, 'batch_size': 291, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 248.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 912.00 MiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.45 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 794.00 MiB memory in use. Process 28792 has 468.00 MiB memory in use. Process 29194 has 790.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 676.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 508.00 MiB memory in use. Process 29971 has 802.00 MiB memory in use. Of the allocated memory 137.76 MiB is allocated by PyTorch, and 36.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b237da25,"{'temperature_head': 0.30000000000000004, 'latent_dim': 393, 'batch_size': 151, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.11 GiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 794.00 MiB memory in use. Process 28792 has 456.00 MiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 676.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 516.00 MiB memory in use. Process 29972 has 662.00 MiB memory in use. Process 29971 has 802.00 MiB memory in use. Of the allocated memory 136.92 MiB is allocated by PyTorch, and 39.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3a63eaca,"{'temperature_head': 0.7000000000000001, 'latent_dim': 355, 'batch_size': 245, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.11 GiB memory in use. Process 25580 has 838.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 472.00 MiB memory in use. Process 29194 has 552.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 652.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 676.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 724.00 MiB memory in use. Process 29972 has 470.00 MiB memory in use. Process 29971 has 848.00 MiB memory in use. Of the allocated memory 346.62 MiB is allocated by PyTorch, and 37.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e1774f27,"{'temperature_head': 0.9, 'latent_dim': 69, 'batch_size': 374, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 768.00 MiB memory in use. Process 29194 has 422.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 644.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.46 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 506.00 MiB memory in use. Process 29972 has 452.00 MiB memory in use. Process 29971 has 1006.00 MiB memory in use. Of the allocated memory 134.38 MiB is allocated by PyTorch, and 31.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8eeec34a,"{'temperature_head': 0.9, 'latent_dim': 640, 'batch_size': 229, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 848.00 MiB memory in use. Process 28792 has 770.00 MiB memory in use. Process 29194 has 450.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.54 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 434.00 MiB memory in use. Process 29971 has 1006.00 MiB memory in use. Of the allocated memory 138.85 MiB is allocated by PyTorch, and 31.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a0f5cc2d,"{'temperature_head': 1.0, 'latent_dim': 373, 'batch_size': 181, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 474.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 748.00 MiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.54 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 452.00 MiB memory in use. Process 29971 has 1006.00 MiB memory in use. Of the allocated memory 136.76 MiB is allocated by PyTorch, and 37.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6e414ab7,"{'temperature_head': 0.6000000000000001, 'latent_dim': 672, 'batch_size': 253, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 470.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 748.00 MiB memory in use. Process 29194 has 420.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 580.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.54 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 530.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 1006.00 MiB memory in use. Of the allocated memory 139.10 MiB is allocated by PyTorch, and 50.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f8c399f1,"{'temperature_head': 0.8, 'latent_dim': 593, 'batch_size': 363, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 484.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 796.00 MiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.54 GiB memory in use. Process 29577 has 1.02 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 452.00 MiB memory in use. Process 29971 has 1006.00 MiB memory in use. Of the allocated memory 138.71 MiB is allocated by PyTorch, and 33.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d43b06c7,"{'temperature_head': 0.9, 'latent_dim': 441, 'batch_size': 143, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 194.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 816.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 500.00 MiB memory in use. Process 28792 has 776.00 MiB memory in use. Process 29194 has 898.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 756.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 504.00 MiB memory in use. Process 29577 has 1012.00 MiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 738.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.29 MiB is allocated by PyTorch, and 36.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3e48df20,"{'temperature_head': 0.4, 'latent_dim': 528, 'batch_size': 345, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 190.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 816.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.12 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 776.00 MiB memory in use. Process 29194 has 898.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 756.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1012.00 MiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 738.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.97 MiB is allocated by PyTorch, and 34.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aff7e6ff,"{'temperature_head': 0.30000000000000004, 'latent_dim': 630, 'batch_size': 410, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 374.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 816.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.07 GiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 912.00 MiB memory in use. Process 29194 has 898.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 756.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1012.00 MiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 738.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 510.72 MiB is allocated by PyTorch, and 247.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
960acb09,"{'temperature_head': 0.4, 'latent_dim': 544, 'batch_size': 271, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 314.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 816.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 500.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 468.00 MiB memory in use. Process 28792 has 912.00 MiB memory in use. Process 29194 has 898.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1012.00 MiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 834.00 MiB memory in use. Process 29972 has 738.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 460.10 MiB is allocated by PyTorch, and 33.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8a5d0316,"{'temperature_head': 0.30000000000000004, 'latent_dim': 661, 'batch_size': 340, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 288.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 816.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 524.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 468.00 MiB memory in use. Process 28792 has 912.00 MiB memory in use. Process 29194 has 898.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1012.00 MiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 880.00 MiB memory in use. Process 29972 has 738.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 139.01 MiB is allocated by PyTorch, and 34.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5db0fd0a,"{'temperature_head': 0.5, 'latent_dim': 503, 'batch_size': 288, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 266.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 816.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 516.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 468.00 MiB memory in use. Process 28792 has 912.00 MiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 542.00 MiB memory in use. Process 29577 has 1012.00 MiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 880.00 MiB memory in use. Process 29972 has 738.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.78 MiB is allocated by PyTorch, and 38.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
09ac5db2,"{'temperature_head': 0.5, 'latent_dim': 302, 'batch_size': 360, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 816.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 496.00 MiB memory in use. Process 28792 has 912.00 MiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 888.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.00 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 880.00 MiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 35.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
baea9a75,"{'temperature_head': 0.2, 'latent_dim': 429, 'batch_size': 394, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 794.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 498.00 MiB memory in use. Process 28792 has 454.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 888.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.00 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.09 GiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.20 MiB is allocated by PyTorch, and 36.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
286cf3c9,"{'temperature_head': 0.30000000000000004, 'latent_dim': 566, 'batch_size': 379, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 794.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 498.00 MiB memory in use. Process 28792 has 454.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 888.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.00 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.09 GiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 472.68 MiB is allocated by PyTorch, and 301.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d292a3f4,"{'temperature_head': 0.30000000000000004, 'latent_dim': 701, 'batch_size': 318, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 416.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 794.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 498.00 MiB memory in use. Process 28792 has 468.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 888.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.00 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.13 GiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 139.50 MiB is allocated by PyTorch, and 32.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c69b3736,"{'temperature_head': 0.5, 'latent_dim': 346, 'batch_size': 404, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 794.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 498.00 MiB memory in use. Process 28792 has 454.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 888.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.00 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.14 GiB memory in use. Process 29972 has 788.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 136.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e49289d1,"{'temperature_head': 0.4, 'latent_dim': 467, 'batch_size': 332, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 214.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 794.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 468.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 888.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.00 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 1.09 GiB memory in use. Process 29972 has 788.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 413.08 MiB is allocated by PyTorch, and 362.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26f92c79,"{'temperature_head': 0.4, 'latent_dim': 588, 'batch_size': 238, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 794.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 996.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 774.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 788.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 138.59 MiB is allocated by PyTorch, and 35.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2fe16e96,"{'temperature_head': 0.5, 'latent_dim': 494, 'batch_size': 220, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 840.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 996.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 660.00 MiB memory in use. Process 29976 has 516.00 MiB memory in use. Process 29972 has 788.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.71 MiB is allocated by PyTorch, and 38.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
194335eb,"{'temperature_head': 0.1, 'latent_dim': 278, 'batch_size': 129, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 676.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 996.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 660.00 MiB memory in use. Process 29976 has 522.00 MiB memory in use. Process 29972 has 788.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 300.37 MiB is allocated by PyTorch, and 35.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3855cf61,"{'temperature_head': 0.1, 'latent_dim': 402, 'batch_size': 294, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 726.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 996.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 660.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 788.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 136.99 MiB is allocated by PyTorch, and 35.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f2ed66be,"{'temperature_head': 0.5, 'latent_dim': 384, 'batch_size': 195, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 160.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 870.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 624.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 996.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 660.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 836.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 136.34 MiB is allocated by PyTorch, and 147.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
78d22fca,"{'temperature_head': 0.30000000000000004, 'latent_dim': 222, 'batch_size': 265, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 870.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 624.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 600.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 996.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 660.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 836.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 47.10 MiB is allocated by PyTorch, and 36.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
27b24d55,"{'temperature_head': 0.7000000000000001, 'latent_dim': 103, 'batch_size': 386, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 870.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.49 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 646.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 836.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 134.65 MiB is allocated by PyTorch, and 37.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ab14ad7a,"{'temperature_head': 0.4, 'latent_dim': 56, 'batch_size': 323, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 870.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 646.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 522.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 776.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 78.28 MiB is allocated by PyTorch, and 31.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e89c50a7,"{'temperature_head': 0.9, 'latent_dim': 452, 'batch_size': 350, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 236.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 870.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 776.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.38 MiB is allocated by PyTorch, and 36.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
49ac0d32,"{'temperature_head': 0.7000000000000001, 'latent_dim': 259, 'batch_size': 156, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 870.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 540.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 662.00 MiB memory in use. Process 29972 has 776.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 289.87 MiB is allocated by PyTorch, and 32.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fcfff877,"{'temperature_head': 0.9, 'latent_dim': 194, 'batch_size': 248, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 870.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 630.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 476.00 MiB memory in use. Process 29972 has 776.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 250.05 MiB is allocated by PyTorch, and 39.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
02811764,"{'temperature_head': 0.8, 'latent_dim': 368, 'batch_size': 214, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 676.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 610.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 458.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 80.72 MiB is allocated by PyTorch, and 37.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e4fc955f,"{'temperature_head': 0.8, 'latent_dim': 285, 'batch_size': 341, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 744.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 304.06 MiB is allocated by PyTorch, and 99.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
95821c3a,"{'temperature_head': 0.2, 'latent_dim': 558, 'batch_size': 433, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 744.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 138.21 MiB is allocated by PyTorch, and 33.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2c7958c6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 147, 'batch_size': 166, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 788.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 134.99 MiB is allocated by PyTorch, and 37.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3ebe6a7a,"{'temperature_head': 0.4, 'latent_dim': 448, 'batch_size': 465, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 788.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.35 MiB is allocated by PyTorch, and 36.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f5bbb442,"{'temperature_head': 0.6000000000000001, 'latent_dim': 523, 'batch_size': 231, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 258.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 468.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 572.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 500.00 MiB memory in use. Process 28792 has 1014.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 138.28 MiB is allocated by PyTorch, and 93.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a136e903,"{'temperature_head': 0.9, 'latent_dim': 329, 'batch_size': 313, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 494.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 512.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 710.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 330.92 MiB is allocated by PyTorch, and 39.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
318daaaf,"{'temperature_head': 0.8, 'latent_dim': 424, 'batch_size': 374, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.52 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 704.00 MiB memory in use. Process 29976 has 564.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 1008.00 MiB memory in use. Of the allocated memory 137.16 MiB is allocated by PyTorch, and 36.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ab136153,"{'temperature_head': 1.0, 'latent_dim': 90, 'batch_size': 416, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 822.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 562.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 870.00 MiB memory in use. Of the allocated memory 134.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
98763b5d,"{'temperature_head': 0.5, 'latent_dim': 653, 'batch_size': 356, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 388.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 822.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 870.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 35.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7c5b03f7,"{'temperature_head': 0.8, 'latent_dim': 178, 'batch_size': 265, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 500.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 822.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 460.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 870.00 MiB memory in use. Of the allocated memory 135.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bf8d3e88,"{'temperature_head': 0.4, 'latent_dim': 510, 'batch_size': 328, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 500.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 822.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 870.00 MiB memory in use. Of the allocated memory 81.83 MiB is allocated by PyTorch, and 32.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
79713995,"{'temperature_head': 0.9, 'latent_dim': 245, 'batch_size': 299, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 760.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 918.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 135.76 MiB is allocated by PyTorch, and 34.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
682df7b3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 717, 'batch_size': 275, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 424.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 760.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 918.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 880.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 139.45 MiB is allocated by PyTorch, and 34.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f58cefa0,"{'temperature_head': 0.2, 'latent_dim': 211, 'batch_size': 335, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 760.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 918.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 494.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.01 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 638.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 260.24 MiB is allocated by PyTorch, and 37.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a05903af,"{'temperature_head': 0.30000000000000004, 'latent_dim': 683, 'batch_size': 226, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 760.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 918.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 552.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.01 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 139.83 MiB is allocated by PyTorch, and 30.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
66bab8f1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 576, 'batch_size': 204, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 760.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 918.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 552.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 552.00 MiB memory in use. Process 29577 has 1.01 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 138.35 MiB is allocated by PyTorch, and 35.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7a019343,"{'temperature_head': 0.7000000000000001, 'latent_dim': 487, 'batch_size': 216, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 920.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 552.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 562.00 MiB memory in use. Process 29577 has 1.01 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 708.00 MiB memory in use. Of the allocated memory 137.65 MiB is allocated by PyTorch, and 36.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6f5b8d0b,"{'temperature_head': 0.9, 'latent_dim': 407, 'batch_size': 307, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 238.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 774.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 552.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 562.00 MiB memory in use. Process 29577 has 1.01 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 708.00 MiB memory in use. Of the allocated memory 377.14 MiB is allocated by PyTorch, and 56.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f21cf65a,"{'temperature_head': 0.4, 'latent_dim': 303, 'batch_size': 445, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 700.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 562.00 MiB memory in use. Process 29577 has 1.04 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 708.00 MiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 35.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
766ec3d3,"{'temperature_head': 0.9, 'latent_dim': 137, 'batch_size': 402, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 700.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 590.00 MiB memory in use. Process 29577 has 1.05 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 474.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 708.00 MiB memory in use. Of the allocated memory 215.91 MiB is allocated by PyTorch, and 34.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
25e1e0ab,"{'temperature_head': 1.0, 'latent_dim': 633, 'batch_size': 257, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 366.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 430.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 726.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 532.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 476.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 138.29 MiB is allocated by PyTorch, and 53.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9bc151ff,"{'temperature_head': 0.1, 'latent_dim': 345, 'batch_size': 390, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 430.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 726.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 584.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 934.00 MiB memory in use. Process 29971 has 726.00 MiB memory in use. Of the allocated memory 136.54 MiB is allocated by PyTorch, and 35.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ebe6d8d3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 475, 'batch_size': 172, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 282.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 496.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 726.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 934.00 MiB memory in use. Process 29971 has 726.00 MiB memory in use. Of the allocated memory 137.56 MiB is allocated by PyTorch, and 30.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
acd5ec86,"{'temperature_head': 1.0, 'latent_dim': 202, 'batch_size': 320, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 496.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 726.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 934.00 MiB memory in use. Process 29971 has 726.00 MiB memory in use. Of the allocated memory 135.42 MiB is allocated by PyTorch, and 36.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f775fa6d,"{'temperature_head': 0.8, 'latent_dim': 221, 'batch_size': 209, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 786.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 934.00 MiB memory in use. Process 29971 has 726.00 MiB memory in use. Of the allocated memory 135.57 MiB is allocated by PyTorch, and 38.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7659e298,"{'temperature_head': 0.5, 'latent_dim': 382, 'batch_size': 184, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 786.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 934.00 MiB memory in use. Process 29971 has 726.00 MiB memory in use. Of the allocated memory 136.83 MiB is allocated by PyTorch, and 35.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fdc6112b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 696, 'batch_size': 238, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 786.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 552.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 484.00 MiB memory in use. Process 29972 has 934.00 MiB memory in use. Process 29971 has 774.00 MiB memory in use. Of the allocated memory 83.29 MiB is allocated by PyTorch, and 60.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e630be27,"{'temperature_head': 0.8, 'latent_dim': 292, 'batch_size': 294, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 786.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 806.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 552.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 484.00 MiB memory in use. Process 29972 has 934.00 MiB memory in use. Process 29971 has 774.00 MiB memory in use. Of the allocated memory 80.13 MiB is allocated by PyTorch, and 33.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d63965f5,"{'temperature_head': 0.5, 'latent_dim': 669, 'batch_size': 354, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 304.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 700.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 728.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 790.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 994.00 MiB memory in use. Process 29972 has 470.00 MiB memory in use. Process 29971 has 770.00 MiB memory in use. Of the allocated memory 139.20 MiB is allocated by PyTorch, and 220.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8240b204,"{'temperature_head': 0.30000000000000004, 'latent_dim': 243, 'batch_size': 314, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 496.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 854.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 658.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 732.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 994.00 MiB memory in use. Process 29972 has 850.00 MiB memory in use. Process 29971 has 820.00 MiB memory in use. Of the allocated memory 279.74 MiB is allocated by PyTorch, and 38.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a82176f9,"{'temperature_head': 0.8, 'latent_dim': 421, 'batch_size': 249, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 506.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 854.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 500.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 640.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 994.00 MiB memory in use. Process 29972 has 850.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 137.14 MiB is allocated by PyTorch, and 36.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
970be92f,"{'temperature_head': 1.0, 'latent_dim': 21, 'batch_size': 261, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1016.00 MiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 998.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 864.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 850.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 78.01 MiB is allocated by PyTorch, and 33.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4be1d5de,"{'temperature_head': 0.9, 'latent_dim': 147, 'batch_size': 191, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 470.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 706.00 MiB memory in use. Process 28792 has 974.00 MiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 864.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 898.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 46.52 MiB is allocated by PyTorch, and 35.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b13fd9e2,"{'temperature_head': 0.5, 'latent_dim': 438, 'batch_size': 304, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 470.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 444.00 MiB memory in use. Process 25586 has 1016.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 706.00 MiB memory in use. Process 28792 has 974.00 MiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 864.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 898.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 86.61 MiB is allocated by PyTorch, and 17.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
999c2c3b,"{'temperature_head': 0.8, 'latent_dim': 530, 'batch_size': 338, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 706.00 MiB memory in use. Process 28792 has 974.00 MiB memory in use. Process 29194 has 486.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 826.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 920.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 451.99 MiB is allocated by PyTorch, and 34.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f9c811cc,"{'temperature_head': 0.7000000000000001, 'latent_dim': 319, 'batch_size': 153, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 706.00 MiB memory in use. Process 28792 has 974.00 MiB memory in use. Process 29194 has 500.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 826.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 920.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 136.34 MiB is allocated by PyTorch, and 31.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e1b87be,"{'temperature_head': 0.6000000000000001, 'latent_dim': 41, 'batch_size': 167, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 508.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 750.00 MiB memory in use. Process 28792 has 1006.00 MiB memory in use. Process 29194 has 866.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 848.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 874.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 448.00 MiB memory in use. Process 29972 has 920.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 78.16 MiB is allocated by PyTorch, and 29.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d19c5134,"{'temperature_head': 0.4, 'latent_dim': 718, 'batch_size': 293, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 450.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 750.00 MiB memory in use. Process 28792 has 1022.00 MiB memory in use. Process 29194 has 866.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 848.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 770.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 920.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 291.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1318d453,"{'temperature_head': 0.8, 'latent_dim': 336, 'batch_size': 509, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 750.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 866.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 848.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 770.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 920.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 334.61 MiB is allocated by PyTorch, and 95.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bcc87c4e,"{'temperature_head': 0.9, 'latent_dim': 276, 'batch_size': 273, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 750.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 866.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 848.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 770.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 920.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 136.00 MiB is allocated by PyTorch, and 32.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2b0c33c6,"{'temperature_head': 0.1, 'latent_dim': 555, 'batch_size': 414, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 750.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 866.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 848.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 770.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 686.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 920.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 138.19 MiB is allocated by PyTorch, and 29.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
75b54712,"{'temperature_head': 0.7000000000000001, 'latent_dim': 573, 'batch_size': 398, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 886.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 976.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 728.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 866.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 848.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 814.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 688.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 138.33 MiB is allocated by PyTorch, and 29.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6f0e63d8,"{'temperature_head': 0.30000000000000004, 'latent_dim': 259, 'batch_size': 333, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 886.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 730.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 868.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 850.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 814.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 688.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 554.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 135.87 MiB is allocated by PyTorch, and 30.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
32a12331,"{'temperature_head': 1.0, 'latent_dim': 605, 'batch_size': 201, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 358.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 886.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 730.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 868.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 806.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 814.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 688.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 138.58 MiB is allocated by PyTorch, and 29.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
917ae273,"{'temperature_head': 0.8, 'latent_dim': 178, 'batch_size': 365, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 886.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 868.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 806.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 816.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 690.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 135.24 MiB is allocated by PyTorch, and 32.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5fae387d,"{'temperature_head': 0.9, 'latent_dim': 514, 'batch_size': 241, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 886.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 846.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 806.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 816.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 690.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 137.86 MiB is allocated by PyTorch, and 30.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ed8ddedd,"{'temperature_head': 0.5, 'latent_dim': 306, 'batch_size': 212, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 886.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1024.00 MiB memory in use. Process 29194 has 846.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 806.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 888.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 690.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 510.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 136.24 MiB is allocated by PyTorch, and 31.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
47483ecf,"{'temperature_head': 0.2, 'latent_dim': 376, 'batch_size': 426, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 728.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 846.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 888.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 450.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 664.00 MiB memory in use. Process 29972 has 558.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 136.78 MiB is allocated by PyTorch, and 37.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1d3c5237,"{'temperature_head': 1.0, 'latent_dim': 93, 'batch_size': 386, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 728.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 852.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 752.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.10 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 496.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 616.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 134.57 MiB is allocated by PyTorch, and 35.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cdeb8468,"{'temperature_head': 0.6000000000000001, 'latent_dim': 500, 'batch_size': 192, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 132.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 772.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 474.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 752.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.10 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 602.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 810.00 MiB memory in use. Process 29972 has 786.00 MiB memory in use. Process 29971 has 960.00 MiB memory in use. Of the allocated memory 433.75 MiB is allocated by PyTorch, and 36.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
12fa732e,"{'temperature_head': 0.7000000000000001, 'latent_dim': 448, 'batch_size': 174, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 180.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 900.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 474.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 796.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.10 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 452.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 750.00 MiB memory in use. Process 29972 has 786.00 MiB memory in use. Process 29971 has 848.00 MiB memory in use. Of the allocated memory 136.84 MiB is allocated by PyTorch, and 273.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e692eaab,"{'temperature_head': 0.6000000000000001, 'latent_dim': 350, 'batch_size': 145, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 900.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 796.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.10 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 452.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 800.00 MiB memory in use. Process 29972 has 786.00 MiB memory in use. Process 29971 has 848.00 MiB memory in use. Of the allocated memory 136.58 MiB is allocated by PyTorch, and 37.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5d24a9b0,"{'temperature_head': 0.6000000000000001, 'latent_dim': 410, 'batch_size': 183, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 900.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 564.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1000.00 MiB memory in use. Process 29972 has 832.00 MiB memory in use. Process 29971 has 848.00 MiB memory in use. Of the allocated memory 378.94 MiB is allocated by PyTorch, and 281.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
707513bb,"{'temperature_head': 0.6000000000000001, 'latent_dim': 331, 'batch_size': 198, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 900.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 564.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1000.00 MiB memory in use. Process 29972 has 832.00 MiB memory in use. Process 29971 has 848.00 MiB memory in use. Of the allocated memory 136.43 MiB is allocated by PyTorch, and 31.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0ba936d5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 361, 'batch_size': 218, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 900.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 640.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 420.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 452.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 996.00 MiB memory in use. Process 29972 has 888.00 MiB memory in use. Process 29971 has 470.00 MiB memory in use. Of the allocated memory 349.58 MiB is allocated by PyTorch, and 306.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c0475f15,"{'temperature_head': 0.5, 'latent_dim': 471, 'batch_size': 157, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 218.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 900.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 640.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 452.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 888.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 137.53 MiB is allocated by PyTorch, and 34.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
59b8f098,"{'temperature_head': 0.7000000000000001, 'latent_dim': 490, 'batch_size': 225, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 834.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 508.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 518.00 MiB memory in use. Process 29972 has 888.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 137.68 MiB is allocated by PyTorch, and 40.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
316dcc19,"{'temperature_head': 0.6000000000000001, 'latent_dim': 239, 'batch_size': 182, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 834.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 508.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.01 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 932.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 135.71 MiB is allocated by PyTorch, and 32.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
312e33f5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 215, 'batch_size': 235, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 834.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 524.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 992.00 MiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 950.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 79.52 MiB is allocated by PyTorch, and 36.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d7949d1b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 626, 'batch_size': 149, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 834.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 522.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 756.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 510.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 992.00 MiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 950.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 139.55 MiB is allocated by PyTorch, and 42.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
07ab1cec,"{'temperature_head': 0.6000000000000001, 'latent_dim': 535, 'batch_size': 176, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 834.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 802.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 992.00 MiB memory in use. Process 29582 has 406.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 520.00 MiB memory in use. Process 29972 has 950.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 138.51 MiB is allocated by PyTorch, and 41.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3c4e1f85,"{'temperature_head': 0.7000000000000001, 'latent_dim': 281, 'batch_size': 243, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 834.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 802.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 992.00 MiB memory in use. Process 29582 has 406.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 950.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 80.04 MiB is allocated by PyTorch, and 33.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cc8e813a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 689, 'batch_size': 268, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 834.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 474.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 802.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 992.00 MiB memory in use. Process 29582 has 406.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 530.00 MiB memory in use. Process 29972 has 950.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 104.49 MiB is allocated by PyTorch, and 29.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 20, in forward
    projection_1 = self.projection_1(base_model_output)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
"
9bf02b1e,"{'temperature_head': 0.8, 'latent_dim': 668, 'batch_size': 191, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 940.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 848.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 936.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 734.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 992.00 MiB memory in use. Process 29582 has 452.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 526.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 139.52 MiB is allocated by PyTorch, and 46.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b340055f,"{'temperature_head': 0.5, 'latent_dim': 419, 'batch_size': 285, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 464.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 940.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 936.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 734.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 430.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 458.00 MiB memory in use. Process 29972 has 502.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 81.12 MiB is allocated by PyTorch, and 36.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ea44181d,"{'temperature_head': 0.9, 'latent_dim': 388, 'batch_size': 229, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 466.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 940.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 936.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 734.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 406.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 502.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 136.88 MiB is allocated by PyTorch, and 35.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7274160f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 269, 'batch_size': 201, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 940.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 936.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.15 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 500.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 670.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 295.95 MiB is allocated by PyTorch, and 34.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2642c0f2,"{'temperature_head': 0.8, 'latent_dim': 548, 'batch_size': 143, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 296.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 940.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 804.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 902.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 620.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 716.00 MiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 830.00 MiB memory in use. Of the allocated memory 461.62 MiB is allocated by PyTorch, and 100.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e5733bcd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 517, 'batch_size': 134, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 984.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.57 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 852.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 948.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 620.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 612.00 MiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 138.15 MiB is allocated by PyTorch, and 133.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3f5b6383,"{'temperature_head': 0.5, 'latent_dim': 563, 'batch_size': 217, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 334.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 562.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 984.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.54 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 852.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 448.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 504.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 910.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 620.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 660.00 MiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 470.59 MiB is allocated by PyTorch, and 99.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3f3fb6c9,"{'temperature_head': 0.9, 'latent_dim': 303, 'batch_size': 252, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 562.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 984.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.54 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 848.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 552.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 668.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.02 GiB memory in use. Process 29972 has 784.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 80.21 MiB is allocated by PyTorch, and 33.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d8e9d8cb,"{'temperature_head': 0.8, 'latent_dim': 354, 'batch_size': 243, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 614.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 984.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.54 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 848.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 658.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.02 GiB memory in use. Process 29972 has 840.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 80.61 MiB is allocated by PyTorch, and 31.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
784ee44f,"{'temperature_head': 0.8, 'latent_dim': 339, 'batch_size': 196, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 614.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 986.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.54 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 848.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 424.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 450.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 658.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.02 GiB memory in use. Process 29972 has 840.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 136.49 MiB is allocated by PyTorch, and 35.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc6105a3,"{'temperature_head': 0.9, 'latent_dim': 326, 'batch_size': 265, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 614.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 884.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.54 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 848.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 450.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 664.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.02 GiB memory in use. Process 29972 has 840.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 328.62 MiB is allocated by PyTorch, and 215.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1fdb9720,"{'temperature_head': 1.0, 'latent_dim': 251, 'batch_size': 213, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 660.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 426.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.54 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 848.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 910.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 704.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 1.02 GiB memory in use. Process 29972 has 840.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 47.33 MiB is allocated by PyTorch, and 38.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ba82bb92,"{'temperature_head': 0.9, 'latent_dim': 379, 'batch_size': 239, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 218.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 748.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 896.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 482.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 910.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 476.00 MiB memory in use. Process 29972 has 840.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 136.81 MiB is allocated by PyTorch, and 35.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e22e28b8,"{'temperature_head': 0.8, 'latent_dim': 396, 'batch_size': 221, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 748.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 896.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 518.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 910.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 136.94 MiB is allocated by PyTorch, and 37.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ba9670a5,"{'temperature_head': 0.8, 'latent_dim': 310, 'batch_size': 275, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 748.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 896.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 910.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 474.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 956.00 MiB memory in use. Of the allocated memory 136.27 MiB is allocated by PyTorch, and 35.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2723d560,"{'temperature_head': 0.9, 'latent_dim': 361, 'batch_size': 228, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 198.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 956.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 136.67 MiB is allocated by PyTorch, and 33.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2e82f982,"{'temperature_head': 0.8, 'latent_dim': 434, 'batch_size': 247, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 222.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 886.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 393.31 MiB is allocated by PyTorch, and 152.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d1ff28c3,"{'temperature_head': 1.0, 'latent_dim': 277, 'batch_size': 176, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 516.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 886.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 136.01 MiB is allocated by PyTorch, and 39.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
549e8cde,"{'temperature_head': 0.8, 'latent_dim': 234, 'batch_size': 187, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 564.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 930.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 135.67 MiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cd397811,"{'temperature_head': 0.9, 'latent_dim': 413, 'batch_size': 290, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 610.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 886.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 516.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 380.73 MiB is allocated by PyTorch, and 165.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
13462785,"{'temperature_head': 0.7000000000000001, 'latent_dim': 264, 'batch_size': 208, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 612.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 892.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 135.91 MiB is allocated by PyTorch, and 34.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bc8a92d2,"{'temperature_head': 1.0, 'latent_dim': 322, 'batch_size': 235, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 668.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 930.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 80.36 MiB is allocated by PyTorch, and 31.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eabe96ea,"{'temperature_head': 0.7000000000000001, 'latent_dim': 447, 'batch_size': 263, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 750.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 860.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 668.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 892.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 716.00 MiB memory in use. Of the allocated memory 401.10 MiB is allocated by PyTorch, and 150.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f6b724c7,"{'temperature_head': 0.8, 'latent_dim': 338, 'batch_size': 270, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 182.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 812.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 668.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 450.00 MiB memory in use. Of the allocated memory 136.49 MiB is allocated by PyTorch, and 35.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
302d18d2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 171, 'batch_size': 196, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 812.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 668.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 610.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 450.00 MiB memory in use. Of the allocated memory 237.18 MiB is allocated by PyTorch, and 32.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
593e48e3,"{'temperature_head': 0.7000000000000001, 'latent_dim': 154, 'batch_size': 281, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 812.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 798.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 668.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 430.00 MiB memory in use. Of the allocated memory 135.05 MiB is allocated by PyTorch, and 36.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e5c7a6ce,"{'temperature_head': 1.0, 'latent_dim': 480, 'batch_size': 151, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 812.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 798.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 668.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 430.00 MiB memory in use. Of the allocated memory 137.60 MiB is allocated by PyTorch, and 32.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3ca9c150,"{'temperature_head': 1.0, 'latent_dim': 213, 'batch_size': 296, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 812.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 798.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 694.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 416.00 MiB memory in use. Of the allocated memory 135.51 MiB is allocated by PyTorch, and 34.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
49a1473d,"{'temperature_head': 0.9, 'latent_dim': 391, 'batch_size': 160, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 812.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 798.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 694.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 416.00 MiB memory in use. Of the allocated memory 136.90 MiB is allocated by PyTorch, and 37.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
149ffd4d,"{'temperature_head': 0.9, 'latent_dim': 253, 'batch_size': 257, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 788.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 694.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 464.00 MiB memory in use. Of the allocated memory 135.82 MiB is allocated by PyTorch, and 34.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
368fa858,"{'temperature_head': 0.8, 'latent_dim': 189, 'batch_size': 190, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 788.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 694.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 464.00 MiB memory in use. Of the allocated memory 135.32 MiB is allocated by PyTorch, and 36.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d8f78178,"{'temperature_head': 0.7000000000000001, 'latent_dim': 56, 'batch_size': 224, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 788.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 694.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 418.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 496.00 MiB memory in use. Of the allocated memory 45.80 MiB is allocated by PyTorch, and 32.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dcdfa130,"{'temperature_head': 0.8, 'latent_dim': 459, 'batch_size': 248, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 788.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 410.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 496.00 MiB memory in use. Of the allocated memory 65.88 MiB is allocated by PyTorch, and 4.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6305f819,"{'temperature_head': 0.6000000000000001, 'latent_dim': 424, 'batch_size': 230, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 788.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 410.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 496.00 MiB memory in use. Of the allocated memory 66.83 MiB is allocated by PyTorch, and 3.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3a0bc462,"{'temperature_head': 0.9, 'latent_dim': 242, 'batch_size': 237, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 788.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 410.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 496.00 MiB memory in use. Of the allocated memory 64.96 MiB is allocated by PyTorch, and 5.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b0b4488,"{'temperature_head': 0.9, 'latent_dim': 406, 'batch_size': 138, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 788.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 410.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 886.00 MiB memory in use. Process 29971 has 496.00 MiB memory in use. Of the allocated memory 137.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ab7f25a4,"{'temperature_head': 0.8, 'latent_dim': 353, 'batch_size': 273, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 834.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 898.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 80.60 MiB is allocated by PyTorch, and 35.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f3ca294b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 271, 'batch_size': 285, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 896.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 834.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 898.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 79.96 MiB is allocated by PyTorch, and 32.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5256d489,"{'temperature_head': 0.6000000000000001, 'latent_dim': 298, 'batch_size': 211, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 824.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 834.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 476.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 806.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 898.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 80.17 MiB is allocated by PyTorch, and 31.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3df04bfa,"{'temperature_head': 0.7000000000000001, 'latent_dim': 383, 'batch_size': 179, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 708.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 942.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 516.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 670.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 898.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 136.84 MiB is allocated by PyTorch, and 39.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
62b27aa7,"{'temperature_head': 0.8, 'latent_dim': 227, 'batch_size': 145, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 708.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 874.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 942.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 740.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 670.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 898.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.62 MiB is allocated by PyTorch, and 36.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8d95b870,"{'temperature_head': 0.8, 'latent_dim': 76, 'batch_size': 132, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 824.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 882.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 702.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 632.00 MiB memory in use. Process 29972 has 866.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.44 MiB is allocated by PyTorch, and 35.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f429731d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 48, 'batch_size': 129, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 672.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 824.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 788.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 866.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.22 MiB is allocated by PyTorch, and 31.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
584d3d84,"{'temperature_head': 0.7000000000000001, 'latent_dim': 149, 'batch_size': 168, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 672.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 824.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 788.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 866.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.01 MiB is allocated by PyTorch, and 32.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a8d10dd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 93, 'batch_size': 129, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 692.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 824.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 788.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 832.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.57 MiB is allocated by PyTorch, and 33.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
915b23d0,"{'temperature_head': 0.6000000000000001, 'latent_dim': 162, 'batch_size': 169, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 692.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 824.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 788.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 832.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.11 MiB is allocated by PyTorch, and 36.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f44983cc,"{'temperature_head': 0.6000000000000001, 'latent_dim': 109, 'batch_size': 175, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 692.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 740.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 870.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 832.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.69 MiB is allocated by PyTorch, and 35.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
549e7b40,"{'temperature_head': 0.6000000000000001, 'latent_dim': 199, 'batch_size': 147, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 786.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 498.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 850.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 630.00 MiB memory in use. Process 29972 has 930.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 253.40 MiB is allocated by PyTorch, and 36.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b01d23c1,"{'temperature_head': 0.9, 'latent_dim': 186, 'batch_size': 176, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 786.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 718.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 850.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 932.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 930.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.30 MiB is allocated by PyTorch, and 36.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7205d0e1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 239, 'batch_size': 137, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 560.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 554.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 980.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 710.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 828.00 MiB memory in use. Process 29972 has 974.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.71 MiB is allocated by PyTorch, and 38.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4c842661,"{'temperature_head': 0.8, 'latent_dim': 138, 'batch_size': 171, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 980.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 710.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 828.00 MiB memory in use. Process 29972 has 974.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.92 MiB is allocated by PyTorch, and 37.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2735ceb4,"{'temperature_head': 0.9, 'latent_dim': 191, 'batch_size': 209, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 474.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 980.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 758.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 974.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.34 MiB is allocated by PyTorch, and 38.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0989b6c5,"{'temperature_head': 0.8, 'latent_dim': 65, 'batch_size': 195, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 980.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 974.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.35 MiB is allocated by PyTorch, and 33.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f57a0d82,"{'temperature_head': 0.5, 'latent_dim': 104, 'batch_size': 231, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 552.00 MiB memory in use. Process 29972 has 974.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.66 MiB is allocated by PyTorch, and 37.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f932ebc8,"{'temperature_head': 0.7000000000000001, 'latent_dim': 325, 'batch_size': 183, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 448.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 562.00 MiB memory in use. Process 29972 has 974.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 80.39 MiB is allocated by PyTorch, and 31.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a383b35b,"{'temperature_head': 0.9, 'latent_dim': 181, 'batch_size': 151, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 470.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 676.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 450.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 802.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 974.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.78 MiB is allocated by PyTorch, and 37.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
efe42129,"{'temperature_head': 0.8, 'latent_dim': 207, 'batch_size': 239, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 676.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 928.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 628.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 904.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.46 MiB is allocated by PyTorch, and 36.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3c58d3ed,"{'temperature_head': 1.0, 'latent_dim': 296, 'batch_size': 215, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 724.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 980.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.16 MiB is allocated by PyTorch, and 37.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a1eb7403,"{'temperature_head': 0.7000000000000001, 'latent_dim': 124, 'batch_size': 224, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 512.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 724.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 980.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 586.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 808.00 MiB memory in use. Of the allocated memory 208.81 MiB is allocated by PyTorch, and 37.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03b7f318,"{'temperature_head': 0.8, 'latent_dim': 337, 'batch_size': 129, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 518.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 712.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 980.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 586.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 808.00 MiB memory in use. Of the allocated memory 336.48 MiB is allocated by PyTorch, and 35.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ef72cecd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 276, 'batch_size': 179, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 560.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 758.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 436.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 980.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 808.00 MiB memory in use. Of the allocated memory 80.00 MiB is allocated by PyTorch, and 30.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a3e0e2bf,"{'temperature_head': 0.9, 'latent_dim': 103, 'batch_size': 191, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 758.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 794.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.01 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 808.00 MiB memory in use. Of the allocated memory 134.65 MiB is allocated by PyTorch, and 33.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f9ed3515,"{'temperature_head': 1.0, 'latent_dim': 400, 'batch_size': 345, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 904.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 656.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 794.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 650.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.01 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 136.47 MiB is allocated by PyTorch, and 179.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
057187f3,"{'temperature_head': 0.8, 'latent_dim': 76, 'batch_size': 136, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 904.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 704.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 794.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 650.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 78.44 MiB is allocated by PyTorch, and 35.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6139db3a,"{'temperature_head': 0.9, 'latent_dim': 376, 'batch_size': 452, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 904.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 658.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 794.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 650.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 136.28 MiB is allocated by PyTorch, and 181.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aab93b55,"{'temperature_head': 0.7000000000000001, 'latent_dim': 145, 'batch_size': 330, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 904.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 502.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 840.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 596.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 662.00 MiB memory in use. Of the allocated memory 220.98 MiB is allocated by PyTorch, and 35.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
afb1e8fd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 316, 'batch_size': 257, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 904.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 680.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 840.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 646.00 MiB memory in use. Of the allocated memory 80.31 MiB is allocated by PyTorch, and 31.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
23077a88,"{'temperature_head': 0.8, 'latent_dim': 199, 'batch_size': 230, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 904.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 682.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 890.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 135.40 MiB is allocated by PyTorch, and 36.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cb6c3657,"{'temperature_head': 0.8, 'latent_dim': 180, 'batch_size': 210, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 904.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 682.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 890.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 452.00 MiB memory in use. Of the allocated memory 135.25 MiB is allocated by PyTorch, and 32.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1acf1644,"{'temperature_head': 0.9, 'latent_dim': 287, 'batch_size': 203, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 770.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 890.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 420.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 700.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 722.00 MiB memory in use. Of the allocated memory 80.09 MiB is allocated by PyTorch, and 33.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bb3b06bc,"{'temperature_head': 0.8, 'latent_dim': 257, 'batch_size': 189, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 770.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 876.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 890.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 616.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 700.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 722.00 MiB memory in use. Of the allocated memory 79.85 MiB is allocated by PyTorch, and 34.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b2c61f91,"{'temperature_head': 0.7000000000000001, 'latent_dim': 168, 'batch_size': 182, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 818.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 876.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 672.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 664.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 748.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 135.16 MiB is allocated by PyTorch, and 32.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
83090565,"{'temperature_head': 0.8, 'latent_dim': 309, 'batch_size': 224, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 818.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 876.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 672.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 664.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 734.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 318.44 MiB is allocated by PyTorch, and 75.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b3a06d42,"{'temperature_head': 0.9, 'latent_dim': 264, 'batch_size': 213, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 910.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 878.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 694.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 692.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 135.91 MiB is allocated by PyTorch, and 32.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b115d501,"{'temperature_head': 0.7000000000000001, 'latent_dim': 195, 'batch_size': 164, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 910.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 878.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 696.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 692.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 554.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 135.37 MiB is allocated by PyTorch, and 36.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4aa3c808,"{'temperature_head': 1.0, 'latent_dim': 186, 'batch_size': 200, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 910.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 830.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 694.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 692.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 135.30 MiB is allocated by PyTorch, and 32.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
13e814ee,"{'temperature_head': 0.9, 'latent_dim': 241, 'batch_size': 154, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 910.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 830.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 428.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 738.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 692.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 554.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 135.73 MiB is allocated by PyTorch, and 36.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2e617907,"{'temperature_head': 0.8, 'latent_dim': 149, 'batch_size': 283, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 910.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 830.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 652.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 692.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 598.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 976.00 MiB memory in use. Process 29971 has 816.00 MiB memory in use. Of the allocated memory 223.10 MiB is allocated by PyTorch, and 34.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fee2bc2b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 298, 'batch_size': 145, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 954.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 830.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 464.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 736.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 646.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 932.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.17 MiB is allocated by PyTorch, and 37.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
83b9813e,"{'temperature_head': 0.9, 'latent_dim': 330, 'batch_size': 227, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 954.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 830.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 464.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 736.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 544.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 932.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.92 MiB is allocated by PyTorch, and 68.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fa76cbc9,"{'temperature_head': 0.7000000000000001, 'latent_dim': 168, 'batch_size': 209, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 748.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 544.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 932.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 134.65 MiB is allocated by PyTorch, and 69.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1c59f4e5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 116, 'batch_size': 261, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 748.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 588.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 932.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 46.27 MiB is allocated by PyTorch, and 37.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
22447c1f,"{'temperature_head': 0.9, 'latent_dim': 67, 'batch_size': 171, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 748.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 540.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 932.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 133.86 MiB is allocated by PyTorch, and 66.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f0b4957d,"{'temperature_head': 0.8, 'latent_dim': 88, 'batch_size': 289, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 748.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 588.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 932.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 46.05 MiB is allocated by PyTorch, and 37.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aafdec50,"{'temperature_head': 1.0, 'latent_dim': 227, 'batch_size': 184, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 790.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.62 MiB is allocated by PyTorch, and 32.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
37f52fc7,"{'temperature_head': 0.9, 'latent_dim': 50, 'batch_size': 159, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 510.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 790.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 134.23 MiB is allocated by PyTorch, and 33.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ef3c6b13,"{'temperature_head': 0.8, 'latent_dim': 286, 'batch_size': 197, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 790.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 80.08 MiB is allocated by PyTorch, and 31.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
32f5aea6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 128, 'batch_size': 278, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 790.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 134.84 MiB is allocated by PyTorch, and 33.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ba95dd0d,"{'temperature_head': 1.0, 'latent_dim': 372, 'batch_size': 222, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 790.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 80.75 MiB is allocated by PyTorch, and 35.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc951c6a,"{'temperature_head': 0.8, 'latent_dim': 194, 'batch_size': 176, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 956.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 790.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.36 MiB is allocated by PyTorch, and 32.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f6577dd3,"{'temperature_head': 0.9, 'latent_dim': 178, 'batch_size': 205, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 926.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 838.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
49120f39,"{'temperature_head': 0.6000000000000001, 'latent_dim': 315, 'batch_size': 150, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 926.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 838.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.31 MiB is allocated by PyTorch, and 31.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2968b928,"{'temperature_head': 0.9, 'latent_dim': 233, 'batch_size': 262, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 926.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 780.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 426.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 47.19 MiB is allocated by PyTorch, and 38.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
339e2c59,"{'temperature_head': 0.6000000000000001, 'latent_dim': 265, 'batch_size': 142, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 926.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 782.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 470.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 79.92 MiB is allocated by PyTorch, and 32.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d1fe6200,"{'temperature_head': 0.8, 'latent_dim': 208, 'batch_size': 295, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 970.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 732.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 470.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 79.47 MiB is allocated by PyTorch, and 34.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
64fcc7ac,"{'temperature_head': 0.7000000000000001, 'latent_dim': 138, 'batch_size': 128, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 970.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 510.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 732.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 134.92 MiB is allocated by PyTorch, and 33.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
15a5dc2d,"{'temperature_head': 0.9, 'latent_dim': 92, 'batch_size': 180, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 970.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 732.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 554.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 78.56 MiB is allocated by PyTorch, and 37.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6c3e86b0,"{'temperature_head': 1.0, 'latent_dim': 388, 'batch_size': 242, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 970.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 732.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 438.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 564.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 80.88 MiB is allocated by PyTorch, and 35.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
98de5860,"{'temperature_head': 0.8, 'latent_dim': 328, 'batch_size': 198, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 974.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 704.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 564.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.41 MiB is allocated by PyTorch, and 33.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9a8417bb,"{'temperature_head': 0.8, 'latent_dim': 18, 'batch_size': 308, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 974.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 420.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 704.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 610.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 45.51 MiB is allocated by PyTorch, and 34.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c68fdab7,"{'temperature_head': 0.7000000000000001, 'latent_dim': 162, 'batch_size': 300, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 974.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 704.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 604.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 231.11 MiB is allocated by PyTorch, and 32.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f8b7f260,"{'temperature_head': 0.6000000000000001, 'latent_dim': 4, 'batch_size': 324, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1022.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 420.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 508.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 512.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 704.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 45.40 MiB is allocated by PyTorch, and 34.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
57765b78,"{'temperature_head': 0.9, 'latent_dim': 248, 'batch_size': 158, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1022.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 478.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 442.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 660.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 282.40 MiB is allocated by PyTorch, and 37.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5f2f5f93,"{'temperature_head': 0.8, 'latent_dim': 416, 'batch_size': 246, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1022.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 460.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 442.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 706.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 81.10 MiB is allocated by PyTorch, and 38.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5f3ad9bd,"{'temperature_head': 0.7000000000000001, 'latent_dim': 187, 'batch_size': 225, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1022.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 510.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 718.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 245.35 MiB is allocated by PyTorch, and 132.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2a7a6ffa,"{'temperature_head': 0.7000000000000001, 'latent_dim': 27, 'batch_size': 292, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1022.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 696.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 498.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 418.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 45.58 MiB is allocated by PyTorch, and 32.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ac93b2a2,"{'temperature_head': 0.6000000000000001, 'latent_dim': 341, 'batch_size': 191, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1022.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 696.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 458.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 498.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 436.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 81.75 MiB is allocated by PyTorch, and 14.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 48, in calculate_loss
    loss = entropy_function(logits, targets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py"", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
"
45d801b5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 125, 'batch_size': 235, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 696.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 924.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 510.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 134.82 MiB is allocated by PyTorch, and 35.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
feced449,"{'temperature_head': 0.9, 'latent_dim': 367, 'batch_size': 213, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 512.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 742.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 924.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 450.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.71 MiB is allocated by PyTorch, and 35.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c06d239a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 278, 'batch_size': 167, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 556.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 742.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 924.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 512.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 450.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 80.02 MiB is allocated by PyTorch, and 31.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
82c2cbd8,"{'temperature_head': 0.9, 'latent_dim': 223, 'batch_size': 198, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 566.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 742.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 924.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 444.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 932.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.59 MiB is allocated by PyTorch, and 34.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8574cbc5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 469, 'batch_size': 315, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 742.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 976.00 MiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 924.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 934.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 137.51 MiB is allocated by PyTorch, and 32.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
232b898a,"{'temperature_head': 0.9, 'latent_dim': 289, 'batch_size': 147, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 132.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 802.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 770.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 468.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 444.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 830.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 306.46 MiB is allocated by PyTorch, and 183.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
521e1380,"{'temperature_head': 0.6000000000000001, 'latent_dim': 236, 'batch_size': 185, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 802.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 770.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 458.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 504.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.69 MiB is allocated by PyTorch, and 32.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7d3767d7,"{'temperature_head': 0.8, 'latent_dim': 66, 'batch_size': 235, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 802.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 770.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 562.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 448.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 78.36 MiB is allocated by PyTorch, and 29.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4bf7d10c,"{'temperature_head': 1.0, 'latent_dim': 320, 'batch_size': 162, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 802.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 770.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 562.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 31.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
32875369,"{'temperature_head': 0.9, 'latent_dim': 429, 'batch_size': 281, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 832.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 764.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 390.69 MiB is allocated by PyTorch, and 101.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b02ab9e,"{'temperature_head': 0.7000000000000001, 'latent_dim': 263, 'batch_size': 192, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 874.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.05 GiB memory in use. Process 29194 has 764.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 506.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.90 MiB is allocated by PyTorch, and 30.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
62020507,"{'temperature_head': 0.7000000000000001, 'latent_dim': 152, 'batch_size': 128, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 470.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 874.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.07 GiB memory in use. Process 29194 has 764.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 566.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 696.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.03 MiB is allocated by PyTorch, and 36.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4744cc43,"{'temperature_head': 1.0, 'latent_dim': 29, 'batch_size': 241, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 874.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.07 GiB memory in use. Process 29194 has 812.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 566.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 416.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 696.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 45.59 MiB is allocated by PyTorch, and 30.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
12aa1dd0,"{'temperature_head': 0.7000000000000001, 'latent_dim': 219, 'batch_size': 217, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 876.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.07 GiB memory in use. Process 29194 has 814.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 612.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 638.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 444.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 876.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 265.56 MiB is allocated by PyTorch, and 32.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9c0ac4e2,"{'temperature_head': 0.5, 'latent_dim': 15, 'batch_size': 322, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 876.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 512.00 MiB memory in use. Process 28792 has 1.10 GiB memory in use. Process 29194 has 968.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 612.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 450.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 828.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 77.96 MiB is allocated by PyTorch, and 32.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
23318178,"{'temperature_head': 0.7000000000000001, 'latent_dim': 52, 'batch_size': 261, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 876.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 968.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 624.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 506.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 430.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 828.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 134.25 MiB is allocated by PyTorch, and 31.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
25b087b4,"{'temperature_head': 0.8, 'latent_dim': 272, 'batch_size': 210, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 832.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 968.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 672.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 452.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 828.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 296.27 MiB is allocated by PyTorch, and 195.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bcc4d509,"{'temperature_head': 0.7000000000000001, 'latent_dim': 300, 'batch_size': 475, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 830.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 968.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 672.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 780.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 500.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 313.04 MiB is allocated by PyTorch, and 176.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b54b9211,"{'temperature_head': 0.8, 'latent_dim': 188, 'batch_size': 199, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 810.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 968.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 780.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 500.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 79.31 MiB is allocated by PyTorch, and 36.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0d2854d9,"{'temperature_head': 0.9, 'latent_dim': 237, 'batch_size': 156, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 810.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 780.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 500.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.70 MiB is allocated by PyTorch, and 36.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ff212994,"{'temperature_head': 0.7000000000000001, 'latent_dim': 336, 'batch_size': 168, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 810.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 768.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 598.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 47.99 MiB is allocated by PyTorch, and 38.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7dba1d86,"{'temperature_head': 0.5, 'latent_dim': 199, 'batch_size': 194, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 810.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 422.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 768.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 598.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 948.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 79.40 MiB is allocated by PyTorch, and 36.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ec6664b2,"{'temperature_head': 0.8, 'latent_dim': 110, 'batch_size': 231, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 810.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 504.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 768.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 598.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 778.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 574.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 200.70 MiB is allocated by PyTorch, and 33.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c98a9574,"{'temperature_head': 0.6000000000000001, 'latent_dim': 445, 'batch_size': 393, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 810.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 768.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 598.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 778.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 137.32 MiB is allocated by PyTorch, and 32.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c15ae533,"{'temperature_head': 0.8, 'latent_dim': 488, 'batch_size': 248, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 274.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 810.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.11 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 768.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 598.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 778.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 516.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 137.66 MiB is allocated by PyTorch, and 38.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9ecfdd9e,"{'temperature_head': 0.9, 'latent_dim': 386, 'batch_size': 222, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 188.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 854.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 680.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 768.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 778.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 560.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.86 MiB is allocated by PyTorch, and 35.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6cab76ac,"{'temperature_head': 0.8, 'latent_dim': 214, 'batch_size': 162, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 854.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 680.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 964.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 576.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 708.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 418.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.52 MiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
10bf3bfa,"{'temperature_head': 0.7000000000000001, 'latent_dim': 295, 'batch_size': 209, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 964.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 624.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 708.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 666.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.15 MiB is allocated by PyTorch, and 33.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3a1a08e0,"{'temperature_head': 0.8, 'latent_dim': 36, 'batch_size': 269, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 512.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 964.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 624.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 708.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 430.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 666.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 78.12 MiB is allocated by PyTorch, and 31.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0d81fc5f,"{'temperature_head': 0.5, 'latent_dim': 366, 'batch_size': 256, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 898.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 470.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 964.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 624.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 828.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 430.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 352.58 MiB is allocated by PyTorch, and 135.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a486a0cd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 347, 'batch_size': 173, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 898.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 964.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 640.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 430.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 886.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 136.56 MiB is allocated by PyTorch, and 35.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0987e276,"{'temperature_head': 0.9, 'latent_dim': 326, 'batch_size': 407, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 150.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 898.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 552.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 432.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 838.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 328.62 MiB is allocated by PyTorch, and 169.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
df158414,"{'temperature_head': 0.6000000000000001, 'latent_dim': 222, 'batch_size': 142, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 884.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 658.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 728.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 554.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 79.58 MiB is allocated by PyTorch, and 36.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4aca3c55,"{'temperature_head': 0.9, 'latent_dim': 379, 'batch_size': 189, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 884.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 694.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 728.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 556.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 442.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 81.51 MiB is allocated by PyTorch, and 20.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ea6f7599,"{'temperature_head': 0.8, 'latent_dim': 63, 'batch_size': 335, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 884.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 694.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 728.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 554.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 982.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 45.86 MiB is allocated by PyTorch, and 36.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d8c2294b,"{'temperature_head': 0.9, 'latent_dim': 76, 'batch_size': 155, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 578.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 824.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 604.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 936.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 134.44 MiB is allocated by PyTorch, and 35.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e329bf40,"{'temperature_head': 0.6000000000000001, 'latent_dim': 106, 'batch_size': 384, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 624.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 510.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 824.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 574.00 MiB memory in use. Process 29972 has 936.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 197.34 MiB is allocated by PyTorch, and 36.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9e9f5762,"{'temperature_head': 0.9, 'latent_dim': 262, 'batch_size': 206, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 616.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 824.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 624.00 MiB memory in use. Process 29972 has 936.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 79.89 MiB is allocated by PyTorch, and 32.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6bd05926,"{'temperature_head': 0.6000000000000001, 'latent_dim': 125, 'batch_size': 287, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 662.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 428.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 824.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 482.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 624.00 MiB memory in use. Process 29972 has 936.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 59.26 MiB is allocated by PyTorch, and 28.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
c63cf726,"{'temperature_head': 0.8, 'latent_dim': 426, 'batch_size': 263, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 662.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 440.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 824.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 624.00 MiB memory in use. Process 29972 has 936.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 86.06 MiB is allocated by PyTorch, and 13.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
a922b023,"{'temperature_head': 0.7000000000000001, 'latent_dim': 305, 'batch_size': 225, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 662.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1010.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 824.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 872.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 522.00 MiB memory in use. Process 29972 has 936.00 MiB memory in use. Process 29971 has 910.00 MiB memory in use. Of the allocated memory 135.72 MiB is allocated by PyTorch, and 46.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
79dae9bc,"{'temperature_head': 1.0, 'latent_dim': 233, 'batch_size': 167, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 862.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 720.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 504.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1012.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 482.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.25 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 668.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.67 MiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ec7256c5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 286, 'batch_size': 215, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 150.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 422.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 862.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 676.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 982.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.25 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 798.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 668.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 136.08 MiB is allocated by PyTorch, and 37.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7fd03750,"{'temperature_head': 0.8, 'latent_dim': 15, 'batch_size': 254, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 418.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 676.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 982.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 672.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.25 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 672.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 708.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 748.00 MiB memory in use. Process 29972 has 560.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 45.48 MiB is allocated by PyTorch, and 32.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8dba067f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 213, 'batch_size': 202, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 496.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 426.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 982.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 672.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.25 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 672.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 708.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 748.00 MiB memory in use. Process 29972 has 808.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 47.03 MiB is allocated by PyTorch, and 38.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a4912d51,"{'temperature_head': 1.0, 'latent_dim': 395, 'batch_size': 134, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 748.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.00 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 718.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 708.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 792.00 MiB memory in use. Process 29972 has 808.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 370.93 MiB is allocated by PyTorch, and 37.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c1fc62fe,"{'temperature_head': 1.0, 'latent_dim': 185, 'batch_size': 129, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 792.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.00 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 770.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 730.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 792.00 MiB memory in use. Process 29972 has 808.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.29 MiB is allocated by PyTorch, and 36.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d072caff,"{'temperature_head': 0.4, 'latent_dim': 97, 'batch_size': 146, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 416.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 676.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.00 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 770.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 568.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 792.00 MiB memory in use. Process 29972 has 808.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 192.60 MiB is allocated by PyTorch, and 35.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1fcb0684,"{'temperature_head': 0.5, 'latent_dim': 174, 'batch_size': 154, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 864.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 450.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.00 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 816.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 616.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 750.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 794.00 MiB memory in use. Process 29972 has 554.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 237.57 MiB is allocated by PyTorch, and 38.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7c495d44,"{'temperature_head': 0.5, 'latent_dim': 114, 'batch_size': 128, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 864.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 448.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 986.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 816.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 628.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 740.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 796.00 MiB memory in use. Process 29976 has 794.00 MiB memory in use. Process 29972 has 556.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 202.23 MiB is allocated by PyTorch, and 85.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6e6c3b5b,"{'temperature_head': 0.5, 'latent_dim': 129, 'batch_size': 165, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 854.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 660.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 656.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 728.00 MiB memory in use. Process 29971 has 504.00 MiB memory in use. Of the allocated memory 46.38 MiB is allocated by PyTorch, and 35.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aa4c1662,"{'temperature_head': 0.4, 'latent_dim': 159, 'batch_size': 182, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 502.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 854.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 660.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 656.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 660.00 MiB memory in use. Of the allocated memory 228.58 MiB is allocated by PyTorch, and 91.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2694a146,"{'temperature_head': 0.5, 'latent_dim': 111, 'batch_size': 159, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 504.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 854.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 708.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 656.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 456.00 MiB memory in use. Process 29971 has 660.00 MiB memory in use. Of the allocated memory 78.71 MiB is allocated by PyTorch, and 33.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b2041482,"{'temperature_head': 0.4, 'latent_dim': 194, 'batch_size': 144, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 746.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 676.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 704.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 692.00 MiB memory in use. Of the allocated memory 249.55 MiB is allocated by PyTorch, and 86.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
40a940f6,"{'temperature_head': 0.9, 'latent_dim': 197, 'batch_size': 303, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 670.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 426.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 674.00 MiB memory in use. Process 29972 has 456.00 MiB memory in use. Process 29971 has 734.00 MiB memory in use. Of the allocated memory 46.91 MiB is allocated by PyTorch, and 39.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
19424466,"{'temperature_head': 0.6000000000000001, 'latent_dim': 136, 'batch_size': 371, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 670.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 448.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 420.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 674.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 734.00 MiB memory in use. Of the allocated memory 46.43 MiB is allocated by PyTorch, and 33.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8df7f360,"{'temperature_head': 0.9, 'latent_dim': 200, 'batch_size': 342, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 670.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 440.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 628.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 734.00 MiB memory in use. Of the allocated memory 253.65 MiB is allocated by PyTorch, and 34.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
548ea6fe,"{'temperature_head': 0.9, 'latent_dim': 178, 'batch_size': 181, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 772.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 626.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 678.00 MiB memory in use. Process 29972 has 456.00 MiB memory in use. Process 29971 has 734.00 MiB memory in use. Of the allocated memory 240.73 MiB is allocated by PyTorch, and 97.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
86022aff,"{'temperature_head': 0.9, 'latent_dim': 219, 'batch_size': 192, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 674.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 690.00 MiB memory in use. Process 29971 has 784.00 MiB memory in use. Of the allocated memory 135.56 MiB is allocated by PyTorch, and 34.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bd916936,"{'temperature_head': 0.9, 'latent_dim': 230, 'batch_size': 227, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 674.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 690.00 MiB memory in use. Process 29971 has 792.00 MiB memory in use. Of the allocated memory 135.64 MiB is allocated by PyTorch, and 36.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f7be51cb,"{'temperature_head': 1.0, 'latent_dim': 121, 'batch_size': 354, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 674.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 690.00 MiB memory in use. Process 29971 has 792.00 MiB memory in use. Of the allocated memory 78.79 MiB is allocated by PyTorch, and 35.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1b158a64,"{'temperature_head': 0.5, 'latent_dim': 207, 'batch_size': 128, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 702.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 674.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 792.00 MiB memory in use. Of the allocated memory 79.46 MiB is allocated by PyTorch, and 36.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3618d5ef,"{'temperature_head': 0.6000000000000001, 'latent_dim': 138, 'batch_size': 174, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 702.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 674.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 792.00 MiB memory in use. Of the allocated memory 134.92 MiB is allocated by PyTorch, and 37.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f4930c34,"{'temperature_head': 0.9, 'latent_dim': 414, 'batch_size': 246, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 512.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 702.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 472.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 137.08 MiB is allocated by PyTorch, and 34.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
53dbae5f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 188, 'batch_size': 185, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 702.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 520.00 MiB memory in use. Process 29972 has 472.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 135.31 MiB is allocated by PyTorch, and 36.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
611b008c,"{'temperature_head': 1.0, 'latent_dim': 71, 'batch_size': 237, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 560.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 730.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 420.00 MiB memory in use. Process 29972 has 472.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 45.92 MiB is allocated by PyTorch, and 34.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3331ab0c,"{'temperature_head': 0.5, 'latent_dim': 246, 'batch_size': 201, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 560.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 748.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 444.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 135.77 MiB is allocated by PyTorch, and 36.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a59b7b2c,"{'temperature_head': 0.9, 'latent_dim': 89, 'batch_size': 220, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 876.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 134.54 MiB is allocated by PyTorch, and 39.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bb6da7d1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 177, 'batch_size': 139, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 876.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 716.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 470.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 79.23 MiB is allocated by PyTorch, and 36.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
66557116,"{'temperature_head': 0.7000000000000001, 'latent_dim': 126, 'batch_size': 159, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 876.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 504.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 674.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 470.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 78.83 MiB is allocated by PyTorch, and 37.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
604e1c09,"{'temperature_head': 1.0, 'latent_dim': 263, 'batch_size': 150, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 876.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 458.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 674.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 470.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 498.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 79.90 MiB is allocated by PyTorch, and 38.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b1f2966e,"{'temperature_head': 0.8, 'latent_dim': 80, 'batch_size': 210, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 794.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 718.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 498.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 134.47 MiB is allocated by PyTorch, and 35.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e5020d7c,"{'temperature_head': 0.5, 'latent_dim': 150, 'batch_size': 128, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 794.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 476.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 718.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 420.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 600.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 223.70 MiB is allocated by PyTorch, and 36.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d4380be8,"{'temperature_head': 0.7000000000000001, 'latent_dim': 383, 'batch_size': 259, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 794.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 718.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 136.84 MiB is allocated by PyTorch, and 35.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e907c61f,"{'temperature_head': 0.9, 'latent_dim': 212, 'batch_size': 240, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.01 GiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 794.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 718.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 79.50 MiB is allocated by PyTorch, and 36.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cd597f4d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 436, 'batch_size': 179, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 222.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 842.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 794.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 718.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 394.75 MiB is allocated by PyTorch, and 107.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b2e41d38,"{'temperature_head': 0.7000000000000001, 'latent_dim': 188, 'batch_size': 334, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 426.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 892.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 794.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 728.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 718.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 79.31 MiB is allocated by PyTorch, and 36.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a4bc9f45,"{'temperature_head': 0.5, 'latent_dim': 480, 'batch_size': 144, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 470.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 870.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 794.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 728.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 718.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 432.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 421.09 MiB is allocated by PyTorch, and 108.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
675e5797,"{'temperature_head': 0.1, 'latent_dim': 406, 'batch_size': 155, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 556.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 778.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 504.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 676.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 137.02 MiB is allocated by PyTorch, and 34.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0010f101,"{'temperature_head': 0.7000000000000001, 'latent_dim': 329, 'batch_size': 188, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 508.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 778.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 708.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 330.92 MiB is allocated by PyTorch, and 37.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c40b1046,"{'temperature_head': 0.8, 'latent_dim': 352, 'batch_size': 173, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 748.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 750.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 344.19 MiB is allocated by PyTorch, and 63.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bbcf788a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 145, 'batch_size': 203, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 750.00 MiB memory in use. Process 29972 has 558.00 MiB memory in use. Process 29971 has 840.00 MiB memory in use. Of the allocated memory 134.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1c4f7b1b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 203, 'batch_size': 135, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 774.00 MiB memory in use. Process 29972 has 558.00 MiB memory in use. Process 29971 has 854.00 MiB memory in use. Of the allocated memory 135.43 MiB is allocated by PyTorch, and 36.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ccd0c207,"{'temperature_head': 1.0, 'latent_dim': 241, 'batch_size': 265, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 802.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 774.00 MiB memory in use. Process 29972 has 624.00 MiB memory in use. Process 29971 has 854.00 MiB memory in use. Of the allocated memory 47.25 MiB is allocated by PyTorch, and 34.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
94014c6f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 463, 'batch_size': 318, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 774.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 774.00 MiB memory in use. Process 29972 has 624.00 MiB memory in use. Process 29971 has 854.00 MiB memory in use. Of the allocated memory 137.46 MiB is allocated by PyTorch, and 34.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cebbb686,"{'temperature_head': 0.7000000000000001, 'latent_dim': 319, 'batch_size': 399, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 646.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 774.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 770.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 624.00 MiB memory in use. Process 29971 has 854.00 MiB memory in use. Of the allocated memory 136.34 MiB is allocated by PyTorch, and 31.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a99fb693,"{'temperature_head': 0.8, 'latent_dim': 272, 'batch_size': 276, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 646.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.01 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 774.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 770.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 506.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 902.00 MiB memory in use. Of the allocated memory 135.97 MiB is allocated by PyTorch, and 30.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bb139758,"{'temperature_head': 0.6000000000000001, 'latent_dim': 254, 'batch_size': 289, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 452.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 658.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 732.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 764.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 652.00 MiB memory in use. Process 29972 has 558.00 MiB memory in use. Process 29971 has 866.00 MiB memory in use. Of the allocated memory 79.83 MiB is allocated by PyTorch, and 34.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
feab73b6,"{'temperature_head': 0.9, 'latent_dim': 98, 'batch_size': 326, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 660.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 732.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 764.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 652.00 MiB memory in use. Process 29972 has 560.00 MiB memory in use. Process 29971 has 866.00 MiB memory in use. Of the allocated memory 46.13 MiB is allocated by PyTorch, and 69.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4c3d9efd,"{'temperature_head': 0.8, 'latent_dim': 372, 'batch_size': 243, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 158.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 732.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 502.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 764.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 652.00 MiB memory in use. Process 29972 has 558.00 MiB memory in use. Process 29971 has 866.00 MiB memory in use. Of the allocated memory 136.75 MiB is allocated by PyTorch, and 29.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
27861628,"{'temperature_head': 0.7000000000000001, 'latent_dim': 132, 'batch_size': 214, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 778.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 842.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 764.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 700.00 MiB memory in use. Process 29972 has 558.00 MiB memory in use. Process 29971 has 866.00 MiB memory in use. Of the allocated memory 134.88 MiB is allocated by PyTorch, and 37.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
90f70a94,"{'temperature_head': 0.6000000000000001, 'latent_dim': 2, 'batch_size': 234, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 426.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 450.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 810.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 770.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 77.86 MiB is allocated by PyTorch, and 32.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b346794,"{'temperature_head': 0.9, 'latent_dim': 151, 'batch_size': 168, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 426.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 450.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 810.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 770.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.02 MiB is allocated by PyTorch, and 32.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
06d67763,"{'temperature_head': 0.7000000000000001, 'latent_dim': 173, 'batch_size': 178, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 458.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 498.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 770.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.20 MiB is allocated by PyTorch, and 38.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4880b303,"{'temperature_head': 0.5, 'latent_dim': 204, 'batch_size': 159, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 502.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 770.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.44 MiB is allocated by PyTorch, and 34.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f7adb369,"{'temperature_head': 0.6000000000000001, 'latent_dim': 217, 'batch_size': 203, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 512.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 770.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.54 MiB is allocated by PyTorch, and 36.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bf8595aa,"{'temperature_head': 0.7000000000000001, 'latent_dim': 54, 'batch_size': 223, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 512.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 450.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 770.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.27 MiB is allocated by PyTorch, and 31.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4282a0aa,"{'temperature_head': 0.5, 'latent_dim': 104, 'batch_size': 377, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 772.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.66 MiB is allocated by PyTorch, and 33.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6f38863f,"{'temperature_head': 0.8, 'latent_dim': 447, 'batch_size': 194, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 874.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 892.00 MiB memory in use. Process 29972 has 772.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 137.34 MiB is allocated by PyTorch, and 36.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3c8ee20a,"{'temperature_head': 0.8, 'latent_dim': 397, 'batch_size': 312, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 752.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 814.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 772.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 371.66 MiB is allocated by PyTorch, and 40.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6c2b60ed,"{'temperature_head': 0.7000000000000001, 'latent_dim': 79, 'batch_size': 150, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 808.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 772.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.46 MiB is allocated by PyTorch, and 35.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ed5a7c49,"{'temperature_head': 0.6000000000000001, 'latent_dim': 29, 'batch_size': 217, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 808.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 772.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.07 MiB is allocated by PyTorch, and 31.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ce21f32c,"{'temperature_head': 0.8, 'latent_dim': 502, 'batch_size': 188, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 472.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 808.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 784.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 472.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 137.77 MiB is allocated by PyTorch, and 36.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1e748c44,"{'temperature_head': 0.4, 'latent_dim': 347, 'batch_size': 164, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 808.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 784.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 472.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 136.56 MiB is allocated by PyTorch, and 33.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8156d268,"{'temperature_head': 1.0, 'latent_dim': 90, 'batch_size': 350, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 568.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 808.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 784.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 452.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 187.75 MiB is allocated by PyTorch, and 40.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
82a423ec,"{'temperature_head': 0.6000000000000001, 'latent_dim': 298, 'batch_size': 135, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 502.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 858.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 810.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 456.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 136.17 MiB is allocated by PyTorch, and 31.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
41e68525,"{'temperature_head': 0.9, 'latent_dim': 192, 'batch_size': 142, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 502.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 626.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 858.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 840.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 502.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 249.34 MiB is allocated by PyTorch, and 36.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c06d528f,"{'temperature_head': 0.8, 'latent_dim': 120, 'batch_size': 239, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 724.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 458.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 840.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 646.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.78 MiB is allocated by PyTorch, and 39.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5450a5b5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 319, 'batch_size': 231, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 736.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 458.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 840.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 648.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 136.34 MiB is allocated by PyTorch, and 31.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a2989897,"{'temperature_head': 1.0, 'latent_dim': 179, 'batch_size': 180, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 512.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 772.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 474.00 MiB memory in use. Process 29972 has 662.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
97fec329,"{'temperature_head': 0.8, 'latent_dim': 64, 'batch_size': 279, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 772.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 474.00 MiB memory in use. Process 29972 has 662.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.34 MiB is allocated by PyTorch, and 33.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6ba55eaf,"{'temperature_head': 0.6000000000000001, 'latent_dim': 360, 'batch_size': 260, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 772.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 662.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 80.66 MiB is allocated by PyTorch, and 35.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
363287cd,"{'temperature_head': 0.8, 'latent_dim': 139, 'batch_size': 330, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 662.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.93 MiB is allocated by PyTorch, and 35.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26a93576,"{'temperature_head': 0.9, 'latent_dim': 164, 'batch_size': 196, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 656.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.13 MiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8826ed8d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 285, 'batch_size': 205, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 906.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 656.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 136.07 MiB is allocated by PyTorch, and 31.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0466a037,"{'temperature_head': 0.4, 'latent_dim': 238, 'batch_size': 285, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 458.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 950.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 656.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.70 MiB is allocated by PyTorch, and 34.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8587eb97,"{'temperature_head': 0.4, 'latent_dim': 207, 'batch_size': 318, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 502.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 950.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 656.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.46 MiB is allocated by PyTorch, and 34.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f84cde4e,"{'temperature_head': 0.4, 'latent_dim': 227, 'batch_size': 269, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 502.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 950.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 656.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.62 MiB is allocated by PyTorch, and 36.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0311bee2,"{'temperature_head': 0.4, 'latent_dim': 215, 'batch_size': 280, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 502.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 978.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 950.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 750.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 746.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 702.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.52 MiB is allocated by PyTorch, and 38.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0cc6791a,"{'temperature_head': 0.5, 'latent_dim': 151, 'batch_size': 296, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 950.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 828.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 746.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 814.00 MiB memory in use. Process 29972 has 454.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.02 MiB is allocated by PyTorch, and 34.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
213f998b,"{'temperature_head': 0.5, 'latent_dim': 246, 'batch_size': 338, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 950.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 828.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 746.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 814.00 MiB memory in use. Process 29972 has 456.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.77 MiB is allocated by PyTorch, and 36.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aee4415b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 128, 'batch_size': 318, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 950.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 828.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 746.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 814.00 MiB memory in use. Process 29972 has 672.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.84 MiB is allocated by PyTorch, and 37.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6085ce8f,"{'temperature_head': 0.5, 'latent_dim': 142, 'batch_size': 326, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 418.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 502.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 952.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 876.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 788.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 768.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 458.00 MiB memory in use. Process 29972 has 894.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.95 MiB is allocated by PyTorch, and 39.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d98a3e5a,"{'temperature_head': 0.4, 'latent_dim': 172, 'batch_size': 265, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 952.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 876.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 788.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 768.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 894.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.19 MiB is allocated by PyTorch, and 36.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2eda76e4,"{'temperature_head': 0.5, 'latent_dim': 194, 'batch_size': 302, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 998.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 876.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 788.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 690.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 894.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.36 MiB is allocated by PyTorch, and 36.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3e7f0484,"{'temperature_head': 0.4, 'latent_dim': 159, 'batch_size': 275, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 998.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 876.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 788.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 690.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 894.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 46.61 MiB is allocated by PyTorch, and 35.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
efbe1c30,"{'temperature_head': 0.4, 'latent_dim': 212, 'batch_size': 249, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 430.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 998.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 876.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 788.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 690.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 894.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 69.48 MiB is allocated by PyTorch, and 20.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
b7a6dcb0,"{'temperature_head': 0.5, 'latent_dim': 107, 'batch_size': 264, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 440.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 454.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 998.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 876.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 788.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 690.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 894.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.68 MiB is allocated by PyTorch, and 35.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
46885e06,"{'temperature_head': 0.4, 'latent_dim': 182, 'batch_size': 147, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 416.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 658.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 510.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 998.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 876.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 790.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.27 MiB is allocated by PyTorch, and 34.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
402ff03a,"{'temperature_head': 0.5, 'latent_dim': 235, 'batch_size': 244, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 658.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 556.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 850.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 790.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.68 MiB is allocated by PyTorch, and 36.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cc4a1258,"{'temperature_head': 0.5, 'latent_dim': 203, 'batch_size': 255, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 402.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 686.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 602.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 850.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 792.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.43 MiB is allocated by PyTorch, and 36.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
77d74303,"{'temperature_head': 0.30000000000000004, 'latent_dim': 268, 'batch_size': 228, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 418.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 704.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 646.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 850.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 732.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 852.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 293.88 MiB is allocated by PyTorch, and 98.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
89541c68,"{'temperature_head': 0.5, 'latent_dim': 217, 'batch_size': 213, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 764.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 648.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 672.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.54 MiB is allocated by PyTorch, and 36.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cdf145e7,"{'temperature_head': 0.6000000000000001, 'latent_dim': 87, 'batch_size': 186, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 764.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 662.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 672.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.52 MiB is allocated by PyTorch, and 37.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d023f22a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 157, 'batch_size': 336, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 662.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 540.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 660.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 718.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.07 MiB is allocated by PyTorch, and 36.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92f3c309,"{'temperature_head': 0.6000000000000001, 'latent_dim': 229, 'batch_size': 130, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 446.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 560.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 650.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 762.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 271.63 MiB is allocated by PyTorch, and 38.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
097a7559,"{'temperature_head': 0.6000000000000001, 'latent_dim': 533, 'batch_size': 134, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 446.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 560.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 650.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 762.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 138.44 MiB is allocated by PyTorch, and 33.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
654aee8c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 204, 'batch_size': 324, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 608.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 690.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 762.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.44 MiB is allocated by PyTorch, and 36.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
179fda14,"{'temperature_head': 0.5, 'latent_dim': 129, 'batch_size': 129, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 512.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 604.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 690.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 810.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.85 MiB is allocated by PyTorch, and 35.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f56d468b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 245, 'batch_size': 269, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 660.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 856.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 930.00 MiB memory in use. Process 29972 has 938.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 280.60 MiB is allocated by PyTorch, and 39.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ab59ad9a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 147, 'batch_size': 306, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 466.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 600.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 856.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 930.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 221.90 MiB is allocated by PyTorch, and 38.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2d5ba264,"{'temperature_head': 0.6000000000000001, 'latent_dim': 261, 'batch_size': 292, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 466.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 654.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 856.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 930.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.89 MiB is allocated by PyTorch, and 32.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fd70a0a4,"{'temperature_head': 0.5, 'latent_dim': 223, 'batch_size': 277, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 466.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 654.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 480.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 856.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 930.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 47.11 MiB is allocated by PyTorch, and 36.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0ccbe826,"{'temperature_head': 0.6000000000000001, 'latent_dim': 237, 'batch_size': 140, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 564.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 652.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 275.81 MiB is allocated by PyTorch, and 36.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
30eeb519,"{'temperature_head': 0.5, 'latent_dim': 281, 'batch_size': 129, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 564.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 652.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 80.04 MiB is allocated by PyTorch, and 29.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f5c13531,"{'temperature_head': 0.6000000000000001, 'latent_dim': 210, 'batch_size': 328, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 610.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 900.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.49 MiB is allocated by PyTorch, and 32.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
77d80dda,"{'temperature_head': 0.5, 'latent_dim': 134, 'batch_size': 301, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 646.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 858.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.89 MiB is allocated by PyTorch, and 37.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ddb2466e,"{'temperature_head': 0.4, 'latent_dim': 118, 'batch_size': 357, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 646.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 858.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.77 MiB is allocated by PyTorch, and 35.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ca119140,"{'temperature_head': 0.5, 'latent_dim': 160, 'batch_size': 284, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 646.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 610.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 858.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 794.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.09 MiB is allocated by PyTorch, and 36.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
553c9fdb,"{'temperature_head': 0.6000000000000001, 'latent_dim': 145, 'batch_size': 273, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 646.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 658.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 656.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 858.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 134.98 MiB is allocated by PyTorch, and 35.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
555f0955,"{'temperature_head': 0.5, 'latent_dim': 76, 'batch_size': 158, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 646.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 658.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 656.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 858.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.44 MiB is allocated by PyTorch, and 37.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
288d0d7e,"{'temperature_head': 0.6000000000000001, 'latent_dim': 251, 'batch_size': 147, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 660.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 658.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 656.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 858.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 284.20 MiB is allocated by PyTorch, and 35.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1f6561ff,"{'temperature_head': 0.5, 'latent_dim': 177, 'batch_size': 258, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 658.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 656.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 902.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 618.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 496.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 239.87 MiB is allocated by PyTorch, and 38.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aaed85fa,"{'temperature_head': 0.6000000000000001, 'latent_dim': 268, 'batch_size': 337, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 658.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 656.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 902.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 618.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.94 MiB is allocated by PyTorch, and 34.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
31c0d073,"{'temperature_head': 0.6000000000000001, 'latent_dim': 218, 'batch_size': 134, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 658.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 700.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 664.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 902.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.55 MiB is allocated by PyTorch, and 36.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cb69d6e4,"{'temperature_head': 0.6000000000000001, 'latent_dim': 90, 'batch_size': 366, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 502.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 450.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 700.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 800.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.55 MiB is allocated by PyTorch, and 35.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e51a331a,"{'temperature_head': 0.5, 'latent_dim': 95, 'batch_size': 157, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 662.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 468.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 800.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.59 MiB is allocated by PyTorch, and 37.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
345c395e,"{'temperature_head': 0.6000000000000001, 'latent_dim': 165, 'batch_size': 267, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 498.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 660.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 416.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 800.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.13 MiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9dc883c1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 236, 'batch_size': 232, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 660.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.69 MiB is allocated by PyTorch, and 36.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
44bfb8aa,"{'temperature_head': 0.6000000000000001, 'latent_dim': 294, 'batch_size': 223, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 442.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 498.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 638.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 80.14 MiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
190ee02c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 156, 'batch_size': 281, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 512.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 418.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 638.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 79.06 MiB is allocated by PyTorch, and 36.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ade7018f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 133, 'batch_size': 138, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 592.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 213.51 MiB is allocated by PyTorch, and 38.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
19af0393,"{'temperature_head': 0.5, 'latent_dim': 248, 'batch_size': 322, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 468.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 638.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 47.31 MiB is allocated by PyTorch, and 38.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c2b2fd5d,"{'temperature_head': 0.4, 'latent_dim': 97, 'batch_size': 169, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 638.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 592.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 728.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.60 MiB is allocated by PyTorch, and 37.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c7cb4676,"{'temperature_head': 0.6000000000000001, 'latent_dim': 217, 'batch_size': 500, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 638.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 560.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 728.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.54 MiB is allocated by PyTorch, and 36.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
23f72aae,"{'temperature_head': 0.7000000000000001, 'latent_dim': 173, 'batch_size': 147, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 496.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 638.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 442.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 616.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 237.47 MiB is allocated by PyTorch, and 38.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
29df8f53,"{'temperature_head': 0.7000000000000001, 'latent_dim': 258, 'batch_size': 256, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 562.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 730.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.86 MiB is allocated by PyTorch, and 32.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c08ea23b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 138, 'batch_size': 129, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 562.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 732.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 448.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 458.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 78.92 MiB is allocated by PyTorch, and 39.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b28f9e94,"{'temperature_head': 0.6000000000000001, 'latent_dim': 186, 'batch_size': 209, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 736.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 738.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.30 MiB is allocated by PyTorch, and 36.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6b57944b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 202, 'batch_size': 275, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 736.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 666.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 254.92 MiB is allocated by PyTorch, and 71.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5afc6406,"{'temperature_head': 0.5, 'latent_dim': 222, 'batch_size': 245, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 736.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 666.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.58 MiB is allocated by PyTorch, and 38.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
176ce969,"{'temperature_head': 0.6000000000000001, 'latent_dim': 153, 'batch_size': 143, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 736.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 450.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 666.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 912.00 MiB memory in use. Of the allocated memory 135.04 MiB is allocated by PyTorch, and 36.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5a948eb1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 274, 'batch_size': 314, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 784.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 666.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.99 MiB is allocated by PyTorch, and 34.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4ae85d59,"{'temperature_head': 0.5, 'latent_dim': 297, 'batch_size': 286, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 730.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 666.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 940.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 311.66 MiB is allocated by PyTorch, and 78.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6edc1824,"{'temperature_head': 0.7000000000000001, 'latent_dim': 178, 'batch_size': 219, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 778.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 500.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 564.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 978.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bf41ace1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 308, 'batch_size': 390, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 732.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 500.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 606.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 564.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 904.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 978.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 80.25 MiB is allocated by PyTorch, and 33.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9285399f,"{'temperature_head': 0.5, 'latent_dim': 114, 'batch_size': 161, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 732.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 556.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 610.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 916.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 506.00 MiB memory in use. Process 29972 has 978.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.73 MiB is allocated by PyTorch, and 31.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ee17b094,"{'temperature_head': 0.5, 'latent_dim': 138, 'batch_size': 176, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 456.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 732.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 608.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 904.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 590.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 916.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 978.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 216.92 MiB is allocated by PyTorch, and 33.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a00bc472,"{'temperature_head': 0.5, 'latent_dim': 109, 'batch_size': 137, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 654.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 450.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 864.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 578.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 916.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 674.00 MiB memory in use. Process 29972 has 1024.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 199.14 MiB is allocated by PyTorch, and 38.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
19bd02f6,"{'temperature_head': 0.6000000000000001, 'latent_dim': 153, 'batch_size': 178, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 654.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 864.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 624.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 916.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 674.00 MiB memory in use. Process 29972 has 1024.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.56 MiB is allocated by PyTorch, and 37.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
13c4a911,"{'temperature_head': 0.7000000000000001, 'latent_dim': 127, 'batch_size': 156, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 470.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 692.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 864.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 598.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 674.00 MiB memory in use. Process 29972 has 1024.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 210.33 MiB is allocated by PyTorch, and 47.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2545e445,"{'temperature_head': 0.7000000000000001, 'latent_dim': 160, 'batch_size': 185, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 620.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 872.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 630.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 542.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1024.00 MiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 229.18 MiB is allocated by PyTorch, and 60.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8ce9f1ee,"{'temperature_head': 0.5, 'latent_dim': 170, 'batch_size': 205, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 872.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 680.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 622.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.17 MiB is allocated by PyTorch, and 36.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eae0b921,"{'temperature_head': 0.1, 'latent_dim': 146, 'batch_size': 141, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 510.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 872.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 680.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 622.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.51 MiB is allocated by PyTorch, and 35.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
780bd42d,"{'temperature_head': 1.0, 'latent_dim': 50, 'batch_size': 134, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 872.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 680.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 622.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.23 MiB is allocated by PyTorch, and 33.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7fcd7be2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 194, 'batch_size': 172, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 594.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 680.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.36 MiB is allocated by PyTorch, and 34.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
14d7cb47,"{'temperature_head': 0.5, 'latent_dim': 72, 'batch_size': 190, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 594.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 708.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d15db937,"{'temperature_head': 0.4, 'latent_dim': 89, 'batch_size': 202, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 594.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 726.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.06 MiB is allocated by PyTorch, and 39.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5119116f,"{'temperature_head': 0.5, 'latent_dim': 157, 'batch_size': 147, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 818.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 812.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 604.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 227.89 MiB is allocated by PyTorch, and 36.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
51d0f24d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 113, 'batch_size': 135, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 818.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 814.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 604.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.73 MiB is allocated by PyTorch, and 33.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
949377f5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 128, 'batch_size': 195, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 658.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 818.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 502.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 684.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 624.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 210.34 MiB is allocated by PyTorch, and 73.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3c557c58,"{'temperature_head': 0.6000000000000001, 'latent_dim': 61, 'batch_size': 175, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 658.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 818.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 684.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 634.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.32 MiB is allocated by PyTorch, and 35.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
df684258,"{'temperature_head': 0.7000000000000001, 'latent_dim': 163, 'batch_size': 187, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 752.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 912.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 818.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 470.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 560.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 684.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.12 MiB is allocated by PyTorch, and 34.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c71feea4,"{'temperature_head': 1.0, 'latent_dim': 140, 'batch_size': 152, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 842.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 752.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 418.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 958.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 818.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 470.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 684.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.94 MiB is allocated by PyTorch, and 37.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a548e4db,"{'temperature_head': 0.6000000000000001, 'latent_dim': 119, 'batch_size': 215, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 804.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 752.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 984.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 554.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 674.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.77 MiB is allocated by PyTorch, and 37.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
461ca386,"{'temperature_head': 0.7000000000000001, 'latent_dim': 170, 'batch_size': 143, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 804.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 760.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 984.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 556.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.17 MiB is allocated by PyTorch, and 36.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3fb78c83,"{'temperature_head': 0.4, 'latent_dim': 213, 'batch_size': 168, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 804.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 760.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 984.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.51 MiB is allocated by PyTorch, and 36.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
50d790a5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 549, 'batch_size': 198, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 196.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 760.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 766.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 848.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 463.14 MiB is allocated by PyTorch, and 44.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03cb12b0,"{'temperature_head': 0.5, 'latent_dim': 182, 'batch_size': 130, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 760.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 766.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 848.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 620.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 243.27 MiB is allocated by PyTorch, and 36.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c610cd3a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 130, 'batch_size': 155, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 760.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 766.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 720.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.86 MiB is allocated by PyTorch, and 37.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0d4733ee,"{'temperature_head': 0.5, 'latent_dim': 148, 'batch_size': 128, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 764.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.00 MiB is allocated by PyTorch, and 39.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e4f086e4,"{'temperature_head': 0.5, 'latent_dim': 165, 'batch_size': 261, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 424.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.66 MiB is allocated by PyTorch, and 39.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a1d9ef15,"{'temperature_head': 0.6000000000000001, 'latent_dim': 109, 'batch_size': 212, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 57.41 MiB is allocated by PyTorch, and 28.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
2e2ce9f0,"{'temperature_head': 0.7000000000000001, 'latent_dim': 183, 'batch_size': 203, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 410.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 65.46 MiB is allocated by PyTorch, and 4.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
96e1c084,"{'temperature_head': 0.9, 'latent_dim': 31, 'batch_size': 150, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 57.30 MiB is allocated by PyTorch, and 28.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
59a43afe,"{'temperature_head': 0.4, 'latent_dim': 16, 'batch_size': 178, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 57.21 MiB is allocated by PyTorch, and 28.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
da4e0119,"{'temperature_head': 0.6000000000000001, 'latent_dim': 138, 'batch_size': 353, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 57.23 MiB is allocated by PyTorch, and 28.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
3ffa15c5,"{'temperature_head': 0.5, 'latent_dim': 227, 'batch_size': 230, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 412.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 68.82 MiB is allocated by PyTorch, and 3.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ec847b1c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 124, 'batch_size': 128, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 762.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 57.50 MiB is allocated by PyTorch, and 28.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
b0a6b894,"{'temperature_head': 0.4, 'latent_dim': 566, 'batch_size': 159, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 228.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 506.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 436.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 808.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 138.94 MiB is allocated by PyTorch, and 33.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
29aca688,"{'temperature_head': 0.5, 'latent_dim': 213, 'batch_size': 137, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 808.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 896.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 636.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 261.51 MiB is allocated by PyTorch, and 34.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3d87f7d0,"{'temperature_head': 0.9, 'latent_dim': 587, 'batch_size': 270, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 688.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 642.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 946.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 676.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 524.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 430.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 672.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 138.44 MiB is allocated by PyTorch, and 45.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
929a3bbe,"{'temperature_head': 0.7000000000000001, 'latent_dim': 38, 'batch_size': 174, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 714.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 704.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 946.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 706.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 418.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 432.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 672.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 45.66 MiB is allocated by PyTorch, and 32.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
acadf702,"{'temperature_head': 1.0, 'latent_dim': 184, 'batch_size': 154, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 714.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 704.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 946.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 410.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 432.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 672.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 65.50 MiB is allocated by PyTorch, and 4.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
5f41a2ac,"{'temperature_head': 0.4, 'latent_dim': 478, 'batch_size': 129, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 714.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 668.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 946.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 458.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 432.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 672.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 91.25 MiB is allocated by PyTorch, and 26.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 48, in calculate_loss
    loss = entropy_function(logits, targets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py"", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
"
24ed8e32,"{'temperature_head': 0.7000000000000001, 'latent_dim': 115, 'batch_size': 181, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 714.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 946.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 580.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 718.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 202.74 MiB is allocated by PyTorch, and 37.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4fab49f5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 256, 'batch_size': 128, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 760.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 848.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 628.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 718.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.84 MiB is allocated by PyTorch, and 36.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
85d397d2,"{'temperature_head': 0.5, 'latent_dim': 168, 'batch_size': 236, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 850.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 810.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 848.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 450.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 720.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.16 MiB is allocated by PyTorch, and 34.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4002083f,"{'temperature_head': 0.8, 'latent_dim': 609, 'batch_size': 265, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 362.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 216.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 848.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 810.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 848.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 538.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 138.10 MiB is allocated by PyTorch, and 59.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
df8446d4,"{'temperature_head': 0.9, 'latent_dim': 23, 'batch_size': 153, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 848.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 508.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 894.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 644.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 732.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 590.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.02 MiB is allocated by PyTorch, and 31.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7bcbacdb,"{'temperature_head': 0.7000000000000001, 'latent_dim': 283, 'batch_size': 297, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 160.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 914.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 762.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 896.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 690.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 470.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 648.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.06 MiB is allocated by PyTorch, and 33.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
063d078a,"{'temperature_head': 0.5, 'latent_dim': 69, 'batch_size': 318, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 914.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 510.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 770.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.38 MiB is allocated by PyTorch, and 31.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
583a0755,"{'temperature_head': 0.9, 'latent_dim': 42, 'batch_size': 171, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 914.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 504.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 668.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 888.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 770.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 554.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.17 MiB is allocated by PyTorch, and 29.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3e58772d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 244, 'batch_size': 258, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 676.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 898.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 818.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 712.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 279.50 MiB is allocated by PyTorch, and 56.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ae57524a,"{'temperature_head': 0.5, 'latent_dim': 262, 'batch_size': 138, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 674.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 468.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 914.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 898.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 864.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 712.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.89 MiB is allocated by PyTorch, and 34.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
da36e3e9,"{'temperature_head': 0.4, 'latent_dim': 226, 'batch_size': 129, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 672.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 684.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 972.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 468.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 682.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 424.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 848.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 708.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 47.13 MiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
26097739,"{'temperature_head': 0.6000000000000001, 'latent_dim': 170, 'batch_size': 273, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 684.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 972.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 686.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 824.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 710.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.17 MiB is allocated by PyTorch, and 32.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dbf2e389,"{'temperature_head': 0.7000000000000001, 'latent_dim': 192, 'batch_size': 470, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 504.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 684.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 972.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 686.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 448.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 824.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 624.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 249.34 MiB is allocated by PyTorch, and 34.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a9ad183f,"{'temperature_head': 0.8, 'latent_dim': 207, 'batch_size': 342, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 504.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 684.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 972.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 634.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 824.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 668.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 257.84 MiB is allocated by PyTorch, and 36.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5fe38f03,"{'temperature_head': 0.6000000000000001, 'latent_dim': 159, 'batch_size': 327, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 556.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 972.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 824.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 662.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 228.58 MiB is allocated by PyTorch, and 93.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a3facc60,"{'temperature_head': 0.5, 'latent_dim': 178, 'batch_size': 303, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 558.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 458.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 972.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 824.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 706.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.24 MiB is allocated by PyTorch, and 38.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a560f101,"{'temperature_head': 0.9, 'latent_dim': 2, 'batch_size': 191, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 564.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 706.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 77.86 MiB is allocated by PyTorch, and 38.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
59033ae0,"{'temperature_head': 0.4, 'latent_dim': 120, 'batch_size': 141, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 564.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 502.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 720.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 424.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 706.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.30 MiB is allocated by PyTorch, and 37.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c2353271,"{'temperature_head': 0.6000000000000001, 'latent_dim': 140, 'batch_size': 282, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 708.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 706.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.94 MiB is allocated by PyTorch, and 35.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
664505fc,"{'temperature_head': 0.5, 'latent_dim': 218, 'batch_size': 267, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 642.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 706.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 264.43 MiB is allocated by PyTorch, and 37.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
90d919bc,"{'temperature_head': 0.8, 'latent_dim': 272, 'batch_size': 350, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 674.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 688.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 296.78 MiB is allocated by PyTorch, and 37.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
40450fc3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 333, 'batch_size': 247, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 720.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 688.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.45 MiB is allocated by PyTorch, and 31.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
30d251fb,"{'temperature_head': 0.7000000000000001, 'latent_dim': 188, 'batch_size': 147, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 720.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 698.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 246.81 MiB is allocated by PyTorch, and 111.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
071c1cb1,"{'temperature_head': 1.0, 'latent_dim': 83, 'batch_size': 164, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 678.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 746.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.49 MiB is allocated by PyTorch, and 35.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
531a004f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 439, 'batch_size': 129, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 202.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 678.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 568.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.77 MiB is allocated by PyTorch, and 91.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a854c128,"{'temperature_head': 0.8, 'latent_dim': 312, 'batch_size': 295, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 678.00 MiB memory in use. Process 25586 has 1024.00 MiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 714.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.28 MiB is allocated by PyTorch, and 31.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
03bf9894,"{'temperature_head': 0.9, 'latent_dim': 35, 'batch_size': 189, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 714.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 450.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 554.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.12 MiB is allocated by PyTorch, and 31.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1eefe936,"{'temperature_head': 0.7000000000000001, 'latent_dim': 126, 'batch_size': 260, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 434.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 714.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 480.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.83 MiB is allocated by PyTorch, and 33.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
64753168,"{'temperature_head': 0.9, 'latent_dim': 105, 'batch_size': 208, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 418.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 718.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.66 MiB is allocated by PyTorch, and 39.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b746d4a1,"{'temperature_head': 0.5, 'latent_dim': 206, 'batch_size': 317, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 466.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 630.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 257.45 MiB is allocated by PyTorch, and 32.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b7d0cce2,"{'temperature_head': 0.6000000000000001, 'latent_dim': 172, 'batch_size': 231, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 466.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 630.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.19 MiB is allocated by PyTorch, and 36.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dda6bb2f,"{'temperature_head': 0.8, 'latent_dim': 149, 'batch_size': 240, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 738.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.01 MiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f893a01b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 294, 'batch_size': 144, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 432.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 738.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 774.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 872.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.14 MiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
734b81e3,"{'temperature_head': 0.30000000000000004, 'latent_dim': 248, 'batch_size': 152, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 784.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 788.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 822.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 828.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.78 MiB is allocated by PyTorch, and 36.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
09242090,"{'temperature_head': 0.5, 'latent_dim': 216, 'batch_size': 128, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 454.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 786.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 672.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 822.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 890.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 828.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.53 MiB is allocated by PyTorch, and 36.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bf1a3d17,"{'temperature_head': 0.6000000000000001, 'latent_dim': 127, 'batch_size': 358, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 654.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 786.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 672.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 844.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 800.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 776.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.84 MiB is allocated by PyTorch, and 35.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3e8790bd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 116, 'batch_size': 328, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 684.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 786.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 672.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 844.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 800.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 422.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 776.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.27 MiB is allocated by PyTorch, and 35.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a0c3e7d6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 229, 'batch_size': 128, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 684.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 788.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 416.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 844.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 800.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 662.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 776.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.63 MiB is allocated by PyTorch, and 32.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0cefef31,"{'temperature_head': 0.5, 'latent_dim': 281, 'batch_size': 252, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 684.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 738.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 428.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 844.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 804.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 658.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 820.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 301.66 MiB is allocated by PyTorch, and 96.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7f1c5223,"{'temperature_head': 0.4, 'latent_dim': 158, 'batch_size': 262, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 730.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 804.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 662.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 424.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 704.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.60 MiB is allocated by PyTorch, and 37.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8a617261,"{'temperature_head': 1.0, 'latent_dim': 41, 'batch_size': 172, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 730.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 420.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 804.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 662.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 704.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 45.69 MiB is allocated by PyTorch, and 34.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9a5a9174,"{'temperature_head': 0.9, 'latent_dim': 89, 'batch_size': 182, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 688.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 804.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 662.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 422.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.06 MiB is allocated by PyTorch, and 35.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
af0e190b,"{'temperature_head': 1.0, 'latent_dim': 55, 'batch_size': 208, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 688.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 420.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 804.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 662.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 45.80 MiB is allocated by PyTorch, and 34.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8103bc9d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 179, 'batch_size': 223, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 688.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 804.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 618.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 241.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bcfe61c7,"{'temperature_head': 0.5, 'latent_dim': 134, 'batch_size': 299, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 688.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 592.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 804.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 214.89 MiB is allocated by PyTorch, and 37.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d8673c51,"{'temperature_head': 1.0, 'latent_dim': 99, 'batch_size': 188, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 736.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 608.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 696.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.62 MiB is allocated by PyTorch, and 35.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
edda87c4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 413, 'batch_size': 150, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 736.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 608.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 696.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 758.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 381.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9d4bd23c,"{'temperature_head': 1.0, 'latent_dim': 110, 'batch_size': 164, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 714.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 616.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 696.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 804.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 430.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 822.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.70 MiB is allocated by PyTorch, and 35.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d1011c51,"{'temperature_head': 0.9, 'latent_dim': 513, 'batch_size': 198, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 714.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 616.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 744.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 702.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 432.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 866.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 441.41 MiB is allocated by PyTorch, and 84.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cd2b0987,"{'temperature_head': 0.9, 'latent_dim': 70, 'batch_size': 144, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 714.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 616.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 744.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 702.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 398.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 912.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.39 MiB is allocated by PyTorch, and 31.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5ca6b341,"{'temperature_head': 1.0, 'latent_dim': 319, 'batch_size': 178, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 714.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 458.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 616.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 744.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 702.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 426.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 762.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 324.43 MiB is allocated by PyTorch, and 97.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
82112159,"{'temperature_head': 0.9, 'latent_dim': 346, 'batch_size': 151, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 714.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 744.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 702.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 448.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d7ff6ee1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 207, 'batch_size': 335, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 764.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 672.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.46 MiB is allocated by PyTorch, and 34.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cbcddb1d,"{'temperature_head': 0.8, 'latent_dim': 195, 'batch_size': 237, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 764.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 450.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 672.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.37 MiB is allocated by PyTorch, and 34.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a995ffa1,"{'temperature_head': 1.0, 'latent_dim': 37, 'batch_size': 170, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 796.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 422.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 672.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 45.66 MiB is allocated by PyTorch, and 36.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1ce3b7da,"{'temperature_head': 0.4, 'latent_dim': 226, 'batch_size': 137, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 796.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 672.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 47.13 MiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d30602a5,"{'temperature_head': 0.8, 'latent_dim': 173, 'batch_size': 292, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 784.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 448.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 672.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.20 MiB is allocated by PyTorch, and 34.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
617a1b19,"{'temperature_head': 0.5, 'latent_dim': 139, 'batch_size': 225, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 784.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 672.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.93 MiB is allocated by PyTorch, and 33.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
db271138,"{'temperature_head': 1.0, 'latent_dim': 632, 'batch_size': 162, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 784.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 942.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 464.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 672.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 102.39 MiB is allocated by PyTorch, and 21.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
894515f4,"{'temperature_head': 0.9, 'latent_dim': 118, 'batch_size': 200, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 784.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 406.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 648.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 804.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.77 MiB is allocated by PyTorch, and 35.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c9609ac6,"{'temperature_head': 0.6000000000000001, 'latent_dim': 269, 'batch_size': 376, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 784.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 390.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 406.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 510.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 648.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 806.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.95 MiB is allocated by PyTorch, and 32.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cbc494ae,"{'temperature_head': 0.9, 'latent_dim': 109, 'batch_size': 164, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 784.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 560.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 648.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 806.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.69 MiB is allocated by PyTorch, and 35.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f6affc9d,"{'temperature_head': 0.9, 'latent_dim': 3, 'batch_size': 176, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 784.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 512.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 834.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 506.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 648.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 806.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 133.87 MiB is allocated by PyTorch, and 32.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a986fe81,"{'temperature_head': 1.0, 'latent_dim': 58, 'batch_size': 216, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 830.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 512.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 704.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 554.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 696.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 806.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.30 MiB is allocated by PyTorch, and 31.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a43a31a1,"{'temperature_head': 0.9, 'latent_dim': 126, 'batch_size': 204, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 830.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 704.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 586.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 696.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 806.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 209.32 MiB is allocated by PyTorch, and 36.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
57f9ede0,"{'temperature_head': 0.8, 'latent_dim': 210, 'batch_size': 233, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 832.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 646.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 760.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 259.13 MiB is allocated by PyTorch, and 160.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d97990a8,"{'temperature_head': 0.5, 'latent_dim': 163, 'batch_size': 245, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 832.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 646.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 760.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.12 MiB is allocated by PyTorch, and 38.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e7b22a9,"{'temperature_head': 0.5, 'latent_dim': 152, 'batch_size': 281, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 832.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 646.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 760.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 46.56 MiB is allocated by PyTorch, and 37.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
92b13557,"{'temperature_head': 0.6000000000000001, 'latent_dim': 259, 'batch_size': 310, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 986.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 646.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 944.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 506.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 556.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.87 MiB is allocated by PyTorch, and 32.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c9d2ecfc,"{'temperature_head': 0.9, 'latent_dim': 454, 'batch_size': 145, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 986.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 692.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 900.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 568.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 137.39 MiB is allocated by PyTorch, and 36.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a825cf0f,"{'temperature_head': 0.4, 'latent_dim': 287, 'batch_size': 364, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 986.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 678.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 900.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 556.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 614.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 556.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 306.09 MiB is allocated by PyTorch, and 31.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f0b20412,"{'temperature_head': 0.9, 'latent_dim': 93, 'batch_size': 156, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 986.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 900.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 658.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 614.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 654.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.57 MiB is allocated by PyTorch, and 37.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c44f333a,"{'temperature_head': 0.8, 'latent_dim': 46, 'batch_size': 193, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 986.00 MiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 686.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 900.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 660.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 422.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 614.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 654.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.20 MiB is allocated by PyTorch, and 31.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2153d00b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 143, 'batch_size': 128, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.01 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 686.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 900.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 596.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 690.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 219.50 MiB is allocated by PyTorch, and 36.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
42b968a1,"{'temperature_head': 1.0, 'latent_dim': 106, 'batch_size': 172, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.01 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 686.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 900.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 646.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 692.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 576.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 197.34 MiB is allocated by PyTorch, and 38.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
68ffd50b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 178, 'batch_size': 263, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.01 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 732.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 434.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 646.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 692.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.24 MiB is allocated by PyTorch, and 30.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e97688fd,"{'temperature_head': 0.5, 'latent_dim': 221, 'batch_size': 382, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.01 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 734.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 434.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 510.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 646.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 692.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.57 MiB is allocated by PyTorch, and 36.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1aed5b86,"{'temperature_head': 1.0, 'latent_dim': 30, 'batch_size': 211, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.01 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 734.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 434.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 646.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 692.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 61.87 MiB is allocated by PyTorch, and 30.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
08d7db0d,"{'temperature_head': 0.9, 'latent_dim': 331, 'batch_size': 150, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.02 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 734.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 448.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 558.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 542.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 728.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 135.93 MiB is allocated by PyTorch, and 66.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aa2d0c6a,"{'temperature_head': 0.9, 'latent_dim': 125, 'batch_size': 219, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.02 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 828.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 598.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 728.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 208.72 MiB is allocated by PyTorch, and 49.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cd573392,"{'temperature_head': 0.8, 'latent_dim': 110, 'batch_size': 164, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.02 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 828.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 598.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 728.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.70 MiB is allocated by PyTorch, and 35.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7c4a4e3b,"{'temperature_head': 0.4, 'latent_dim': 70, 'batch_size': 141, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.02 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 828.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 426.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 644.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 728.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.39 MiB is allocated by PyTorch, and 31.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6d28616e,"{'temperature_head': 1.0, 'latent_dim': 97, 'batch_size': 195, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.02 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 828.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 464.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 644.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 728.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 57.69 MiB is allocated by PyTorch, and 28.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
fdc847f6,"{'temperature_head': 0.5, 'latent_dim': 247, 'batch_size': 275, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.02 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 828.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 904.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 79.77 MiB is allocated by PyTorch, and 34.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
97255335,"{'temperature_head': 0.8, 'latent_dim': 78, 'batch_size': 159, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.02 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 828.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 908.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 904.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.45 MiB is allocated by PyTorch, and 33.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
14938ce7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 63, 'batch_size': 203, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 828.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 808.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 904.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 134.34 MiB is allocated by PyTorch, and 33.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
43a27fd0,"{'temperature_head': 0.9, 'latent_dim': 123, 'batch_size': 136, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 808.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 904.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 606.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 78.80 MiB is allocated by PyTorch, and 37.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
27f51bd7,"{'temperature_head': 1.0, 'latent_dim': 43, 'batch_size': 184, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 420.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 494.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 808.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 906.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 606.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 45.70 MiB is allocated by PyTorch, and 34.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
70bc7efe,"{'temperature_head': 0.2, 'latent_dim': 399, 'batch_size': 170, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 430.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 494.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 808.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 906.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 606.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 83.36 MiB is allocated by PyTorch, and 6.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
efd6c182,"{'temperature_head': 0.8, 'latent_dim': 135, 'batch_size': 153, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 448.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 498.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 78.90 MiB is allocated by PyTorch, and 37.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
48e5c9a3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 472, 'batch_size': 245, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 448.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 498.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 486.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 90.79 MiB is allocated by PyTorch, and 55.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 48, in calculate_loss
    loss = entropy_function(logits, targets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py"", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
"
1803f188,"{'temperature_head': 0.5, 'latent_dim': 203, 'batch_size': 287, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 420.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 498.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 486.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 46.95 MiB is allocated by PyTorch, and 33.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6b204c7b,"{'temperature_head': 0.1, 'latent_dim': 188, 'batch_size': 240, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 498.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 62.79 MiB is allocated by PyTorch, and 29.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
0b5383c9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 209, 'batch_size': 329, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 498.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 62.56 MiB is allocated by PyTorch, and 29.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
75f86342,"{'temperature_head': 0.7000000000000001, 'latent_dim': 277, 'batch_size': 351, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 696.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 498.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 74.12 MiB is allocated by PyTorch, and 17.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
61a8809d,"{'temperature_head': 0.5, 'latent_dim': 161, 'batch_size': 268, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 444.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 742.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 135.10 MiB is allocated by PyTorch, and 34.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
536d589f,"{'temperature_head': 0.4, 'latent_dim': 228, 'batch_size': 128, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 478.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 742.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 47.15 MiB is allocated by PyTorch, and 36.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e610e52,"{'temperature_head': 0.5, 'latent_dim': 142, 'batch_size': 339, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 742.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 46.48 MiB is allocated by PyTorch, and 37.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6588f671,"{'temperature_head': 0.9, 'latent_dim': 113, 'batch_size': 146, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 476.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 742.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 414.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 46.88 MiB is allocated by PyTorch, and 27.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
c16bcf07,"{'temperature_head': 0.8, 'latent_dim': 127, 'batch_size': 157, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 476.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 742.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 414.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 64.78 MiB is allocated by PyTorch, and 9.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 48, in calculate_loss
    loss = entropy_function(logits, targets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py"", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
"
eb76c057,"{'temperature_head': 0.8, 'latent_dim': 96, 'batch_size': 135, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 462.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 742.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 996.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 428.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 59.44 MiB is allocated by PyTorch, and 28.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
48247f28,"{'temperature_head': 0.6000000000000001, 'latent_dim': 502, 'batch_size': 128, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 206.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 930.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.01 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 137.77 MiB is allocated by PyTorch, and 36.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f1930b87,"{'temperature_head': 0.8, 'latent_dim': 139, 'batch_size': 148, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 930.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 822.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 596.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 217.11 MiB is allocated by PyTorch, and 38.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7ba8bd85,"{'temperature_head': 0.8, 'latent_dim': 104, 'batch_size': 181, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 466.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 930.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 814.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 134.66 MiB is allocated by PyTorch, and 37.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
460ebf74,"{'temperature_head': 0.9, 'latent_dim': 170, 'batch_size': 156, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 466.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 502.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 930.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 814.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 46.70 MiB is allocated by PyTorch, and 37.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f224d4b0,"{'temperature_head': 0.8, 'latent_dim': 149, 'batch_size': 135, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 552.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 930.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 814.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 135.01 MiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dc37ac05,"{'temperature_head': 0.8, 'latent_dim': 139, 'batch_size': 128, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 552.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 930.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 814.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 78.93 MiB is allocated by PyTorch, and 31.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e11b39ec,"{'temperature_head': 0.5, 'latent_dim': 184, 'batch_size': 164, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 706.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 608.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 676.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 818.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.28 MiB is allocated by PyTorch, and 36.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9c679a0d,"{'temperature_head': 0.9, 'latent_dim': 63, 'batch_size': 193, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 706.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 596.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 676.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 818.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 568.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 171.58 MiB is allocated by PyTorch, and 56.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
df06cae8,"{'temperature_head': 0.8, 'latent_dim': 108, 'batch_size': 140, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 662.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 768.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 720.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 626.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 560.00 MiB memory in use. Of the allocated memory 78.69 MiB is allocated by PyTorch, and 35.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
25f8d52a,"{'temperature_head': 0.8, 'latent_dim': 56, 'batch_size': 178, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 660.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 768.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 666.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 768.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 420.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 540.00 MiB memory in use. Of the allocated memory 45.80 MiB is allocated by PyTorch, and 34.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5a7f8d21,"{'temperature_head': 0.7000000000000001, 'latent_dim': 191, 'batch_size': 229, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 660.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 768.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 666.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 768.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 412.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 65.83 MiB is allocated by PyTorch, and 6.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
e3e47d5c,"{'temperature_head': 0.8, 'latent_dim': 159, 'batch_size': 200, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 660.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 716.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 770.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 46.61 MiB is allocated by PyTorch, and 35.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a36f574c,"{'temperature_head': 0.7000000000000001, 'latent_dim': 123, 'batch_size': 158, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 618.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 716.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 770.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 134.80 MiB is allocated by PyTorch, and 37.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a2069f5a,"{'temperature_head': 0.9, 'latent_dim': 72, 'batch_size': 184, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 752.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 434.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 558.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 770.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 772.00 MiB memory in use. Of the allocated memory 134.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b4101c09,"{'temperature_head': 0.7000000000000001, 'latent_dim': 182, 'batch_size': 220, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 752.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 648.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 452.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 656.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 816.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 79.27 MiB is allocated by PyTorch, and 36.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4fb6e7d5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 157, 'batch_size': 162, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 798.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 588.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 708.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 774.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 135.07 MiB is allocated by PyTorch, and 34.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
550f7279,"{'temperature_head': 0.9, 'latent_dim': 33, 'batch_size': 175, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 676.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 892.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 508.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 760.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 436.00 MiB memory in use. Of the allocated memory 134.10 MiB is allocated by PyTorch, and 33.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
afee4cef,"{'temperature_head': 0.9, 'latent_dim': 108, 'batch_size': 187, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 676.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 892.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 78.69 MiB is allocated by PyTorch, and 35.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e3d7b66,"{'temperature_head': 0.9, 'latent_dim': 61, 'batch_size': 172, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 562.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 676.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 892.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 170.38 MiB is allocated by PyTorch, and 51.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dc87c0aa,"{'temperature_head': 0.8, 'latent_dim': 238, 'batch_size': 146, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 654.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 432.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 79.70 MiB is allocated by PyTorch, and 32.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f1674e16,"{'temperature_head': 0.7000000000000001, 'latent_dim': 154, 'batch_size': 128, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 654.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 444.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 766.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 79.05 MiB is allocated by PyTorch, and 34.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
876760dc,"{'temperature_head': 0.8, 'latent_dim': 118, 'batch_size': 218, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 654.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 420.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 432.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 810.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 78.77 MiB is allocated by PyTorch, and 35.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1f850152,"{'temperature_head': 0.9, 'latent_dim': 71, 'batch_size': 195, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 444.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 506.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 134.40 MiB is allocated by PyTorch, and 31.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0cf14d89,"{'temperature_head': 1.0, 'latent_dim': 50, 'batch_size': 206, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 452.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 432.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 78.23 MiB is allocated by PyTorch, and 31.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a75a6229,"{'temperature_head': 1.0, 'latent_dim': 102, 'batch_size': 176, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 504.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 418.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 78.64 MiB is allocated by PyTorch, and 35.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
633f3383,"{'temperature_head': 0.9, 'latent_dim': 39, 'batch_size': 167, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 504.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 464.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 134.15 MiB is allocated by PyTorch, and 33.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0832803f,"{'temperature_head': 0.9, 'latent_dim': 74, 'batch_size': 183, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 514.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 464.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 134.42 MiB is allocated by PyTorch, and 35.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3588928e,"{'temperature_head': 0.9, 'latent_dim': 84, 'batch_size': 154, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 444.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 46.02 MiB is allocated by PyTorch, and 37.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8befcabb,"{'temperature_head': 1.0, 'latent_dim': 24, 'batch_size': 191, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 438.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 496.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 420.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 45.55 MiB is allocated by PyTorch, and 34.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d40e1954,"{'temperature_head': 0.8, 'latent_dim': 97, 'batch_size': 160, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 434.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 566.00 MiB memory in use. Of the allocated memory 78.60 MiB is allocated by PyTorch, and 37.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2f1de7f2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 162, 'batch_size': 138, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 434.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 614.00 MiB memory in use. Of the allocated memory 46.63 MiB is allocated by PyTorch, and 37.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a9729fdf,"{'temperature_head': 1.0, 'latent_dim': 64, 'batch_size': 179, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 418.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 434.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 614.00 MiB memory in use. Of the allocated memory 45.87 MiB is allocated by PyTorch, and 32.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8aa1284a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 223, 'batch_size': 134, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 442.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 446.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.59 MiB is allocated by PyTorch, and 36.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
17303ffb,"{'temperature_head': 0.7000000000000001, 'latent_dim': 165, 'batch_size': 259, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 446.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.13 MiB is allocated by PyTorch, and 34.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f41b4c66,"{'temperature_head': 0.9, 'latent_dim': 96, 'batch_size': 174, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 414.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 498.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 418.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 46.12 MiB is allocated by PyTorch, and 31.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cace957c,"{'temperature_head': 1.0, 'latent_dim': 75, 'batch_size': 168, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 498.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 430.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 464.00 MiB memory in use. Of the allocated memory 61.08 MiB is allocated by PyTorch, and 28.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
17a31ad3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 134, 'batch_size': 144, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 498.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 430.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 134.89 MiB is allocated by PyTorch, and 35.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2eebe1c4,"{'temperature_head': 0.6000000000000001, 'latent_dim': 543, 'batch_size': 225, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 498.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 1006.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 460.15 MiB is allocated by PyTorch, and 205.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
59171f83,"{'temperature_head': 0.8, 'latent_dim': 117, 'batch_size': 186, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 738.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 500.00 MiB memory in use. Of the allocated memory 46.28 MiB is allocated by PyTorch, and 37.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a146a5ab,"{'temperature_head': 0.7000000000000001, 'latent_dim': 182, 'batch_size': 294, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 444.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 738.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 135.27 MiB is allocated by PyTorch, and 34.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
04268f60,"{'temperature_head': 0.6000000000000001, 'latent_dim': 149, 'batch_size': 129, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 430.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 738.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 135.01 MiB is allocated by PyTorch, and 34.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8a6d7f2b,"{'temperature_head': 0.8, 'latent_dim': 241, 'batch_size': 426, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 404.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 738.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 79.73 MiB is allocated by PyTorch, and 30.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2b7fda59,"{'temperature_head': 0.7000000000000001, 'latent_dim': 254, 'batch_size': 233, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 426.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 404.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 738.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 47.35 MiB is allocated by PyTorch, and 38.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2a1a446f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 201, 'batch_size': 273, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 404.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 738.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 498.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 135.42 MiB is allocated by PyTorch, and 36.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
574ef148,"{'temperature_head': 1.0, 'latent_dim': 31, 'batch_size': 192, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 408.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 766.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 78.09 MiB is allocated by PyTorch, and 31.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a6dee85d,"{'temperature_head': 0.9, 'latent_dim': 129, 'batch_size': 204, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 408.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 938.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 714.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 766.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 134.85 MiB is allocated by PyTorch, and 35.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f6fd0b77,"{'temperature_head': 1.0, 'latent_dim': 3, 'batch_size': 171, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 404.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 940.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 468.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 716.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 422.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 766.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 45.39 MiB is allocated by PyTorch, and 36.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
72a00e21,"{'temperature_head': 1.0, 'latent_dim': 14, 'batch_size': 182, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 562.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 432.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 710.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 420.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 766.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 45.48 MiB is allocated by PyTorch, and 34.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
db1c3540,"{'temperature_head': 0.8, 'latent_dim': 104, 'batch_size': 154, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 710.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 78.66 MiB is allocated by PyTorch, and 33.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cf96d1f7,"{'temperature_head': 0.7000000000000001, 'latent_dim': 186, 'batch_size': 252, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 710.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 245.30 MiB is allocated by PyTorch, and 32.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ab59b864,"{'temperature_head': 0.9, 'latent_dim': 91, 'batch_size': 165, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 662.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 494.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 710.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 966.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 62.22 MiB is allocated by PyTorch, and 29.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
f9d5891c,"{'temperature_head': 1.0, 'latent_dim': 577, 'batch_size': 193, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 562.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 894.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 756.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 526.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 866.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 694.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 138.44 MiB is allocated by PyTorch, and 47.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
82fbf91e,"{'temperature_head': 0.5, 'latent_dim': 176, 'batch_size': 330, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 592.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 430.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 628.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 798.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 780.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 798.00 MiB memory in use. Of the allocated memory 135.22 MiB is allocated by PyTorch, and 34.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
773b6360,"{'temperature_head': 0.8, 'latent_dim': 306, 'batch_size': 150, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 560.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 638.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 456.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 780.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 844.00 MiB memory in use. Of the allocated memory 80.24 MiB is allocated by PyTorch, and 31.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e9cdc2d9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 264, 'batch_size': 136, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 612.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 135.91 MiB is allocated by PyTorch, and 38.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f24cc49f,"{'temperature_head': 0.5, 'latent_dim': 154, 'batch_size': 368, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 658.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 754.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 458.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 79.05 MiB is allocated by PyTorch, and 38.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
11e7c483,"{'temperature_head': 0.9, 'latent_dim': 57, 'batch_size': 164, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 658.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 506.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 802.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 134.29 MiB is allocated by PyTorch, and 31.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5546dabf,"{'temperature_head': 1.0, 'latent_dim': 125, 'batch_size': 208, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 658.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 802.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 134.82 MiB is allocated by PyTorch, and 37.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d3474407,"{'temperature_head': 0.7000000000000001, 'latent_dim': 186, 'batch_size': 263, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 476.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 658.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 802.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 135.30 MiB is allocated by PyTorch, and 36.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cd9c0d93,"{'temperature_head': 0.8, 'latent_dim': 3, 'batch_size': 176, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 476.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 658.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 540.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 802.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 77.87 MiB is allocated by PyTorch, and 34.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
144804eb,"{'temperature_head': 0.7000000000000001, 'latent_dim': 349, 'batch_size': 308, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 188.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 694.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 810.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 472.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 136.57 MiB is allocated by PyTorch, and 35.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
de1834f6,"{'temperature_head': 1.0, 'latent_dim': 321, 'batch_size': 159, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 750.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 454.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 33.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d1c1646d,"{'temperature_head': 0.9, 'latent_dim': 83, 'batch_size': 188, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 564.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 750.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 470.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 183.56 MiB is allocated by PyTorch, and 40.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f6f88144,"{'temperature_head': 0.5, 'latent_dim': 168, 'batch_size': 129, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 564.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 750.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 856.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 472.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 794.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 135.16 MiB is allocated by PyTorch, and 36.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2f26366f,"{'temperature_head': 1.0, 'latent_dim': 40, 'batch_size': 200, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 914.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 750.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 450.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 78.16 MiB is allocated by PyTorch, and 31.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a13d8fb5,"{'temperature_head': 0.8, 'latent_dim': 117, 'batch_size': 146, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 914.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 750.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 882.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 554.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 462.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 846.00 MiB memory in use. Of the allocated memory 46.28 MiB is allocated by PyTorch, and 35.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c57c3bea,"{'temperature_head': 0.8, 'latent_dim': 21, 'batch_size': 216, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 914.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 680.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 744.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 506.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 134.01 MiB is allocated by PyTorch, and 31.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3bc833e3,"{'temperature_head': 0.5, 'latent_dim': 101, 'batch_size': 171, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 914.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 682.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 568.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 744.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 194.63 MiB is allocated by PyTorch, and 33.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5368b19f,"{'temperature_head': 0.8, 'latent_dim': 78, 'batch_size': 185, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 914.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 660.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 744.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 592.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 78.45 MiB is allocated by PyTorch, and 33.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
759c1688,"{'temperature_head': 0.6000000000000001, 'latent_dim': 157, 'batch_size': 128, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 824.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 710.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 732.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 826.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 432.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 728.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 556.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 434.00 MiB memory in use. Of the allocated memory 135.07 MiB is allocated by PyTorch, and 36.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
71e02b4d,"{'temperature_head': 0.9, 'latent_dim': 427, 'batch_size': 206, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 824.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 710.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 776.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 874.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 422.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 736.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 137.18 MiB is allocated by PyTorch, and 36.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e9dda77,"{'temperature_head': 0.8, 'latent_dim': 109, 'batch_size': 150, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 710.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 846.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 896.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 714.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 736.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 514.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 46.22 MiB is allocated by PyTorch, and 35.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3a083298,"{'temperature_head': 0.5, 'latent_dim': 531, 'batch_size': 160, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 710.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 846.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 896.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 714.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 736.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 138.00 MiB is allocated by PyTorch, and 32.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a9f10f59,"{'temperature_head': 0.7000000000000001, 'latent_dim': 172, 'batch_size': 359, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 710.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 846.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 896.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 422.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 714.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 782.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 79.19 MiB is allocated by PyTorch, and 34.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7933fa84,"{'temperature_head': 0.6000000000000001, 'latent_dim': 195, 'batch_size': 236, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 426.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 710.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 846.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 896.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 760.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 782.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 46.89 MiB is allocated by PyTorch, and 39.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e2292a55,"{'temperature_head': 0.6000000000000001, 'latent_dim': 148, 'batch_size': 275, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 446.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 846.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 896.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 782.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 416.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 434.00 MiB memory in use. Of the allocated memory 46.52 MiB is allocated by PyTorch, and 29.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e23d363c,"{'temperature_head': 0.7000000000000001, 'latent_dim': 180, 'batch_size': 293, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 846.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 896.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 782.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 416.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 434.00 MiB memory in use. Of the allocated memory 79.25 MiB is allocated by PyTorch, and 30.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
062aac9b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 251, 'batch_size': 252, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 700.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 942.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 782.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 458.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 79.81 MiB is allocated by PyTorch, and 38.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
74ad818e,"{'temperature_head': 0.5, 'latent_dim': 228, 'batch_size': 287, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 700.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 498.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 468.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 135.63 MiB is allocated by PyTorch, and 36.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
71daeff6,"{'temperature_head': 0.4, 'latent_dim': 681, 'batch_size': 198, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 334.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 440.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 554.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 450.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 139.17 MiB is allocated by PyTorch, and 32.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
86fa2d23,"{'temperature_head': 0.6000000000000001, 'latent_dim': 213, 'batch_size': 223, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 554.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 740.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 47.03 MiB is allocated by PyTorch, and 36.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
524c8875,"{'temperature_head': 0.8, 'latent_dim': 33, 'batch_size': 141, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 556.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 740.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 420.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 45.62 MiB is allocated by PyTorch, and 34.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
be89f1ee,"{'temperature_head': 1.0, 'latent_dim': 128, 'batch_size': 138, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 508.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 644.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 676.00 MiB memory in use. Of the allocated memory 46.37 MiB is allocated by PyTorch, and 37.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a028a1bc,"{'temperature_head': 0.6000000000000001, 'latent_dim': 203, 'batch_size': 280, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 712.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 504.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 422.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 644.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 696.00 MiB memory in use. Of the allocated memory 79.43 MiB is allocated by PyTorch, and 34.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1db21b73,"{'temperature_head': 0.5, 'latent_dim': 170, 'batch_size': 241, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 422.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 736.00 MiB memory in use. Of the allocated memory 135.17 MiB is allocated by PyTorch, and 32.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c835412b,"{'temperature_head': 0.5, 'latent_dim': 189, 'batch_size': 299, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 452.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 538.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 762.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 736.00 MiB memory in use. Of the allocated memory 79.32 MiB is allocated by PyTorch, and 36.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dc07b8db,"{'temperature_head': 0.7000000000000001, 'latent_dim': 238, 'batch_size': 135, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 672.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 736.00 MiB memory in use. Of the allocated memory 275.90 MiB is allocated by PyTorch, and 56.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
500da6ce,"{'temperature_head': 0.9, 'latent_dim': 41, 'batch_size': 172, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 718.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 736.00 MiB memory in use. Of the allocated memory 78.16 MiB is allocated by PyTorch, and 33.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b05c2a67,"{'temperature_head': 0.4, 'latent_dim': 333, 'batch_size': 188, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 718.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 458.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 736.00 MiB memory in use. Of the allocated memory 80.45 MiB is allocated by PyTorch, and 37.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d8699991,"{'temperature_head': 0.7000000000000001, 'latent_dim': 208, 'batch_size': 388, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 502.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.08 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 504.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.47 MiB is allocated by PyTorch, and 36.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ff2cb471,"{'temperature_head': 0.6000000000000001, 'latent_dim': 254, 'batch_size': 232, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 502.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 908.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 500.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 666.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 285.99 MiB is allocated by PyTorch, and 40.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e8bbd97a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 178, 'batch_size': 247, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 908.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 640.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 46.76 MiB is allocated by PyTorch, and 37.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b4c529b2,"{'temperature_head': 1.0, 'latent_dim': 14, 'batch_size': 171, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 618.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 908.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 640.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 45.48 MiB is allocated by PyTorch, and 36.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2e87ddec,"{'temperature_head': 0.8, 'latent_dim': 109, 'batch_size': 146, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 574.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 908.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 640.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 402.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 604.00 MiB memory in use. Of the allocated memory 35.50 MiB is allocated by PyTorch, and 26.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
e7a01073,"{'temperature_head': 0.8, 'latent_dim': 74, 'batch_size': 178, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 420.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 908.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 402.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 550.00 MiB memory in use. Of the allocated memory 52.28 MiB is allocated by PyTorch, and 27.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
c388e8b2,"{'temperature_head': 0.5, 'latent_dim': 598, 'batch_size': 399, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 458.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 470.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 434.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 82.56 MiB is allocated by PyTorch, and 35.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d67cf36e,"{'temperature_head': 0.4, 'latent_dim': 31, 'batch_size': 158, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 472.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 450.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 78.09 MiB is allocated by PyTorch, and 31.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d8073b1d,"{'temperature_head': 0.9, 'latent_dim': 300, 'batch_size': 183, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 470.00 MiB memory in use. Of the allocated memory 80.19 MiB is allocated by PyTorch, and 31.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
402b50e2,"{'temperature_head': 1.0, 'latent_dim': 121, 'batch_size': 198, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 472.00 MiB memory in use. Of the allocated memory 78.79 MiB is allocated by PyTorch, and 37.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e80f37ea,"{'temperature_head': 0.8, 'latent_dim': 52, 'batch_size': 149, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 512.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 844.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 860.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 472.00 MiB memory in use. Of the allocated memory 62.00 MiB is allocated by PyTorch, and 30.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
c3fa8f77,"{'temperature_head': 1.0, 'latent_dim': 79, 'batch_size': 134, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 78.46 MiB is allocated by PyTorch, and 33.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e601cd7a,"{'temperature_head': 0.5, 'latent_dim': 155, 'batch_size': 325, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 818.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 426.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 846.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 46.58 MiB is allocated by PyTorch, and 37.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ae0f7bdd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 172, 'batch_size': 269, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 784.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 448.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 592.00 MiB memory in use. Of the allocated memory 135.19 MiB is allocated by PyTorch, and 34.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9a4f0e0a,"{'temperature_head': 0.9, 'latent_dim': 124, 'batch_size': 203, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 784.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 582.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 208.81 MiB is allocated by PyTorch, and 33.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8a8ba4f9,"{'temperature_head': 0.7000000000000001, 'latent_dim': 163, 'batch_size': 258, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 666.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 542.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 784.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 876.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.12 MiB is allocated by PyTorch, and 32.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cee484e7,"{'temperature_head': 0.6000000000000001, 'latent_dim': 218, 'batch_size': 342, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 784.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 758.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 79.55 MiB is allocated by PyTorch, and 36.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ea7ff6a5,"{'temperature_head': 0.5, 'latent_dim': 268, 'batch_size': 136, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 842.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 476.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 758.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 135.94 MiB is allocated by PyTorch, and 34.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
21b1c23a,"{'temperature_head': 0.9, 'latent_dim': 390, 'batch_size': 180, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 842.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 458.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 758.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 80.89 MiB is allocated by PyTorch, and 37.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
84a5c58a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 146, 'batch_size': 285, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 842.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 758.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 134.99 MiB is allocated by PyTorch, and 33.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
14cc63a1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 184, 'batch_size': 237, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 842.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 758.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 79.28 MiB is allocated by PyTorch, and 36.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
750f1205,"{'temperature_head': 0.7000000000000001, 'latent_dim': 244, 'batch_size': 218, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 842.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 758.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 512.00 MiB memory in use. Of the allocated memory 135.75 MiB is allocated by PyTorch, and 32.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ba4dc7e4,"{'temperature_head': 0.8, 'latent_dim': 465, 'batch_size': 158, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 554.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 888.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 458.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 802.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 81.48 MiB is allocated by PyTorch, and 36.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
67b84f91,"{'temperature_head': 0.6000000000000001, 'latent_dim': 134, 'batch_size': 129, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 888.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 500.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 446.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 802.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 134.89 MiB is allocated by PyTorch, and 31.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
886f7fab,"{'temperature_head': 0.8, 'latent_dim': 92, 'batch_size': 150, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 888.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 446.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 802.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 134.56 MiB is allocated by PyTorch, and 37.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
10478559,"{'temperature_head': 1.0, 'latent_dim': 6, 'batch_size': 211, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 464.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 802.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 77.89 MiB is allocated by PyTorch, and 34.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c4f074aa,"{'temperature_head': 0.6000000000000001, 'latent_dim': 223, 'batch_size': 295, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 464.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 802.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 79.59 MiB is allocated by PyTorch, and 34.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1d1d19b0,"{'temperature_head': 0.5, 'latent_dim': 562, 'batch_size': 278, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 504.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 802.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 470.00 MiB memory in use. Of the allocated memory 49.76 MiB is allocated by PyTorch, and 42.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
582cf07f,"{'temperature_head': 0.4, 'latent_dim': 501, 'batch_size': 178, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 504.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 802.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 470.00 MiB memory in use. Of the allocated memory 78.70 MiB is allocated by PyTorch, and 13.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e5a05e8d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 315, 'batch_size': 230, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 770.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 470.00 MiB memory in use. Of the allocated memory 136.31 MiB is allocated by PyTorch, and 37.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ffbe7ff1,"{'temperature_head': 1.0, 'latent_dim': 45, 'batch_size': 153, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 652.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 422.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 770.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 470.00 MiB memory in use. Of the allocated memory 78.19 MiB is allocated by PyTorch, and 31.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
780fc8f1,"{'temperature_head': 0.9, 'latent_dim': 617, 'batch_size': 195, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 652.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 420.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 770.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 470.00 MiB memory in use. Of the allocated memory 101.61 MiB is allocated by PyTorch, and 14.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
23bce100,"{'temperature_head': 0.8, 'latent_dim': 82, 'batch_size': 171, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 652.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 418.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 444.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 770.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 46.01 MiB is allocated by PyTorch, and 31.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
397ee138,"{'temperature_head': 0.5, 'latent_dim': 177, 'batch_size': 136, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 652.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 402.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 444.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 770.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 432.00 MiB memory in use. Of the allocated memory 35.70 MiB is allocated by PyTorch, and 26.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
5d0749c3,"{'temperature_head': 0.7000000000000001, 'latent_dim': 192, 'batch_size': 267, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 954.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 444.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 816.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.34 MiB is allocated by PyTorch, and 34.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
56cd4d39,"{'temperature_head': 0.5, 'latent_dim': 208, 'batch_size': 323, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 816.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 434.00 MiB memory in use. Of the allocated memory 135.47 MiB is allocated by PyTorch, and 36.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9d20eb8e,"{'temperature_head': 0.6000000000000001, 'latent_dim': 279, 'batch_size': 128, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 890.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 850.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 436.00 MiB memory in use. Of the allocated memory 136.03 MiB is allocated by PyTorch, and 35.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f9b5283a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 231, 'batch_size': 259, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 426.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 898.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 850.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 442.00 MiB memory in use. Of the allocated memory 47.17 MiB is allocated by PyTorch, and 38.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a3eb253c,"{'temperature_head': 1.0, 'latent_dim': 66, 'batch_size': 160, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 898.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 422.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 566.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 850.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 173.38 MiB is allocated by PyTorch, and 52.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
757eecc2,"{'temperature_head': 0.9, 'latent_dim': 97, 'batch_size': 145, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 898.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 500.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 850.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 78.60 MiB is allocated by PyTorch, and 31.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0d4b1776,"{'temperature_head': 0.6000000000000001, 'latent_dim': 134, 'batch_size': 221, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 898.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 424.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 500.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 850.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 46.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
16e44056,"{'temperature_head': 0.8, 'latent_dim': 418, 'batch_size': 187, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 898.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 510.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 850.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 84.43 MiB is allocated by PyTorch, and 9.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
4bf9ac92,"{'temperature_head': 0.9, 'latent_dim': 339, 'batch_size': 209, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 854.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 558.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 784.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 336.41 MiB is allocated by PyTorch, and 107.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ba60d4f6,"{'temperature_head': 0.4, 'latent_dim': 45, 'batch_size': 170, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 854.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 558.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 826.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 78.19 MiB is allocated by PyTorch, and 33.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a82f7b88,"{'temperature_head': 0.5, 'latent_dim': 186, 'batch_size': 331, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 854.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 956.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 498.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 780.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 244.76 MiB is allocated by PyTorch, and 195.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
486e93ae,"{'temperature_head': 0.6000000000000001, 'latent_dim': 153, 'batch_size': 242, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 856.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 508.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 826.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.04 MiB is allocated by PyTorch, and 32.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a211c354,"{'temperature_head': 0.5, 'latent_dim': 172, 'batch_size': 459, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 856.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 502.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 778.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 236.37 MiB is allocated by PyTorch, and 201.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dc5b3311,"{'temperature_head': 0.6000000000000001, 'latent_dim': 290, 'batch_size': 355, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 682.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 504.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 512.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 826.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 634.00 MiB memory in use. Of the allocated memory 308.11 MiB is allocated by PyTorch, and 33.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ca571720,"{'temperature_head': 0.7000000000000001, 'latent_dim': 199, 'batch_size': 135, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 728.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 606.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 826.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.40 MiB is allocated by PyTorch, and 34.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
09148d98,"{'temperature_head': 0.6000000000000001, 'latent_dim': 230, 'batch_size': 129, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 728.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 510.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 782.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 512.00 MiB memory in use. Of the allocated memory 271.11 MiB is allocated by PyTorch, and 170.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aca09090,"{'temperature_head': 0.7000000000000001, 'latent_dim': 270, 'batch_size': 128, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 624.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 510.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 558.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 510.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 784.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 135.45 MiB is allocated by PyTorch, and 148.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3d8f39c3,"{'temperature_head': 0.5, 'latent_dim': 148, 'batch_size': 252, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 600.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 558.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 826.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 560.00 MiB memory in use. Of the allocated memory 223.00 MiB is allocated by PyTorch, and 37.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
60d31269,"{'temperature_head': 0.7000000000000001, 'latent_dim': 128, 'batch_size': 381, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 622.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 930.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 558.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 966.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 560.00 MiB memory in use. Of the allocated memory 134.34 MiB is allocated by PyTorch, and 147.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
29e8fb79,"{'temperature_head': 0.5, 'latent_dim': 157, 'batch_size': 142, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 966.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 666.00 MiB memory in use. Of the allocated memory 79.07 MiB is allocated by PyTorch, and 36.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
751f0d88,"{'temperature_head': 0.6000000000000001, 'latent_dim': 194, 'batch_size': 155, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 458.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 966.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 666.00 MiB memory in use. Of the allocated memory 79.36 MiB is allocated by PyTorch, and 38.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c7b08543,"{'temperature_head': 0.8, 'latent_dim': 312, 'batch_size': 318, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 166.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 136.28 MiB is allocated by PyTorch, and 31.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
40a6b6ca,"{'temperature_head': 0.5, 'latent_dim': 172, 'batch_size': 372, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 614.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 237.19 MiB is allocated by PyTorch, and 36.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d0e3a955,"{'temperature_head': 0.7000000000000001, 'latent_dim': 139, 'batch_size': 223, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 514.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 660.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 468.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 458.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 78.93 MiB is allocated by PyTorch, and 39.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
db587af0,"{'temperature_head': 0.6000000000000001, 'latent_dim': 153, 'batch_size': 270, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 660.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 79.04 MiB is allocated by PyTorch, and 34.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
95c78dc7,"{'temperature_head': 0.8, 'latent_dim': 199, 'batch_size': 128, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 676.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 456.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 252.89 MiB is allocated by PyTorch, and 83.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fd290e59,"{'temperature_head': 0.7000000000000001, 'latent_dim': 256, 'batch_size': 145, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 676.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 456.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 926.00 MiB memory in use. Of the allocated memory 47.37 MiB is allocated by PyTorch, and 36.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4defe17b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 125, 'batch_size': 284, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 708.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 134.82 MiB is allocated by PyTorch, and 37.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c42829fc,"{'temperature_head': 0.7000000000000001, 'latent_dim': 170, 'batch_size': 348, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 708.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 422.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 46.70 MiB is allocated by PyTorch, and 35.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c5306583,"{'temperature_head': 0.4, 'latent_dim': 143, 'batch_size': 153, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 476.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 710.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 470.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 470.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 78.96 MiB is allocated by PyTorch, and 33.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
58f53305,"{'temperature_head': 0.5, 'latent_dim': 109, 'batch_size': 292, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 476.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 710.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 506.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 134.69 MiB is allocated by PyTorch, and 31.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
054417d4,"{'temperature_head': 0.8, 'latent_dim': 369, 'batch_size': 135, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 710.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 472.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 136.73 MiB is allocated by PyTorch, and 35.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3a6acf66,"{'temperature_head': 0.8, 'latent_dim': 327, 'batch_size': 232, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 80.40 MiB is allocated by PyTorch, and 33.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
487a36a7,"{'temperature_head': 0.6000000000000001, 'latent_dim': 232, 'batch_size': 145, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 498.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 79.66 MiB is allocated by PyTorch, and 36.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
589521ae,"{'temperature_head': 0.6000000000000001, 'latent_dim': 405, 'batch_size': 150, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 137.01 MiB is allocated by PyTorch, and 34.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2b5cd870,"{'temperature_head': 0.8, 'latent_dim': 110, 'batch_size': 179, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 78.70 MiB is allocated by PyTorch, and 33.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ff3ba8e1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 133, 'batch_size': 335, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 470.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 556.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 78.88 MiB is allocated by PyTorch, and 35.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3386a1a4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 144, 'batch_size': 326, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 502.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 134.97 MiB is allocated by PyTorch, and 35.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
134ae1a8,"{'temperature_head': 0.7000000000000001, 'latent_dim': 160, 'batch_size': 317, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 412.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 472.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 502.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 135.09 MiB is allocated by PyTorch, and 36.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1d1eb1c2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 150, 'batch_size': 325, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 722.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 558.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 135.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8b397a10,"{'temperature_head': 0.8, 'latent_dim': 102, 'batch_size': 161, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 500.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 570.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 194.94 MiB is allocated by PyTorch, and 35.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0d7fc8f4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 162, 'batch_size': 310, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 500.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 424.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 620.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 46.63 MiB is allocated by PyTorch, and 37.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7fe7e0a4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 121, 'batch_size': 332, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 500.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 454.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 588.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 206.28 MiB is allocated by PyTorch, and 41.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
acf2f192,"{'temperature_head': 0.7000000000000001, 'latent_dim': 180, 'batch_size': 334, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 670.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 708.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 422.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 410.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 46.77 MiB is allocated by PyTorch, and 35.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
33f74342,"{'temperature_head': 0.6000000000000001, 'latent_dim': 139, 'batch_size': 302, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 708.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 446.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 596.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 217.11 MiB is allocated by PyTorch, and 38.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
255d970c,"{'temperature_head': 0.7000000000000001, 'latent_dim': 154, 'batch_size': 311, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 708.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 424.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 446.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 642.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 46.57 MiB is allocated by PyTorch, and 37.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0fa877e6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 125, 'batch_size': 299, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 424.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 688.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 468.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 446.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 642.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 46.34 MiB is allocated by PyTorch, and 37.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
45b27173,"{'temperature_head': 0.9, 'latent_dim': 113, 'batch_size': 176, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 688.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 470.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 608.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 201.03 MiB is allocated by PyTorch, and 66.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f732d84f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 140, 'batch_size': 297, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 598.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 688.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 470.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 217.71 MiB is allocated by PyTorch, and 40.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
30a0a6c2,"{'temperature_head': 0.8, 'latent_dim': 100, 'batch_size': 187, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 642.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 688.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 78.62 MiB is allocated by PyTorch, and 33.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fb680acc,"{'temperature_head': 0.7000000000000001, 'latent_dim': 193, 'batch_size': 294, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 642.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 688.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 79.35 MiB is allocated by PyTorch, and 34.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5d7719f4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 167, 'batch_size': 325, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 640.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 688.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 974.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 432.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 500.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 233.37 MiB is allocated by PyTorch, and 66.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc746bd7,"{'temperature_head': 0.9, 'latent_dim': 67, 'batch_size': 194, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 432.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 616.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 656.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 134.37 MiB is allocated by PyTorch, and 35.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dba490dd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 175, 'batch_size': 315, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 450.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 616.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 656.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 928.00 MiB memory in use. Of the allocated memory 79.21 MiB is allocated by PyTorch, and 36.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
58eb3bd9,"{'temperature_head': 0.8, 'latent_dim': 107, 'batch_size': 172, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 580.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 616.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 656.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 826.00 MiB memory in use. Of the allocated memory 78.68 MiB is allocated by PyTorch, and 37.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c6b97471,"{'temperature_head': 0.9, 'latent_dim': 114, 'batch_size': 179, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 422.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 620.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 616.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 656.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 826.00 MiB memory in use. Of the allocated memory 46.26 MiB is allocated by PyTorch, and 35.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f69a5be3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 202, 'batch_size': 305, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 736.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 434.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 664.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 826.00 MiB memory in use. Of the allocated memory 135.42 MiB is allocated by PyTorch, and 32.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
59db1c74,"{'temperature_head': 0.9, 'latent_dim': 89, 'batch_size': 161, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 736.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 664.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 418.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 826.00 MiB memory in use. Of the allocated memory 46.06 MiB is allocated by PyTorch, and 31.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1f03f3e5,"{'temperature_head': 0.8, 'latent_dim': 80, 'batch_size': 152, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 736.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 452.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 656.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 466.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 826.00 MiB memory in use. Of the allocated memory 78.47 MiB is allocated by PyTorch, and 33.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b0556749,"{'temperature_head': 0.9, 'latent_dim': 74, 'batch_size': 203, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 452.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 736.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 656.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 826.00 MiB memory in use. Of the allocated memory 134.42 MiB is allocated by PyTorch, and 33.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e8c509d4,"{'temperature_head': 0.6000000000000001, 'latent_dim': 216, 'batch_size': 277, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 422.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 47.06 MiB is allocated by PyTorch, and 36.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
29ee18b6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 708, 'batch_size': 319, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 446.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 79.04 MiB is allocated by PyTorch, and 4.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dbd73ca3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 124, 'batch_size': 306, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 446.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 430.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 61.01 MiB is allocated by PyTorch, and 28.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
66874c3f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 150, 'batch_size': 345, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 446.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 424.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 430.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 46.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
575d26bc,"{'temperature_head': 0.7000000000000001, 'latent_dim': 199, 'batch_size': 325, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 446.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 412.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 68.34 MiB is allocated by PyTorch, and 3.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
53bb59b1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 163, 'batch_size': 291, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 446.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 430.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 60.54 MiB is allocated by PyTorch, and 29.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
400080ad,"{'temperature_head': 0.8, 'latent_dim': 186, 'batch_size': 343, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 446.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 424.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 430.00 MiB memory in use. Of the allocated memory 46.82 MiB is allocated by PyTorch, and 37.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1ba58671,"{'temperature_head': 0.7000000000000001, 'latent_dim': 211, 'batch_size': 336, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 446.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 412.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 68.54 MiB is allocated by PyTorch, and 3.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
1a5aface,"{'temperature_head': 0.5, 'latent_dim': 140, 'batch_size': 278, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 420.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 742.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 78.94 MiB is allocated by PyTorch, and 35.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
18f54159,"{'temperature_head': 0.9, 'latent_dim': 113, 'batch_size': 158, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 818.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 514.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 422.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 452.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 660.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 46.25 MiB is allocated by PyTorch, and 35.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e6d1cbe6,"{'temperature_head': 1.0, 'latent_dim': 120, 'batch_size': 186, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 786.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 456.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 660.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 78.78 MiB is allocated by PyTorch, and 35.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f582f928,"{'temperature_head': 0.8, 'latent_dim': 54, 'batch_size': 146, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 786.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 456.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 420.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 660.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 45.79 MiB is allocated by PyTorch, and 34.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b982037c,"{'temperature_head': 0.9, 'latent_dim': 50, 'batch_size': 173, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 500.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 786.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 456.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 420.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 660.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 502.00 MiB memory in use. Of the allocated memory 52.14 MiB is allocated by PyTorch, and 27.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_full_estimator.py"", line 55, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
850fb89b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 181, 'batch_size': 296, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 502.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 650.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 504.00 MiB memory in use. Of the allocated memory 79.26 MiB is allocated by PyTorch, and 34.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cd2ae861,"{'temperature_head': 0.5, 'latent_dim': 72, 'batch_size': 207, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 650.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 504.00 MiB memory in use. Of the allocated memory 134.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
10a17797,"{'temperature_head': 0.5, 'latent_dim': 135, 'batch_size': 273, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 650.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 762.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 504.00 MiB memory in use. Of the allocated memory 134.90 MiB is allocated by PyTorch, and 35.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5a3697f5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 177, 'batch_size': 357, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 650.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 504.00 MiB memory in use. Of the allocated memory 79.23 MiB is allocated by PyTorch, and 36.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
164ed4f7,"{'temperature_head': 0.7000000000000001, 'latent_dim': 150, 'batch_size': 284, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 742.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 612.00 MiB memory in use. Of the allocated memory 135.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e146e1a4,"{'temperature_head': 0.6000000000000001, 'latent_dim': 203, 'batch_size': 320, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 808.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 634.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 658.00 MiB memory in use. Of the allocated memory 255.44 MiB is allocated by PyTorch, and 38.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
31bf8ece,"{'temperature_head': 0.5, 'latent_dim': 223, 'batch_size': 341, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 558.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 456.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 792.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 680.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 658.00 MiB memory in use. Of the allocated memory 79.59 MiB is allocated by PyTorch, and 36.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ad4160fd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 133, 'batch_size': 300, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 590.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 792.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 680.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 658.00 MiB memory in use. Of the allocated memory 213.51 MiB is allocated by PyTorch, and 36.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b903684b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 167, 'batch_size': 350, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 512.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 792.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 678.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 658.00 MiB memory in use. Of the allocated memory 233.37 MiB is allocated by PyTorch, and 104.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a7cba7b6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 191, 'batch_size': 263, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 502.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 628.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 792.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 658.00 MiB memory in use. Of the allocated memory 248.26 MiB is allocated by PyTorch, and 39.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d2f2a70e,"{'temperature_head': 0.6000000000000001, 'latent_dim': 156, 'batch_size': 291, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 502.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 792.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 810.00 MiB memory in use. Of the allocated memory 135.06 MiB is allocated by PyTorch, and 38.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fb2f52c3,"{'temperature_head': 0.8, 'latent_dim': 151, 'batch_size': 268, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 514.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 502.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 792.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 810.00 MiB memory in use. Of the allocated memory 79.02 MiB is allocated by PyTorch, and 34.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0d0f36d1,"{'temperature_head': 1.0, 'latent_dim': 33, 'batch_size': 162, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 560.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 506.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 792.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 502.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 810.00 MiB memory in use. Of the allocated memory 134.10 MiB is allocated by PyTorch, and 31.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7d8cbe1a,"{'temperature_head': 0.8, 'latent_dim': 62, 'batch_size': 198, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 434.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 554.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 838.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 512.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 810.00 MiB memory in use. Of the allocated memory 134.33 MiB is allocated by PyTorch, and 37.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0ca46295,"{'temperature_head': 0.9, 'latent_dim': 87, 'batch_size': 128, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 506.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 554.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 838.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 810.00 MiB memory in use. Of the allocated memory 134.52 MiB is allocated by PyTorch, and 31.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
513553ac,"{'temperature_head': 0.7000000000000001, 'latent_dim': 180, 'batch_size': 371, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 434.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 554.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 838.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 456.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 856.00 MiB memory in use. Of the allocated memory 79.25 MiB is allocated by PyTorch, and 36.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7ab9b0a5,"{'temperature_head': 1.0, 'latent_dim': 101, 'batch_size': 139, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 434.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 566.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 838.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 856.00 MiB memory in use. Of the allocated memory 194.63 MiB is allocated by PyTorch, and 31.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
67132488,"{'temperature_head': 0.7000000000000001, 'latent_dim': 221, 'batch_size': 311, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 428.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 432.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 614.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 838.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 856.00 MiB memory in use. Of the allocated memory 47.09 MiB is allocated by PyTorch, and 40.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cd39272c,"{'temperature_head': 0.5, 'latent_dim': 238, 'batch_size': 333, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 446.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 424.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 654.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 846.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 275.90 MiB is allocated by PyTorch, and 38.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4b4b6a5a,"{'temperature_head': 0.9, 'latent_dim': 72, 'batch_size': 180, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 432.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 446.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 846.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 564.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 176.97 MiB is allocated by PyTorch, and 47.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03b56428,"{'temperature_head': 1.0, 'latent_dim': 520, 'batch_size': 168, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 562.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 846.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 432.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 138.69 MiB is allocated by PyTorch, and 33.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
764d2ee0,"{'temperature_head': 0.9, 'latent_dim': 81, 'batch_size': 155, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 562.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 512.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 846.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 420.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 46.00 MiB is allocated by PyTorch, and 34.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6ba7cfe6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 164, 'batch_size': 309, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 504.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 510.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 846.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 466.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 135.13 MiB is allocated by PyTorch, and 34.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e51b14c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 184, 'batch_size': 273, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 504.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 896.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 510.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 814.00 MiB memory in use. Of the allocated memory 135.28 MiB is allocated by PyTorch, and 34.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e702ff1f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 212, 'batch_size': 263, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 746.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 896.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 554.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.50 MiB is allocated by PyTorch, and 36.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e16acd49,"{'temperature_head': 0.9, 'latent_dim': 105, 'batch_size': 128, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 746.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 454.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 914.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 572.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 446.00 MiB memory in use. Of the allocated memory 196.74 MiB is allocated by PyTorch, and 35.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5614c772,"{'temperature_head': 0.6000000000000001, 'latent_dim': 170, 'batch_size': 318, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 746.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 500.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 512.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 914.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 454.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 135.17 MiB is allocated by PyTorch, and 36.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d3a84b95,"{'temperature_head': 0.8, 'latent_dim': 46, 'batch_size': 211, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 502.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 502.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 418.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 914.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 692.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 45.73 MiB is allocated by PyTorch, and 32.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1c764c22,"{'temperature_head': 0.9, 'latent_dim': 96, 'batch_size': 174, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 456.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 502.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 466.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 914.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 692.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 558.00 MiB memory in use. Of the allocated memory 78.59 MiB is allocated by PyTorch, and 37.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
59470532,"{'temperature_head': 0.8, 'latent_dim': 112, 'batch_size': 137, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 502.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 502.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 506.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 958.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 692.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 134.72 MiB is allocated by PyTorch, and 31.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1c87057b,"{'temperature_head': 0.8, 'latent_dim': 70, 'batch_size': 183, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 512.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 502.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 958.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 692.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 514.00 MiB memory in use. Of the allocated memory 134.39 MiB is allocated by PyTorch, and 37.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5dd4ace5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 233, 'batch_size': 365, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 556.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 558.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 618.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 958.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 452.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 79.67 MiB is allocated by PyTorch, and 32.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2c2aa613,"{'temperature_head': 0.9, 'latent_dim': 28, 'batch_size': 146, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 598.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 558.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 618.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 958.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 418.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 456.00 MiB memory in use. Of the allocated memory 45.59 MiB is allocated by PyTorch, and 32.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9797d11c,"{'temperature_head': 0.7000000000000001, 'latent_dim': 386, 'batch_size': 314, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 646.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 560.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 958.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 428.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 400.00 MiB memory in use. Of the allocated memory 136.86 MiB is allocated by PyTorch, and 37.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6b4584c5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 253, 'batch_size': 437, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 646.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 560.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 514.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 958.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 426.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 400.00 MiB memory in use. Of the allocated memory 47.34 MiB is allocated by PyTorch, and 38.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
57525dd8,"{'temperature_head': 0.6000000000000001, 'latent_dim': 179, 'batch_size': 255, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 626.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 560.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 432.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 958.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 468.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 400.00 MiB memory in use. Of the allocated memory 241.24 MiB is allocated by PyTorch, and 44.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
15b6bd64,"{'temperature_head': 0.5, 'latent_dim': 87, 'batch_size': 135, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 564.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 684.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 960.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 78.52 MiB is allocated by PyTorch, and 33.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
48cb92b2,"{'temperature_head': 0.4, 'latent_dim': 66, 'batch_size': 203, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 564.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 684.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 960.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 508.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 454.00 MiB memory in use. Of the allocated memory 134.36 MiB is allocated by PyTorch, and 33.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8ef149a4,"{'temperature_head': 0.9, 'latent_dim': 119, 'batch_size': 172, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 448.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 960.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 704.00 MiB memory in use. Of the allocated memory 46.30 MiB is allocated by PyTorch, and 35.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
070d9652,"{'temperature_head': 0.8, 'latent_dim': 127, 'batch_size': 160, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 452.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 960.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 422.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 704.00 MiB memory in use. Of the allocated memory 78.84 MiB is allocated by PyTorch, and 33.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6c0d6064,"{'temperature_head': 0.6000000000000001, 'latent_dim': 206, 'batch_size': 294, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 25582 has 716.00 MiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28801 has 720.00 MiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 454.00 MiB memory in use. Process 29189 has 784.00 MiB memory in use. Process 29188 has 434.00 MiB memory in use. Process 29577 has 1.06 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29582 has 720.00 MiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 960.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29973 has 904.00 MiB memory in use. Process 29976 has 470.00 MiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 704.00 MiB memory in use. Of the allocated memory 135.45 MiB is allocated by PyTorch, and 32.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cbf37d21,"{'temperature_head': 0.8, 'latent_dim': 421, 'batch_size': 143, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.02 GiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 880.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.12 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 960.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.13 GiB memory in use. Of the allocated memory 385.53 MiB is allocated by PyTorch, and 350.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
94a10e37,"{'temperature_head': 0.7000000000000001, 'latent_dim': 323, 'batch_size': 266, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 936.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.12 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 916.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.09 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.13 GiB memory in use. Of the allocated memory 326.82 MiB is allocated by PyTorch, and 269.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
41418efb,"{'temperature_head': 0.5, 'latent_dim': 553, 'batch_size': 225, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 138.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 982.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 976.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.02 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 962.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.09 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.13 GiB memory in use. Of the allocated memory 464.60 MiB is allocated by PyTorch, and 243.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
155cb5fc,"{'temperature_head': 0.5, 'latent_dim': 305, 'batch_size': 250, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 936.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.07 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 962.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.09 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.13 GiB memory in use. Of the allocated memory 316.04 MiB is allocated by PyTorch, and 279.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
700361e9,"{'temperature_head': 0.5, 'latent_dim': 328, 'batch_size': 266, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 982.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.07 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.05 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.13 GiB memory in use. Of the allocated memory 329.82 MiB is allocated by PyTorch, and 404.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a04f524b,"{'temperature_head': 0.5, 'latent_dim': 641, 'batch_size': 268, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 390.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 666.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.07 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.09 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.13 GiB memory in use. Of the allocated memory 138.35 MiB is allocated by PyTorch, and 187.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
36b78353,"{'temperature_head': 0.30000000000000004, 'latent_dim': 304, 'batch_size': 291, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 1.06 GiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.03 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 780.00 MiB memory in use. Of the allocated memory 315.44 MiB is allocated by PyTorch, and 394.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bfd28ea3,"{'temperature_head': 0.2, 'latent_dim': 321, 'batch_size': 253, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 132.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 950.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 566.00 MiB memory in use. Of the allocated memory 325.62 MiB is allocated by PyTorch, and 284.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bc65797d,"{'temperature_head': 0.30000000000000004, 'latent_dim': 373, 'batch_size': 266, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 948.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 614.00 MiB memory in use. Of the allocated memory 356.77 MiB is allocated by PyTorch, and 251.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a6207279,"{'temperature_head': 0.2, 'latent_dim': 263, 'batch_size': 271, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 666.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 291.90 MiB is allocated by PyTorch, and 34.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2ad4871f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 350, 'batch_size': 282, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 1.01 GiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 914.00 MiB memory in use. Of the allocated memory 136.07 MiB is allocated by PyTorch, and 133.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
299ba480,"{'temperature_head': 0.30000000000000004, 'latent_dim': 405, 'batch_size': 283, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 994.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1014.00 MiB memory in use. Of the allocated memory 136.51 MiB is allocated by PyTorch, and 133.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
42257948,"{'temperature_head': 0.30000000000000004, 'latent_dim': 335, 'batch_size': 291, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 610.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 994.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1014.00 MiB memory in use. Of the allocated memory 135.96 MiB is allocated by PyTorch, and 134.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
726f6690,"{'temperature_head': 0.2, 'latent_dim': 360, 'batch_size': 244, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 724.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 862.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 958.00 MiB memory in use. Of the allocated memory 349.49 MiB is allocated by PyTorch, and 34.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
450b9b3c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 337, 'batch_size': 235, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 668.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 908.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 988.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 958.00 MiB memory in use. Of the allocated memory 135.97 MiB is allocated by PyTorch, and 192.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
51becf60,"{'temperature_head': 0.30000000000000004, 'latent_dim': 356, 'batch_size': 234, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 668.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 958.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 990.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 958.00 MiB memory in use. Of the allocated memory 136.12 MiB is allocated by PyTorch, and 191.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8bf229b2,"{'temperature_head': 0.2, 'latent_dim': 282, 'batch_size': 258, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 676.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 872.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 990.00 MiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 302.77 MiB is allocated by PyTorch, and 33.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0f041512,"{'temperature_head': 0.30000000000000004, 'latent_dim': 282, 'batch_size': 272, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 454.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 898.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 80.05 MiB is allocated by PyTorch, and 33.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7e5319d7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 307, 'batch_size': 238, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 450.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 898.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 80.24 MiB is allocated by PyTorch, and 29.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
42ab4227,"{'temperature_head': 0.30000000000000004, 'latent_dim': 295, 'batch_size': 254, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 814.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.15 MiB is allocated by PyTorch, and 33.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6f212b97,"{'temperature_head': 0.1, 'latent_dim': 389, 'batch_size': 231, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 200.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 742.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 366.89 MiB is allocated by PyTorch, and 35.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
81196077,"{'temperature_head': 0.30000000000000004, 'latent_dim': 280, 'batch_size': 270, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 682.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 558.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 301.06 MiB is allocated by PyTorch, and 40.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ce0da8fd,"{'temperature_head': 0.30000000000000004, 'latent_dim': 297, 'batch_size': 264, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 858.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 454.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 311.66 MiB is allocated by PyTorch, and 206.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
274b7418,"{'temperature_head': 0.2, 'latent_dim': 352, 'batch_size': 277, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 858.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 456.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 344.19 MiB is allocated by PyTorch, and 173.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7993c9fd,"{'temperature_head': 0.30000000000000004, 'latent_dim': 405, 'batch_size': 234, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 870.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 484.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 376.51 MiB is allocated by PyTorch, and 153.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0ec2c830,"{'temperature_head': 0.30000000000000004, 'latent_dim': 285, 'batch_size': 266, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 772.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.07 MiB is allocated by PyTorch, and 31.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4eed78f4,"{'temperature_head': 0.30000000000000004, 'latent_dim': 320, 'batch_size': 272, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 772.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 33.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a51445c3,"{'temperature_head': 0.30000000000000004, 'latent_dim': 423, 'batch_size': 218, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 772.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 137.15 MiB is allocated by PyTorch, and 32.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bd995d19,"{'temperature_head': 0.30000000000000004, 'latent_dim': 416, 'batch_size': 236, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 820.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 137.10 MiB is allocated by PyTorch, and 30.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a71d52e6,"{'temperature_head': 0.30000000000000004, 'latent_dim': 380, 'batch_size': 226, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 510.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 764.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.81 MiB is allocated by PyTorch, and 33.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4c7a4d18,"{'temperature_head': 0.2, 'latent_dim': 407, 'batch_size': 230, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 170.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 508.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 716.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.30 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 137.03 MiB is allocated by PyTorch, and 30.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f72e7cc3,"{'temperature_head': 0.2, 'latent_dim': 394, 'batch_size': 221, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 164.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 744.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 716.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.07 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 369.86 MiB is allocated by PyTorch, and 34.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cc7cd78e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 441, 'batch_size': 245, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 690.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 852.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.07 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.79 MiB is allocated by PyTorch, and 213.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d1e69aa0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 367, 'batch_size': 227, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 688.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 852.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.07 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 211.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9e996257,"{'temperature_head': 0.30000000000000004, 'latent_dim': 398, 'batch_size': 277, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 688.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 852.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 1.07 GiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.45 MiB is allocated by PyTorch, and 211.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
118679fe,"{'temperature_head': 0.30000000000000004, 'latent_dim': 386, 'batch_size': 245, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 186.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 686.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 902.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 948.00 MiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.36 MiB is allocated by PyTorch, and 209.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
72938d56,"{'temperature_head': 0.30000000000000004, 'latent_dim': 343, 'batch_size': 236, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 686.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 902.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 948.00 MiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.02 MiB is allocated by PyTorch, and 209.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
346288ae,"{'temperature_head': 0.2, 'latent_dim': 408, 'batch_size': 265, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 182.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 686.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 902.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 950.00 MiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 136.53 MiB is allocated by PyTorch, and 209.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2b83659d,"{'temperature_head': 0.30000000000000004, 'latent_dim': 309, 'batch_size': 250, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 870.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 902.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 878.00 MiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 318.44 MiB is allocated by PyTorch, and 211.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7d01f66a,"{'temperature_head': 0.2, 'latent_dim': 384, 'batch_size': 238, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 25584 has 1.06 GiB memory in use. Process 25580 has 1002.00 MiB memory in use. Process 25542 has 874.00 MiB memory in use. Process 25586 has 1.00 GiB memory in use. Process 28795 has 1.59 GiB memory in use. Process 28798 has 1.11 GiB memory in use. Process 28804 has 902.00 MiB memory in use. Process 28792 has 1.12 GiB memory in use. Process 29194 has 1.18 GiB memory in use. Process 29195 has 1.21 GiB memory in use. Process 29183 has 1.23 GiB memory in use. Process 29188 has 1.30 GiB memory in use. Process 29577 has 878.00 MiB memory in use. Process 29574 has 1.02 GiB memory in use. Process 29586 has 2.06 GiB memory in use. Process 29583 has 964.00 MiB memory in use. Process 29964 has 1.12 GiB memory in use. Process 29976 has 1.42 GiB memory in use. Process 29972 has 1.00 GiB memory in use. Process 29971 has 1.05 GiB memory in use. Of the allocated memory 363.36 MiB is allocated by PyTorch, and 170.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
