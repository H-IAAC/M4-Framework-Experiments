{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73c2972a-8a68-476c-8260-6f981e684777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def create_simclr_basic(dataset,folder):\n",
    "    data=\"\"\"\n",
    "    estimators:\n",
    "    -   algorithm: RandomForest\n",
    "        kwargs:\n",
    "            n_estimators: 100\n",
    "        name: randomforest-100\n",
    "        num_runs: 10\n",
    "    -   algorithm: KNN\n",
    "        kwargs:\n",
    "            n_neighbors: 5\n",
    "        name: KNN-5\n",
    "        num_runs: 1\n",
    "    -   algorithm: SVM\n",
    "        kwargs:\n",
    "            C: 1.0\n",
    "            kernel: rbf\n",
    "        name: SVM-rbf-C1.0\n",
    "        num_runs: 1\n",
    "    extra:\n",
    "        in_use_features:\n",
    "        - accel-x\n",
    "        - accel-y\n",
    "        - accel-z\n",
    "        - gyro-x\n",
    "        - gyro-y\n",
    "        - gyro-z\n",
    "        reduce_on: all\n",
    "        save_reducer: true\n",
    "        scale_on: train\n",
    "    reducer:\n",
    "        algorithm: SimCLR\n",
    "        kwargs:\n",
    "            input_shape: [60, 6]\n",
    "            n_components: 98\n",
    "            batch_size: 256\n",
    "            transform_funcs: [0]\n",
    "            temperature: 1.0\n",
    "            epochs: 300\n",
    "            verbose: 0\n",
    "            patience: 10\n",
    "            min_delta: 0.001\n",
    "            device: 'cuda'\n",
    "            dataset: 'uci'\n",
    "            save_reducer: false\n",
    "            \n",
    "        name: SIMCLR\n",
    "        use_y: false\n",
    "    \n",
    "    reducer_dataset:\n",
    "    - uci.standartized_balanced[train]\n",
    "    test_dataset:\n",
    "    - uci.standartized_balanced[validation]\n",
    "    train_dataset:\n",
    "    - uci.standartized_balanced[train]\n",
    "    \n",
    "    \n",
    "    \n",
    "    version: '1.0'\n",
    "    \"\"\"\n",
    "    config_data = data.replace('uci',f'{dataset}')\n",
    "\n",
    "    with open(f'{folder}/base_config.yaml', 'w') as file:\n",
    "            file.write(config_data)\n",
    "\n",
    "def create_exploration_config_simclr(folder,latent_dim,transformation):\n",
    "    data= \"\"\"\n",
    "    resources:\n",
    "      gpu: 0.9\n",
    "      cpu: 1.0\n",
    "    search_space: \n",
    "    \n",
    "      min_delta:\n",
    "        tune_function: quniform\n",
    "        tune_parameters: [0.001, 0.9,0.001]\n",
    "        route: reducer/kwargs/min_delta\n",
    "    \n",
    "      temperature:\n",
    "        tune_function: quniform\n",
    "        tune_parameters: [0.1, 2.0, 0.1]\n",
    "        route: reducer/kwargs/temperature\n",
    " \n",
    "      batch_size:\n",
    "        tune_function: randint\n",
    "        tune_parameters: [128, 512]\n",
    "        route: reducer/kwargs/batch_size\n",
    "    \n",
    "      latent_dim:\n",
    "        tune_function: randint\n",
    "        tune_parameters: [2, 361]\n",
    "        route: reducer/kwargs/n_components\n",
    "    \n",
    "    \n",
    "    \n",
    "      transform_funcs:\n",
    "        tune_function: choice\n",
    "        tune_parameters: [[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]\n",
    "    ]]\n",
    "        route: reducer/kwargs/transform_funcs\n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    initial_params:\n",
    "    \n",
    "    \"\"\"\n",
    "    dim=str((latent_dim*360/100)+1)\n",
    "    config_data = data.replace('tune_parameters: [2, 361]',f'tune_parameters: [2,{dim}]')\n",
    "    config_data = config_data.replace(f'tune_parameters: [[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]]]',f'tune_parameters: [{transformations}]')\n",
    "    with open(f'{folder}/exploration_config.yaml', 'w') as file:\n",
    "        file.write(config_data)\n",
    "\n",
    "\n",
    "datasets = ['kuhar', 'motionsense',  'wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "#datasets=['realworld_waist']\n",
    "type_simclr='simclr'\n",
    "transformations=[1,2,3,4]\n",
    "percentages = [25, 50, 75, 100, 200]\n",
    "folder_name=f'experiments/simclr_all1/{type_simclr}'\n",
    "create_folder(folder_name)\n",
    "#simclr_expr=\"simclr_linear\"\n",
    "#transformation='0_19_T' \n",
    "for dataset in datasets:\n",
    "  create_folder(f'{folder_name}/{dataset}')\n",
    "  script_filename = f'{type_simclr}_{dataset}.sh'\n",
    "\n",
    "# Escribir el contenido en el archivo .sh\n",
    "  script_file=open(script_filename, 'w')\n",
    "  for transformation in transformations:\n",
    "    for percentage in percentages:\n",
    "            folder=f'{folder_name}/{dataset}/{type_simclr}_{transformation}T_{dataset}_P{percentage}'\n",
    "            create_folder(folder)\n",
    "            create_exploration_config_simclr(folder,percentage,transformation)\n",
    "            create_simclr_basic(dataset,folder)\n",
    "            script_content= f'python hsearch_main.py --data ../data/ --cpu 0.2 --gpu 0.2 --max_concurrent 20 --experiment simclr_all/{type_simclr}/{dataset}/{type_simclr}_{transformation}T_{dataset}_P{percentage}'\n",
    "            create_execute(script_file,script_content)\n",
    "            if(percentage!=200):\n",
    "                create_execute(script_file,' & \\n')\n",
    "            else:\n",
    "                create_execute(script_file,'\\n')\n",
    "                \n",
    "            \n",
    "            \n",
    "                \n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3c1ec6-e76d-48e9-8c39-bc4a541a1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def create_uci_explotation_config(folder,latent_dim):\n",
    "    \n",
    "    \n",
    "    data=\"\"\"\n",
    "    resources:\n",
    "      gpu: 0.9\n",
    "      cpu: 1.0\n",
    "    search_space: \n",
    "  \n",
    "      temperature_head:\n",
    "        tune_function: quniform\n",
    "        tune_parameters: [0.1, 1.0,0.1]\n",
    "        route: reducer/kwargs/temperature_head\n",
    "    \n",
    "      latent_dim:\n",
    "        tune_function: randint\n",
    "        tune_parameters: [2, 361]\n",
    "        route: reducer/kwargs/n_components\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "     \n",
    "    \n",
    "    \n",
    "    initial_params:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    dim=str((latent_dim*360/100)+1)\n",
    "    config_data = data.replace('tune_parameters: [2, 361]',f'tune_parameters: [2,{dim}]')\n",
    "    #config_data = config_data.replace(f'tune_parameters: [[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]]]',f'tune_parameters: [{transformations}]')\n",
    "    with open(f'{folder}/exploration_config.yaml', 'w') as file:\n",
    "        file.write(config_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850d2c3-f0a8-4e5b-8b74-e854513424b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4a0998-2c8b-49a2-968a-2cab86c982a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_execute(script_file,script_content):\n",
    "    script_file.write(script_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193f3a84-d00b-482f-b82a-df5ac5944d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 15:17:56.904112: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-13 15:17:56.934364: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-13 15:17:56.934411: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-13 15:17:56.934431: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-13 15:17:56.939995: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 15:17:57.622053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def create_linear_base_config(dataset,folder):\n",
    "    estimators = [\n",
    "        {\n",
    "            'algorithm': 'RandomForest',\n",
    "            'kwargs': {\n",
    "                'n_estimators': 100,\n",
    "            },\n",
    "            'name': 'randomforest-100',\n",
    "            'num_runs': 10,\n",
    "        },\n",
    "        {\n",
    "            'algorithm': 'KNN',\n",
    "            'kwargs': {\n",
    "                'n_neighbors': 5,\n",
    "            },\n",
    "            'name': 'KNN-5',\n",
    "            'num_runs': 1,\n",
    "        },\n",
    "        {\n",
    "            'algorithm': 'SVM',\n",
    "            'kwargs': {\n",
    "                'C': 1.0,\n",
    "                'kernel': 'rbf',\n",
    "            },\n",
    "            'name': 'SVM-rbf-C1.0',\n",
    "            'num_runs': 1,\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    extra = {\n",
    "        'in_use_features': [\n",
    "            'accel-x',\n",
    "            'accel-y',\n",
    "            'accel-z',\n",
    "            'gyro-x',\n",
    "            'gyro-y',\n",
    "            'gyro-z',\n",
    "        ],\n",
    "        'reduce_on': 'all',\n",
    "        'save_reducer': False,\n",
    "        'scale_on': 'train',\n",
    "    }\n",
    "    \n",
    "    reducer = {\n",
    "        'algorithm': 'SimCLR_linear',\n",
    "        'kwargs': {\n",
    "            'dataset': dataset,\n",
    "            'input_shape': [60, 6],\n",
    "            'n_components': 60,\n",
    "            'batch_size_head': 256,\n",
    "            'transform_funcs': [0, 1, 9],\n",
    "            'temperature_head': 0.77,\n",
    "            'epochs_head': 300,\n",
    "            'patience': 10,\n",
    "            'min_delta': 0.001,\n",
    "            'device': 'cuda',\n",
    "            'save_reducer': False,\n",
    "            'save_model': False,\n",
    "            'verbose': 0,\n",
    "            'total_epochs': 50,\n",
    "            'batch_size': 32,\n",
    "            'lr': 0.001,\n",
    "        },\n",
    "        'name': 'SIMCLR_linear',\n",
    "        'use_y': True,\n",
    "    }\n",
    "    \n",
    "    reducer_dataset = [f'{dataset}.standartized_balanced[train]']\n",
    "    test_dataset = [f'{dataset}.standartized_balanced[validation]']\n",
    "    train_dataset = [f'{dataset}.standartized_balanced[train]']\n",
    "    \n",
    "    config = {\n",
    "        'estimators': estimators,\n",
    "        'extra': extra,\n",
    "        'reducer': reducer,\n",
    "        'reducer_dataset': reducer_dataset,\n",
    "        'test_dataset': test_dataset,\n",
    "        'train_dataset': train_dataset,\n",
    "        'version': '1.0',\n",
    "    }\n",
    "    \n",
    "    import yaml\n",
    "    \n",
    "    # Guardar la configuración en un archivo YAML\n",
    "    with open(f'{folder}/base_config.yaml', 'w') as file:\n",
    "        yaml.dump(config, file, default_flow_style=False)\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    import os\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)    \n",
    "\n",
    "datasets = ['kuhar', 'motionsense', 'uci', 'wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "#datasets=['realworld_waist']\n",
    "type_simclr='SimCLR_linear'\n",
    "transformations=[1,2,3,4]\n",
    "percentages = [25, 50, 75, 100, 200]\n",
    "folder_name=f'experiments/simclr_all/{type_simclr}'\n",
    "create_folder(folder_name)\n",
    "#simclr_expr=\"simclr_linear\"\n",
    "#transformation='0_19_T' \n",
    "for dataset in datasets:\n",
    "  create_folder(f'{folder_name}/{dataset}')\n",
    "  script_filename = f'{type_simclr}_{dataset}.sh'\n",
    "\n",
    "# Escribir el contenido en el archivo .sh\n",
    "  script_file=open(script_filename, 'w')\n",
    "  for transformation in transformations:\n",
    "    for percentage in percentages:\n",
    "            folder=f'{folder_name}/{dataset}/{type_simclr}_{transformation}T_{dataset}_P{percentage}'\n",
    "            create_folder(folder)\n",
    "            #create_uci_explotation_config(folder,percentage)\n",
    "            create_explotation_config(folder,percentage,transformation)\n",
    "            create_linear_base_config(dataset,folder)\n",
    "            script_content= f'python hsearch_main.py --data ../data/ --cpu 0.2 --gpu 0.2 --max_concurrent 20 --experiment simclr_all/{type_simclr}/{dataset}/{type_simclr}_{transformation}T_{dataset}_P{percentage}'\n",
    "            create_execute(script_file,script_content)\n",
    "            if(percentage!=200):\n",
    "                create_execute(script_file,' & \\n')\n",
    "            else:\n",
    "                create_execute(script_file,'\\n')\n",
    "                \n",
    "            \n",
    "            \n",
    "                \n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05821527-de63-4150-b980-70d4d0372f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200*360/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89c62e13-9ec3-42d5-91b1-de29b2b51361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/kuhar/simclr_full_kuhar_P75/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/kuhar/simclr_full_kuhar_P200/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/kuhar/simclr_full_kuhar_P100/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/kuhar/simclr_full_kuhar_P25/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/kuhar/simclr_full_kuhar_P50/base_config.yaml\n",
      "Copiado de archivos completado.\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/motionsense/simclr_full_motionsense_P75/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/motionsense/simclr_full_motionsense_P200/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/motionsense/simclr_full_motionsense_P100/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/motionsense/simclr_full_motionsense_P25/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/motionsense/simclr_full_motionsense_P50/base_config.yaml\n",
      "Copiado de archivos completado.\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/wisdm/simclr_full_wisdm_P75/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/wisdm/simclr_full_wisdm_P200/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/wisdm/simclr_full_wisdm_P100/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/wisdm/simclr_full_wisdm_P25/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/wisdm/simclr_full_wisdm_P50/base_config.yaml\n",
      "Copiado de archivos completado.\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_thigh/simclr_full_realworld_thigh_P75/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_thigh/simclr_full_realworld_thigh_P200/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_thigh/simclr_full_realworld_thigh_P100/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_thigh/simclr_full_realworld_thigh_P25/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_thigh/simclr_full_realworld_thigh_P50/base_config.yaml\n",
      "Copiado de archivos completado.\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_waist/simclr_full_realworld_waist_P75/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_waist/simclr_full_realworld_waist_P200/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_waist/simclr_full_realworld_waist_P100/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_waist/simclr_full_realworld_waist_P25/base_config.yaml\n",
      "../experiments/simclr_all/all_transformations/simclr_full/tem_transf/realworld_waist/simclr_full_realworld_waist_P50/base_config.yaml\n",
      "Copiado de archivos completado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def criar_exp(dataset_base,dataset_dest):\n",
    "    root_directory = '../experiments/simclr_all/all_transformations/simclr_full/tem_transf/'+dataset_base\n",
    "    destination_directory = f'../experiments/simclr_all/all_transformations/{model_dest}/tem_transf/'+dataset_dest\n",
    "    \n",
    "    \n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        for directory in dirs:\n",
    "            current_directory = os.path.join(root, directory)\n",
    "            directory = directory.replace(dataset_base, dataset_dest)\n",
    "            directory = directory.replace(model, model_dest)\n",
    "    \n",
    "            dest_subfolder = os.path.join(destination_directory, directory)\n",
    "            os.makedirs(dest_subfolder, exist_ok=True)\n",
    "    \n",
    "            # Copia los archivos 'exploration_config.yaml' y 'base_config.yaml' si existen\n",
    "            for filename in ['exploration_config.yaml', 'base_config.yaml']:\n",
    "                source_file = os.path.join(current_directory, filename)\n",
    "                if os.path.isfile(source_file):\n",
    "                    dest_file = os.path.join(dest_subfolder, filename)\n",
    "                    shutil.copy(source_file, dest_file)\n",
    "                    if(filename=='base_config.yaml'):\n",
    "                        print(dest_file)\n",
    "                        with open(dest_file, 'r') as file:\n",
    "                            config_data = file.read()\n",
    "                        config_data = config_data.replace(dataset_base,dataset_dest)\n",
    "                        config_data = config_data.replace(algorithm,algorithm_dest)\n",
    "                        \n",
    "    \n",
    "                        with open(dest_file, 'w') as file:\n",
    "                            file.write(config_data)\n",
    "            \n",
    "    \n",
    "    \n",
    "    print(\"Copiado de archivos completado.\")\n",
    "\n",
    "algorithm=\"algorithm: SimCLR_full\"\n",
    "algorithm_dest=\"algorithm: SimCLR_linear\"\n",
    "model='simclr_full'\n",
    "model_dest='simclr_linear'\n",
    "datasets = ['kuhar', 'motionsense',  'wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "for dataset in datasets:\n",
    "    criar_exp('uci', dataset)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72359942-cd08-453a-b096-d5e75aba9a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kuhar\n",
      "motionsense\n",
      "wisdm\n",
      "realworld_thigh\n",
      "realworld_waist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model='simclr_full'\n",
    "test='tem_transf'\n",
    "script_filename = f'../{test}_{model}.sh'\n",
    "script_file=open(script_filename, 'w')\n",
    "def create_execute(script_file,script_content):\n",
    "    script_file.write(script_content)\n",
    "\n",
    "datasets = ['kuhar', 'motionsense', 'wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "destination_directory = '../experiments/simclr_all/all_transformations/simclr_full/tem_transf/'\n",
    "destination_directory_ = 'simclr_all/all_transformations/simclr_full/tem_transf'\n",
    "count=0\n",
    "for dataset in datasets:\n",
    "    \n",
    "    dataset1=dataset\n",
    "    print(dataset)\n",
    "            \n",
    "    for root, dirs, files in os.walk(f'{destination_directory}/{dataset}'):       \n",
    "        \n",
    "        for dir in dirs:\n",
    "            if \"simclr\" in dir:\n",
    "                dir1=f'{destination_directory}/{dataset}'\n",
    "                script_content= f'python hsearch_main.py --data ../data/ --cpu 0.2 --gpu 0.2 --max_concurrent 20 --experiment {os.path.join(dir1, dir)}'\n",
    "                create_execute(script_file,script_content)\n",
    "                if(count<4):\n",
    "                    create_execute(script_file,' & \\n')\n",
    "                    count=count+1\n",
    "\n",
    "                else:\n",
    "                    create_execute(script_file,'  \\n')\n",
    "                    count=0\n",
    "                \n",
    "                \n",
    "               \n",
    "  \n",
    "    \n",
    "\n",
    "                    \n",
    "                #print(os.path.join(root, dir))\n",
    "script_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35121b-4265-4d63-b936-cb4bfa1435d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
